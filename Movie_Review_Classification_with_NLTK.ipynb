{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp6VIL19vhlJzXc2uKOFEA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raulc66/AI-Learning/blob/main/Movie_Review_Classification_with_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 : Importing the Libraries"
      ],
      "metadata": {
        "id": "7nWjN1vkduLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random"
      ],
      "metadata": {
        "id": "Eh6J28wUdwnR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjakavz6d9Bq",
        "outputId": "d9aa45d1-672f-46a8-c9d8-ff56274cdc02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /root/nltk_data/corpora/movie_reviews/ # location of the downloaded file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV2X-NpjmdAU",
        "outputId": "8349143c-1ac9-409a-a8c9-5f79f562eff4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neg  pos  README\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 : Data Processing"
      ],
      "metadata": {
        "id": "Z9zT9_ShgMDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of tuples\n",
        "documents= []\n",
        "for category in movie_reviews.categories(): # divides into positive and negative reviews\n",
        "  for fileid in movie_reviews.fileids(category): # for each file id in the given category\n",
        "    documents.append((list(movie_reviews.words(fileid)), category)) # appends the list containing the files divided into the negative / positive reviews"
      ],
      "metadata": {
        "id": "S3B04dgjd_IR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the documents\n",
        "random.shuffle(documents)\n",
        "print(documents[0]) # first tuple of the list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RABgYrDnfLrz",
        "outputId": "ca3a732a-7ae9-481d-e93e-885c96458870"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['the', 'swirling', 'sick', 'feeling', 'hit', 'me', 'just', 'a', 'few', 'minutes', 'into', '\"', 'heartbreakers', '.', '\"', 'ray', 'liotta', \"'\", 's', 'character', 'was', 'making', 'out', 'with', 'his', 'secretary', 'when', 'his', 'new', 'wife', 'knocked', 'on', 'the', 'door', 'of', 'his', 'office', '.', 'while', 'scrambling', 'to', 'collect', 'himself', ',', 'he', 'frantically', 'shouted', 'to', 'her', ',', '\"', 'just', 'wait', 'a', 'sex', '?', 'er', ',', 'i', 'mean', 'sec', '!', '\"', 'i', 'was', 'struck', 'by', 'a', 'wave', 'of', 'revulsion', ',', 'thinking', ',', '\"', 'geez', ',', 'didn', \"'\", 't', 'lines', 'like', 'that', 'die', 'when', \"'\", 'three', \"'\", 's', 'company', \"'\", 'was', 'canceled', '?', '\"', 'over', 'the', 'next', 'few', 'minutes', ',', 'as', 'the', 'barely', 'double', 'entendres', 'and', 'lingering', 'cleavage', 'shots', 'grew', 'more', 'numerous', ',', 'i', 'realized', 'that', 'the', 'mindset', 'behind', '\"', 'heartbreakers', '\"', 'predated', '\"', 'three', \"'\", 's', 'company', '.', '\"', 'suddenly', ',', 'i', 'had', 'an', 'out', '-', 'of', '-', 'body', 'experience', 'as', 'my', 'internal', 'way', '-', 'back', 'machine', 'swept', 'me', 'to', 'the', 'mid', '-', '1960s', '.', 'all', 'across', 'america', ',', 'the', 'counter', '-', 'culture', 'was', 'growing', 'like', 'wildfire', ',', 'but', 'there', 'was', 'scant', 'evidence', 'of', 'it', 'on', 'tv', '.', 'while', 'young', 'people', 'were', 'challenging', 'traditional', 'values', 'on', 'the', 'streets', ',', 'frustrated', 'teenagers', 'like', 'me', 'were', 'stuck', 'at', 'home', ',', 'sulking', 'while', 'our', 'parents', 'enjoyed', 'the', 'latest', 'bob', 'hope', 'special', '.', 'women', 'in', 'skimpy', 'bathing', 'suits', 'would', 'prance', 'onscreen', 'while', 'hope', 'made', 'growling', 'noises', 'and', 'leered', 'at', 'their', 'breasts', '.', 'on', 'another', 'channel', ',', 'dean', 'martin', 'made', 'wisecracks', 'about', '\"', 'booze', 'and', 'broads', '\"', 'and', 'peter', 'lawford', ',', 'decked', 'out', 'in', 'love', 'beads', 'and', 'a', 'nehru', 'jacket', ',', 'purred', 'suggestive', 'one', '-', 'liners', 'as', 'he', 'ogled', 'the', 'go', '-', 'go', 'dancers', '.', 'the', 'adults', 'laughed', 'and', 'laughed', '.', '\"', 'heartbreakers', '\"', 'reeks', 'of', 'that', 'stagnant', 'mentality', ',', 'from', 'its', 'lingering', 'shots', 'of', 'jennifer', 'love', 'hewitt', \"'\", 's', 'vah', '-', 'vah', '-', 'voom', 'breasts', 'to', 'its', 'leaden', 'screenplay', ',', 'which', 'paints', 'women', 'as', 'haughty', 'schemers', 'and', 'men', 'as', 'drooling', 'buffoons', 'too', 'sex', '-', 'obsessed', 'to', 'realize', 'they', 'are', 'being', 'manipulated', '.', 'in', 'addition', 'to', 'liotta', 'and', 'hewitt', ',', 'the', 'cast', 'includes', 'sigourney', 'weaver', ',', 'gene', 'hackman', ',', 'jason', 'lee', ',', 'nora', 'dunn', 'and', 'anne', 'bancroft', '.', 'i', 'can', \"'\", 't', 'imagine', 'what', 'drew', 'performers', 'of', 'their', 'caliber', 'to', 'this', 'project', '.', 'perhaps', 'they', 'thought', 'it', 'was', 'a', 'parody', 'of', 'the', 'sniggering', 'sex', 'comedies', 'of', 'the', \"'\", '60s', '.', 'if', 'so', ',', 'they', 'were', 'sadly', 'mistaken', '.', 'the', 'story', 'revolves', 'around', 'a', 'mother', '-', 'daughter', 'con', '-', 'team', '.', 'it', 'opens', 'with', 'the', 'marriage', 'of', 'max', '(', 'weaver', ')', 'to', 'dean', '(', 'liotta', ')', ',', 'a', 'new', 'jersey', 'chop', 'shop', 'operator', '.', 'having', 'withheld', 'sex', 'until', 'the', 'honeymoon', ',', 'max', 'pretends', 'to', 'pass', 'out', 'on', 'their', 'wedding', 'night', '.', 'the', 'next', 'morning', ',', 'she', 'feigns', 'illness', ',', 'sending', 'a', 'very', 'horny', 'dean', 'off', 'to', 'the', 'office', ',', 'where', 'he', 'ends', 'up', 'in', 'the', 'arms', 'of', 'his', 'new', 'secretary', '.', 'just', 'as', 'the', 'two', 'are', 'about', 'to', 'get', 'overtly', 'physical', ',', 'max', 'bursts', 'into', 'the', 'room', 'and', 'catches', 'them', '.', 'the', '\"', 'horrified', '\"', 'bride', 'dissolves', 'the', 'union', ',', 'garnering', 'a', 'healthy', 'cash', 'settlement', 'along', 'the', 'way', '.', 'of', 'course', ',', 'the', 'secretary', 'was', 'really', 'her', 'daughter', 'page', '(', 'hewitt', ')', 'and', 'the', 'whole', 'thing', 'was', 'a', 'set', '-', 'up', '.', 'the', 'women', 'move', 'on', ',', 'but', 'an', 'irs', 'agent', '(', 'bancroft', ')', 'catches', 'up', 'with', 'them', 'and', 'demands', 'a', 'huge', 'amount', 'of', 'money', 'to', 'cover', 'unpaid', 'taxes', '.', 'in', 'desperate', 'need', 'of', 'funds', ',', 'max', 'and', 'page', 'head', 'for', 'palm', 'beach', 'to', 'replay', 'the', 'scam', '.', 'their', 'mark', 'this', 'time', 'is', 'william', 'b', '.', 'tensy', '(', 'hackman', ',', 'in', 'hideous', 'make', '-', 'up', ')', ',', 'a', 'decrepit', 'tobacco', 'tycoon', 'obsessed', 'with', 'the', 'joys', 'of', 'smoking', '.', 'max', 'starts', 'to', 'put', 'the', 'game', 'into', 'action', ',', 'but', 'page', 'is', 'so', 'repelled', 'by', 'the', 'old', 'man', '(', 'and', 'angry', 'with', 'her', 'mom', ')', 'that', 'she', 'slips', 'off', 'to', 'enact', 'her', 'own', 'score', ',', 'targeting', 'jack', ',', 'a', 'laid', 'back', 'young', 'beach', 'bar', 'owner', 'who', 'is', 'worth', 'a', 'fortune', '.', 'complications', 'arise', 'when', 'page', 'realizes', 'that', 'good', '-', 'natured', 'jack', 'is', 'stirring', 'actual', 'emotions', 'in', 'her', 'steely', 'little', 'heart', '.', 'as', 'if', 'that', 'wasn', \"'\", 't', 'enough', ',', 'dean', 'reappears', 'on', 'the', 'scene', 'with', 'revenge', 'on', 'his', 'mind', '.', 'the', 'attempt', 'to', 'weld', 'a', 'romance', 'onto', 'a', 'caper', 'comedy', 'served', 'only', 'to', 'remind', 'me', 'of', 'the', 'infinitely', 'superior', '\"', 'a', 'fish', 'called', 'wanda', '.', '\"', 'i', 'won', \"'\", 't', 'bother', 'to', 'compare', 'the', 'two', '.', 'suffice', 'to', 'say', 'that', 'everything', 'done', 'right', 'in', '\"', 'wanda', '\"', 'is', 'done', 'wrong', 'here', '.', '\"', 'heartbreakers', '\"', 'is', 'soulless', ',', 'inept', 'and', ',', 'at', '123', 'minutes', ',', 'at', 'least', 'a', 'half', '-', 'hour', 'too', 'long', '.', 'sigourney', 'weaver', 'and', 'jennifer', 'love', 'hewitt', 'throw', 'themselves', 'into', 'their', 'parts', ',', 'but', 'have', 'nowhere', 'to', 'go', 'with', 'the', 'metallic', 'characters', '.', 'gene', 'hackman', 'is', 'utterly', 'wasted', 'in', 'a', 'one', '-', 'note', ',', 'one', '-', 'joke', 'part', 'that', 'has', 'him', 'doing', 'nothing', 'but', 'smoking', ',', 'coughing', 'and', 'waxing', 'rhapsodic', 'about', 'smoking', 'and', 'sex', '.', 'poor', 'jason', 'lee', 'is', 'stuck', 'in', 'the', 'ingenue', 'role', 'and', 'the', 'normally', 'charismatic', 'actor', 'comes', 'off', 'as', 'merely', 'bland', '.', 'ray', 'liotta', 'manages', 'to', 'squeeze', 'a', 'tiny', 'bit', 'of', 'humanity', 'and', 'humor', 'into', 'his', 'walking', 'clich', '?', ',', 'but', 'only', 'a', 'bit', '.', 'the', 'low', 'point', 'in', 'the', 'film', 'has', 'weaver', 'employing', 'a', 'russian', 'accent', 'bad', 'enough', 'to', 'make', 'boris', 'and', 'natasha', 'wince', ',', 'while', 'doing', 'half', '-', 'assed', 'slapstick', 'with', 'a', 'broken', 'off', 'penis', 'from', 'a', 'statue', '.', 'bear', 'in', 'mind', ',', 'though', ',', 'that', 'this', 'is', 'merely', 'the', 'worst', 'segment', 'of', 'a', 'movie', 'made', 'up', 'of', 'nothing', 'but', 'low', 'points', '.', 'if', 'you', 'remember', 'bob', 'hope', 'specials', 'with', 'fondness', ',', 'this', 'might', 'be', 'your', 'cup', 'of', 'tea', '.', 'as', 'for', 'me', ',', 'i', \"'\", 'm', 'going', 'to', 'watch', '\"', 'a', 'fish', 'called', 'wanda', '\"', 'now', 'and', 'try', 'to', 'forget', 'i', 'ever', 'saw', '\"', 'heartbreakers', '.', '\"'], 'neg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the dataset\n",
        "all_words = []\n",
        "for w in movie_reviews.words():\n",
        "  all_words.append(w.lower())"
      ],
      "metadata": {
        "id": "f-5_h3DYfcWJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK frequency distribution\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "print(all_words.most_common(15))\n",
        "print(all_words['love'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOCU94Elf8lr",
        "outputId": "10976346-4233-49ed-d709-bf17fc143241"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
            "1119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit the words\n",
        "word_features = list(all_words.keys())[:3000]"
      ],
      "metadata": {
        "id": "eZjgN5S6gg89"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find features within the documents\n",
        "def find_features(document):\n",
        "  words = set(document) # unique values\n",
        "  features = {} # dictionary containing the existence of a feature within the document\n",
        "  for w in word_features:\n",
        "    features[w] : (w in words) # if the given word is found within the documents, returns True\n",
        "  return features # Provided the file, it will return the existence of each word"
      ],
      "metadata": {
        "id": "0S-nrqF6gZEq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((find_features(movie_reviews.words('/root/nltk_data/corpora/movie_reviews/pos/cv000_29590.txt'))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS5q_MJPh3Vr",
        "outputId": "87e10464-9804-47b6-99bb-10270d293d71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_sets = [(find_features(rev), category) for (rev, category) in documents] # returns a list for all the words found in the documents list if the feature exists"
      ],
      "metadata": {
        "id": "3RR5tlmwiIW6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = feature_sets[:1900]\n",
        "test_set = feature_sets[1900:]"
      ],
      "metadata": {
        "id": "SxUgxwu1iTFh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Classifier\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "qwsN4HJBlMbD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Accuracy\n",
        "print('Accuracy :', (nltk.classify.accuracy(classifier, test_set)) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQp-N4yuldM6",
        "outputId": "609bc02c-6975-4595-e659-72880a4c2920"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 48.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UlXJLHNl1ED",
        "outputId": "27da8a1e-8517-4d9c-ffe3-0a1b6edaf167"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n"
          ]
        }
      ]
    }
  ]
}