{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uKXVZtkK64S"
   },
   "source": [
    "# Analyzing word and document frequency: tf-idf\n",
    "\n",
    "A central question in text mining and natural language processing is how to quantify what a document is about. Can we do this by looking at the words that make up the document? \n",
    "\n",
    "One measure of how important a word may be is its term frequency (tf). \n",
    "\n",
    "This is how frequently a word occurs in a document - as we saw in Lab 2. However, there are words in a document that occur many times but may not be important. In English these words are most often things like “the”, “is”, “of”, and so forth. We might take the approach of adding words like these to a list of stop words and removing them before analysis, but it is possible that some of these words might be more important in some documents than others. A list of stop words is not a very sophisticated approach to adjusting term frequency for commonly used words.\n",
    "\n",
    "Another approach is to look at a term’s inverse document frequency (idf), which decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection of documents. This can be combined with term frequency to calculate a term’s tf-idf (the two quantities multiplied together), the frequency of a term adjusted for how rarely it is used.\n",
    "\n",
    "The tf-idf statistic is intended to measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfHhLTSPjeFT"
   },
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2WwebKjQE4ij",
    "outputId": "437d2830-8a02-4a78-d935-3ae5ff347cb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>line_number</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg eBook of Jane Eyre by Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This eBook is for the use of anyone anywhere i...</td>\n",
       "      <td>2</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>most other parts of the world at no cost and w...</td>\n",
       "      <td>3</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whatsoever You may copy it give it away or reu...</td>\n",
       "      <td>4</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                line  line_number       book\n",
       "0  The Project Gutenberg eBook of Jane Eyre by Ch...            0  Jane Eyre\n",
       "1                                                               1  Jane Eyre\n",
       "2  This eBook is for the use of anyone anywhere i...            2  Jane Eyre\n",
       "3  most other parts of the world at no cost and w...            3  Jane Eyre\n",
       "4  whatsoever You may copy it give it away or reu...            4  Jane Eyre"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "# Jane Eyre\n",
    "book_url = 'https://www.gutenberg.org/files/1260/1260-0.txt'\n",
    "response = requests.get(book_url)\n",
    "bronte1 = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "bronte1 = ''.join(c for c in bronte1 if c in allowed_chars)\n",
    "\n",
    "# Wuthering Heights\n",
    "book_url = 'https://www.gutenberg.org/cache/epub/768/pg768.txt'\n",
    "response = requests.get(book_url)\n",
    "bronte2 = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "bronte2 = ''.join(c for c in bronte2 if c in allowed_chars)\n",
    "\n",
    "# Vilette\n",
    "book_url = 'https://www.gutenberg.org/files/9182/9182-0.txt'\n",
    "response = requests.get(book_url)\n",
    "bronte3 = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "bronte3 = ''.join(c for c in bronte3 if c in allowed_chars)\n",
    "\n",
    "# Agnes Gray\n",
    "book_url = 'https://www.gutenberg.org/files/767/767-0.txt'\n",
    "response = requests.get(book_url)\n",
    "bronte4 = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "bronte4 = ''.join(c for c in bronte4 if c in allowed_chars)\n",
    "\n",
    "# Create our dataframes\n",
    "bronte1_lines = bronte1.splitlines()\n",
    "\n",
    "bronte1_df = pd.DataFrame({\n",
    "    \"line\": bronte1_lines,\n",
    "    \"line_number\": list(range(len(bronte1_lines)))\n",
    "})\n",
    "\n",
    "bronte2_lines = bronte2.splitlines()\n",
    "\n",
    "bronte2_df = pd.DataFrame({\n",
    "    \"line\": bronte2_lines,\n",
    "    \"line_number\": list(range(len(bronte2_lines)))\n",
    "})\n",
    "\n",
    "bronte3_lines = bronte3.splitlines()\n",
    "\n",
    "bronte3_df = pd.DataFrame({\n",
    "    \"line\": bronte3_lines,\n",
    "    \"line_number\": list(range(len(bronte3_lines)))\n",
    "})\n",
    "\n",
    "bronte4_lines = bronte4.splitlines()\n",
    "\n",
    "bronte4_df = pd.DataFrame({\n",
    "    \"line\": bronte4_lines,\n",
    "    \"line_number\": list(range(len(bronte4_lines)))\n",
    "})\n",
    "\n",
    "# We’ll want to know which content comes from which book\n",
    "bronte1_df = bronte1_df.assign(book = 'Jane Eyre')\n",
    "bronte2_df = bronte2_df.assign(book = 'Wuthering Heights')\n",
    "bronte3_df = bronte3_df.assign(book = 'Vilette')\n",
    "bronte4_df = bronte4_df.assign(book = 'Agnes Grey')\n",
    "\n",
    "# Finally, we concatenate the books into one dataframe\n",
    "books = [bronte1_df, bronte2_df, bronte3_df, bronte4_df]\n",
    "bronte_books_df = pd.concat(books)\n",
    "bronte_books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kXaeFADMLSzt",
    "outputId": "e1594a68-82b4-4469-d85f-84564c63cf10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>line_number</th>\n",
       "      <th>book</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg eBook of Jane Eyre by Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Project Gutenberg eBook of Jane Eyre by Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Project Gutenberg eBook of Jane Eyre by Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Project Gutenberg eBook of Jane Eyre by Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Project Gutenberg eBook of Jane Eyre by Ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                line  line_number       book  \\\n",
       "0  The Project Gutenberg eBook of Jane Eyre by Ch...            0  Jane Eyre   \n",
       "1  The Project Gutenberg eBook of Jane Eyre by Ch...            0  Jane Eyre   \n",
       "2  The Project Gutenberg eBook of Jane Eyre by Ch...            0  Jane Eyre   \n",
       "3  The Project Gutenberg eBook of Jane Eyre by Ch...            0  Jane Eyre   \n",
       "4  The Project Gutenberg eBook of Jane Eyre by Ch...            0  Jane Eyre   \n",
       "\n",
       "        word  \n",
       "0        The  \n",
       "1    Project  \n",
       "2  Gutenberg  \n",
       "3      eBook  \n",
       "4         of  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We split the data into words\n",
    "# We first split the text column into a list of words\n",
    "bronte_books_df['word'] = bronte_books_df['line'].str.split()\n",
    "\n",
    "# Explode the words column to create a new row for each word (this creates a separate row for each word from the newly created words list)\n",
    "bronte_books_df = bronte_books_df.explode('word')\n",
    "\n",
    "# Reset the index of the dataframe (we want to index each word now)\n",
    "bronte_books_df = bronte_books_df.reset_index(drop=True)\n",
    "bronte_books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ydf-IDidhH3l",
    "outputId": "bb60c45f-1291-4a9d-8983-734001c15f77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585198</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585199</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585200</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>eBooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585201</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585202</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585203 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              book       word\n",
       "0        Jane Eyre        The\n",
       "1        Jane Eyre    Project\n",
       "2        Jane Eyre  Gutenberg\n",
       "3        Jane Eyre      eBook\n",
       "4        Jane Eyre         of\n",
       "...            ...        ...\n",
       "585198  Agnes Grey      about\n",
       "585199  Agnes Grey        new\n",
       "585200  Agnes Grey     eBooks\n",
       "585201  Agnes Grey        NaN\n",
       "585202  Agnes Grey        NaN\n",
       "\n",
       "[585203 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For our investigations the line & line_number columns will not be necessary, so we will remove them\n",
    "bronte_books_df = bronte_books_df[['book', 'word']]\n",
    "bronte_books_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR1EMwLsjkkE"
   },
   "source": [
    "### Word counting revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFpgEpwpTkvF",
    "outputId": "11f5475c-1b09-4357-f216-937ea20b3ee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "the    22423\n",
       "and    19617\n",
       "I      18439\n",
       "to     15784\n",
       "of     13370\n",
       "a      12297\n",
       "in      8104\n",
       "was     7444\n",
       "you     6431\n",
       "her     5981\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's count the occurrences of each word - this is a prerequisite for finding term frequency\n",
    "count_df = bronte_books_df.groupby('word')['word'].count() # Group by word column, then only keep the word column and perform the counting\n",
    "\n",
    "# Let's sort by term frequency\n",
    "count_df_sorted = count_df.sort_values(ascending=False)\n",
    "\n",
    "pd.set_option('display.max_rows', 10) # You can change the max number of rows that get displayed\n",
    "count_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "nRQCh5DndV1s",
    "outputId": "3aa0310f-0376-4eb4-ece0-1532c773c0fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>22423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>19617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>18439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>15784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>13370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30119</th>\n",
       "      <td>glovessuch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120</th>\n",
       "      <td>gloveless</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30121</th>\n",
       "      <td>glossily</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30122</th>\n",
       "      <td>glossiest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30123</th>\n",
       "      <td>zurck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  count\n",
       "0             the  22423\n",
       "1             and  19617\n",
       "2               I  18439\n",
       "3              to  15784\n",
       "4              of  13370\n",
       "...           ...    ...\n",
       "30119  glovessuch      1\n",
       "30120   gloveless      1\n",
       "30121    glossily      1\n",
       "30122   glossiest      1\n",
       "30123       zurck      1\n",
       "\n",
       "[30124 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .size() method functions similary, but differs slightly in output format\n",
    "# .size() also counts null values, which .count() does not\n",
    "bronte_books_df.groupby(['word']).size().sort_values(ascending=False).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "A3QPbR4ukBoS",
    "outputId": "6c3ff802-f889-4a4e-f9a1-8687032112ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>7501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>6328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>6163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54097</th>\n",
       "      <td>nolet</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54098</th>\n",
       "      <td>noit</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54099</th>\n",
       "      <td>noisy</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54100</th>\n",
       "      <td>counting</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54101</th>\n",
       "      <td>zurck</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word               book  count\n",
       "0           the            Vilette   7894\n",
       "1           the          Jane Eyre   7501\n",
       "2             I          Jane Eyre   7009\n",
       "3           and          Jane Eyre   6328\n",
       "4           and            Vilette   6163\n",
       "...         ...                ...    ...\n",
       "54097     nolet          Jane Eyre      1\n",
       "54098      noit          Jane Eyre      1\n",
       "54099     noisy  Wuthering Heights      1\n",
       "54100  counting         Agnes Grey      1\n",
       "54101     zurck            Vilette      1\n",
       "\n",
       "[54102 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby allows grouping based on multiple columns\n",
    "bronte_books_df.groupby(['word', 'book']).size().sort_values(ascending=False).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2Aa71UJayPr"
   },
   "source": [
    "### Aggregate\n",
    "One useful and elegant way of counting/aggregating data in pandas is by using the .agg() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "jE9R3Se6LlMA",
    "outputId": "8ad06fbb-0998-437a-f6a0-cfd259c7b9e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13th</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zigzag</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zigzags</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zle</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurck</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              book  word\n",
       "word                    \n",
       "1        Jane Eyre     9\n",
       "10         Vilette     1\n",
       "12         Vilette     1\n",
       "1260     Jane Eyre     1\n",
       "13th     Jane Eyre     1\n",
       "...            ...   ...\n",
       "zigzag   Jane Eyre     2\n",
       "zigzags    Vilette     1\n",
       "zle        Vilette     1\n",
       "zone       Vilette     2\n",
       "zurck      Vilette     1\n",
       "\n",
       "[30124 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We group our data by words, then we aggregate and can decide what information we want to display for each column\n",
    "\n",
    "# setting 'first' for the book column means that in the new dataframe we will display the first book on which each word occurs (in the book column)\n",
    "# setting 'count' for the word column means that in the new dataframe we will display the count of given word (in the word column)\n",
    "count_df = bronte_books_df.groupby('word').agg({'book': 'first', 'word': 'count'}) \n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "B3GEP2xMcCr7",
    "outputId": "7b32a8c1-103b-4f56-c38d-de391bb06408"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>22423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>19617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>18439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>15784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>13370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glovessuch</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gloveless</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glossily</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glossiest</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurck</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  book  count\n",
       "word                         \n",
       "the          Jane Eyre  22423\n",
       "and          Jane Eyre  19617\n",
       "I            Jane Eyre  18439\n",
       "to           Jane Eyre  15784\n",
       "of           Jane Eyre  13370\n",
       "...                ...    ...\n",
       "glovessuch     Vilette      1\n",
       "gloveless   Agnes Grey      1\n",
       "glossily     Jane Eyre      1\n",
       "glossiest    Jane Eyre      1\n",
       "zurck          Vilette      1\n",
       "\n",
       "[30124 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we used groupby, the 'word' keyword has become both an index and a column name\n",
    "# To get rid of any naming problems down the line, we will rename the column name 'word' to 'count'\n",
    "count_df = count_df.rename(columns={'word': 'count'})\n",
    "\n",
    "# Sorting values based on count column\n",
    "count_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0wfHaTCrRm3"
   },
   "source": [
    "### Merging Dataframes\n",
    "\n",
    "What we want next is to have a dataframe in which we know how many times each word appears per book and how many times it appears in all of the books.\n",
    "\n",
    "It is sometimes very useful to merge together two dataframes and this is what we're going to do to get our desired dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "_dVwhq0KltWI",
    "outputId": "f5c8a434-1aae-4fb7-9c04-2660d14d9553"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>7501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>6328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>6163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54097</th>\n",
       "      <td>nolet</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54098</th>\n",
       "      <td>noit</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54099</th>\n",
       "      <td>noisy</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54100</th>\n",
       "      <td>counting</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54101</th>\n",
       "      <td>zurck</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word               book  count\n",
       "0           the            Vilette   7894\n",
       "1           the          Jane Eyre   7501\n",
       "2             I          Jane Eyre   7009\n",
       "3           and          Jane Eyre   6328\n",
       "4           and            Vilette   6163\n",
       "...         ...                ...    ...\n",
       "54097     nolet          Jane Eyre      1\n",
       "54098      noit          Jane Eyre      1\n",
       "54099     noisy  Wuthering Heights      1\n",
       "54100  counting         Agnes Grey      1\n",
       "54101     zurck            Vilette      1\n",
       "\n",
       "[54102 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df_1 = bronte_books_df.groupby(['word', 'book']).size().sort_values(ascending=False).reset_index(name='count') # How many appearances each word has in each book\n",
    "count_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "rTbcz-IQqG9i",
    "outputId": "0b228640-c610-4816-9c49-054cf1b6aed7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vilette</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>192766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>72008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                book   count\n",
       "0            Vilette  199315\n",
       "1          Jane Eyre  192766\n",
       "2  Wuthering Heights  121114\n",
       "3         Agnes Grey   72008"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df_2 = bronte_books_df.groupby(['book']).size().sort_values(ascending=False).reset_index(name='count') # How many words each book has\n",
    "count_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "IjwrrW4DqNvc",
    "outputId": "baa793e5-894f-4c29-f3f8-b11710aa0715"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>count_x</th>\n",
       "      <th>count_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>6163</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>5762</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4924</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4732</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4406</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>2980</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>was</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>2836</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>her</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>2071</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>1905</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word     book  count_x  count_y\n",
       "0  the  Vilette     7894   199315\n",
       "1  and  Vilette     6163   199315\n",
       "2    I  Vilette     5762   199315\n",
       "3   of  Vilette     4924   199315\n",
       "4   to  Vilette     4732   199315\n",
       "5    a  Vilette     4406   199315\n",
       "6   in  Vilette     2980   199315\n",
       "7  was  Vilette     2836   199315\n",
       "8  her  Vilette     2071   199315\n",
       "9   it  Vilette     1905   199315"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words = count_df_1.merge(count_df_2, on='book')\n",
    "book_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "6wTzVq-U160s",
    "outputId": "8d0ca662-0f30-43a0-f066-5aa17dc1960e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>6163</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>5762</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4924</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4732</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4406</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>2980</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>was</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>2836</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>her</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>2071</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>1905</td>\n",
       "      <td>199315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word     book  word_appearances_in_book  book_total_word_count\n",
       "0  the  Vilette                      7894                 199315\n",
       "1  and  Vilette                      6163                 199315\n",
       "2    I  Vilette                      5762                 199315\n",
       "3   of  Vilette                      4924                 199315\n",
       "4   to  Vilette                      4732                 199315\n",
       "5    a  Vilette                      4406                 199315\n",
       "6   in  Vilette                      2980                 199315\n",
       "7  was  Vilette                      2836                 199315\n",
       "8  her  Vilette                      2071                 199315\n",
       "9   it  Vilette                      1905                 199315"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words = book_words.rename(columns={'count_x': 'word_appearances_in_book', 'count_y': 'book_total_word_count'}) # Give more meaningful names\n",
    "book_words.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W1cADaX5HxQ"
   },
   "source": [
    "### Exercise 1 \n",
    "\n",
    "1. Add a **tf** (term frequency) column to your dataframe.\n",
    "2. Add a **rank** column to your dataframe.\n",
    "3. Draw the rank vs term-frequency plot by uncommenting the code below \n",
    "\n",
    "Term frequency says how frequently a given word appears in a book. The formula for calculating it is \n",
    "    \n",
    "    term_frequency = word_appearances_in_book / book_total_word_count\n",
    "\n",
    "E.g. If a word appears 30 times in a book with 1000 words, then the term frequency of that word will be 0.03. (or 3%).\n",
    "\n",
    "The rank of a word will tell you where your word places itself in the frequency rankings **of your book**.\n",
    "\n",
    "i.e. The most common word in your book will have rank 1.\n",
    "E.g. If the entire text of your book is: \"he ate chips, ate pudding and he ate spinach\", then you would have:\n",
    "\n",
    "    ate - rank 1 (count = 3)\n",
    "    he - rank 2 (count = 2)\n",
    "    chips - rank 3 (count = 1)\n",
    "    pudding - rank 3 (count = 1)\n",
    "    and - rank 3 (count = 1)\n",
    "    spinach - rank 3 (count = 1)\n",
    "\n",
    "\n",
    "Hint: you can use the pandas .rank(method='dense', ascending=False) method for obtaining your word rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gDjaL0KC1KhM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.039606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>6163</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.030921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>5762</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.028909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4924</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.024705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4732</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.023741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word     book  word_appearances_in_book  book_total_word_count  \\\n",
       "0  the  Vilette                      7894                 199315   \n",
       "1  and  Vilette                      6163                 199315   \n",
       "2    I  Vilette                      5762                 199315   \n",
       "3   of  Vilette                      4924                 199315   \n",
       "4   to  Vilette                      4732                 199315   \n",
       "\n",
       "   term_frequency  \n",
       "0        0.039606  \n",
       "1        0.030921  \n",
       "2        0.028909  \n",
       "3        0.024705  \n",
       "4        0.023741  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below\n",
    "#1 \n",
    "\n",
    "print('\\n1')\n",
    "book_words['term_frequency'] = book_words['word_appearances_in_book'].div(book_words['book_total_word_count'])\n",
    "book_words.dropna(subset = ['term_frequency'], inplace=True)\n",
    "book_words.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.039606</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>6163</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>5762</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4924</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>4732</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.023741</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54097</th>\n",
       "      <td>nonprofit</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "      <td>72008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54098</th>\n",
       "      <td>nonot</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "      <td>72008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54099</th>\n",
       "      <td>noisy</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "      <td>72008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54100</th>\n",
       "      <td>nominate</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "      <td>72008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54101</th>\n",
       "      <td>counting</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>1</td>\n",
       "      <td>72008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54102 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word        book  word_appearances_in_book  book_total_word_count  \\\n",
       "0            the     Vilette                      7894                 199315   \n",
       "1            and     Vilette                      6163                 199315   \n",
       "2              I     Vilette                      5762                 199315   \n",
       "3             of     Vilette                      4924                 199315   \n",
       "4             to     Vilette                      4732                 199315   \n",
       "...          ...         ...                       ...                    ...   \n",
       "54097  nonprofit  Agnes Grey                         1                  72008   \n",
       "54098      nonot  Agnes Grey                         1                  72008   \n",
       "54099      noisy  Agnes Grey                         1                  72008   \n",
       "54100   nominate  Agnes Grey                         1                  72008   \n",
       "54101   counting  Agnes Grey                         1                  72008   \n",
       "\n",
       "       term_frequency   rank  \n",
       "0            0.039606    1.0  \n",
       "1            0.030921    5.0  \n",
       "2            0.028909    6.0  \n",
       "3            0.024705    8.0  \n",
       "4            0.023741    9.0  \n",
       "...               ...    ...  \n",
       "54097        0.000014  468.0  \n",
       "54098        0.000014  468.0  \n",
       "54099        0.000014  468.0  \n",
       "54100        0.000014  468.0  \n",
       "54101        0.000014  468.0  \n",
       "\n",
       "[54102 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\n2')\n",
    "rank_df = book_words['word_appearances_in_book'].rank(method='dense', ascending=False)\n",
    "book_words_df = pd.concat([rank_df.rename('rank'), book_words], axis=1).reset_index(drop=True)\n",
    "book_words_df[['word', 'book', 'word_appearances_in_book','book_total_word_count', 'term_frequency', 'rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6QIikhKYFELm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21fec363310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAChaklEQVR4nOzdeVyU1f7A8c/MsAnIIssAhopaKmkZoKblTrhlWnbbcytvtqrkL9QW13JrsU0tc82yumVdLa8iKl4XChWpFK5pIZixioKCbDPP7w9kcpgBZmDY9Pt+veZVc57zPOcMkvPtLN+jUhRFQQghhBBCGFE3dgeEEEIIIZoiCZKEEEIIIcyQIEkIIYQQwgwJkoQQQgghzJAgSQghhBDCDAmShBBCCCHMkCBJCCGEEMIMCZKEEEIIIcyQIEkIIYQQwgwJkoSwgEqlsugVGxvb2F01MX78+Cr7+/333zd294SF7r77blq2bElZWZlR+dGjR1GpVPj7+5vcs2/fPlQqFe+991699m38+PG0a9euxnoDBgww+v1zcnIiODiYBQsWUFJSUq99BGjXrh133313vbcjrh12jd0BIZqDuLg4o/fz589nz5497N6926g8ODi4IbtlsRYtWpj0FaBz586N0BtRGwMHDuSHH37g8OHD3H777Yby2NhYXFxcyMjI4H//+5/Rn2lF0D5w4MCG7m6V2rdvz2effQZAdnY2n3zyCa+++ippaWl8/PHHjdw7IYxJkCSEBa7+UgLw8fFBrVablNfW5cuXadGihU2eZY61fS0sLMTZ2bne+iOsVxHoxMbGmgRJo0aNYs+ePezZs8ckSPL29qZr1651aru0tBSVSoWdXd2/Mlq0aGHU/2HDhhEcHMz69et57733cHJyqnMbQtiKTLcJYSMlJSUsWLCAzp074+joiI+PDxMmTCA7O9uoXsWQ/+bNm7nttttwcnJi7ty5xMbGolKp+Pzzz4mKisLf3x9XV1dGjhxJZmYmFy9e5J///Cfe3t54e3szYcIELl26VOd+z5kzB5VKRUJCAvfffz+enp506NABAEVRWL58Od27d6dFixZ4enpy//3388cffxg9Q1EUlixZQtu2bXFyciIkJIT//Oc/DBgwgAEDBhjqrVu3DpVKxenTp43ur/jslacrY2JiGDx4MG5ubjg7O3PHHXewa9cus/0/fvw4Dz/8MO7u7mi1WiZOnEheXp5RXb1ez/vvv2/4PB4eHtx+++1s2bIFgCeeeIJWrVpRWFho8nMaNGgQN998c5U/x6lTp+Li4kJ+fr7JtQcffBCtVktpaSkAu3fvZsCAAXh5edGiRQvatGnDmDFjzLZboXv37nh6ehr9jPR6Pfv27WPAgAH079+fPXv2GK6VlJQQFxdnmOICOHbsGKNGjcLT0xMnJye6d+/O+vXrjdqp+LP49NNPefHFF2ndujWOjo6cOnUKKP8z7NSpE46OjnTp0oUNGzZU2WdL2NnZ0b17d0pKSrhw4YKh/PDhwzz00EO0a9eOFi1a0K5dOx5++GFSU1ON7q/4ndqzZw9PP/003t7eeHl5cd999/HXX3/V2P7y5cuxs7Nj9uzZdfoc4tokQZIQNqDX6xk1ahSLFi3ikUce4YcffmDRokXs3LmTAQMGcPnyZaP6CQkJ/N///R8vvPAC27dvZ8yYMYZrs2bNIisri3Xr1vHWW28RGxvLww8/zJgxY3B3d2fTpk289NJLfPrpp8yaNcviPpaVlRm9dDqd0fX77ruPjh078q9//YuVK1cC8NRTTzF16lTCw8P57rvvWL58OcePH6dPnz5kZmYa7p07dy5RUVHcddddfPfddzz99NNMmjSJEydO1ObHCcDGjRuJiIjAzc2N9evX89VXX9GqVSuGDBliEigBjBkzhptuuolvvvmGGTNm8PnnnzNt2jSjOuPHj2fKlCn06NGDL7/8ki+++IJ77rnHELRNmTKF8+fP8/nnnxvdl5SUxJ49e3j22Wer7O/EiRMpLCzkq6++Miq/cOEC//73v3nsscewt7fn9OnTjBgxAgcHB9asWcP27dtZtGgRLi4u1a7LUavV9OvXj/379xvWJSUmJnL+/Hn69+9P//792bt3r6H+jz/+yOXLlw0jUCdOnKBPnz4cP36c9957j82bNxMcHMz48eNZsmSJSXszZ84kLS2NlStXsnXrVnx9fVm3bh0TJkygS5cufPPNN7zyyivMnz/f7FSuNVJSUvDw8MDHx8dQdvr0aTp16sSyZcvYsWMHixcvJj09nR49epCTk2PyjCeffBJ7e3s+//xzlixZQmxsLI899liVbSqKwvTp05k6dSqffPIJc+fOrdNnENcoRQhhtXHjxikuLi6G95s2bVIA5ZtvvjGqd+jQIQVQli9fbihr27atotFolBMnThjV3bNnjwIoI0eONCqfOnWqAigvvPCCUfno0aOVVq1aWdRXwOR1xx13KIqiKLNnz1YA5bXXXjO6Ly4uTgGUt956y6j8zJkzSosWLZSXXnpJURRFOX/+vOLk5KTce++9RvUOHDigAEr//v0NZWvXrlUAJSUlxexn37Nnj6IoilJQUKC0atXK5Geh0+mUW2+9VenZs6ehrKL/S5YsMar7zDPPKE5OToper1cURVH++9//KoDy8ssvV/vz6t+/v9K9e3ejsqefflpxc3NTLl68WO29ISEhSp8+fYzKli9frgDKr7/+qiiKonz99dcKoCQmJlb7LHOWLVumAMrBgwcVRVGUt956S/H391cURVGSkpIUQDl27JiiKIoyd+5cBVCSkpIURVGUhx56SHF0dFTS0tKMnjls2DDF2dlZuXDhgqIof/9Z9OvXz6ieTqdTAgIClJCQEMPPVFEU5fTp04q9vb3Stm3bGvvfv39/5eabb1ZKS0uV0tJSJT09XXnttdcUQFm5cmW195aVlSmXLl1SXFxclHfffddQXvE79cwzzxjVX7JkiQIo6enphrK2bdsqI0aMUAoLC5UxY8Yo7u7uSkxMTI39FtcvGUkSwga+//57PDw8GDlypNFoTffu3fHz8zOZRrrlllu46aabzD6r8u6bLl26ADBixAiT8tzcXIum3Fq0aMGhQ4eMXqtXrzaqc/VoVsVnUqlUPPbYY0afyc/Pj1tvvdXwmeLi4igqKuLRRx81ur9Pnz60bdu2xr6Zc/DgQXJzcxk3bpxR23q9nqFDh3Lo0CEKCgqM7rnnnnuM3t9yyy0UFRWRlZUFwH/+8x+AakeDoHw0KTExkQMHDgCQn5/Pp59+yrhx43B1da323gkTJnDw4EGjEbS1a9fSo0cPw7qg7t274+DgwD//+U/Wr19vMnVZnavXJVX8s3///kD574Ovr69hyi02NhatVmv4/dm9ezeDBw8mMDDQ6Jnjx4+nsLDQZHNC5d+HEydO8Ndff/HII48Ypu8A2rZtS58+fSz+DMePH8fe3h57e3v8/f2ZN28eM2fO5KmnnjKqd+nSJaKioujYsSN2dnbY2dnh6upKQUEBycnJJs819+cPmEzPnTt3jkGDBhEfH8/+/fsZPHiwxX0X1x8JkoSwgczMTC5cuICDg4PhC6DilZGRYTI9YG67doVWrVoZvXdwcKi2vKioqMb+qdVqwsLCjF6dOnWqtk+ZmZkoioJWqzX5TD/++KPhM507dw4APz8/k3bNlVmiYirv/vvvN2l78eLFKIpCbm6u0T1eXl5G7x0dHQEMU53Z2dloNJoa+zRq1CjatWvHhx9+CJSveSkoKKgxuAJ49NFHcXR0ZN26dUD5NN2hQ4eYMGGCoU6HDh2IiYnB19eXZ599lg4dOtChQwfefffdGp/frVs3vL292bNnj2E9UkWQBNCvXz9iY2MpLi4mLi7OaFfbuXPnzP7eBQQEGK5frXJdW/05d+jQgUOHDhEfH8+//vUvbr31VhYuXMgXX3xhVO+RRx7hgw8+4Mknn2THjh3Ex8dz6NAhfHx8TKavoeY//wq//fYbP/30E8OGDavzgnZx7ZPdbULYQMVi0e3bt5u93rJlS6P3V/+feFNRuU/e3t6oVCr27dtn+MK5WkVZxZdTRkaGSZ2MjAyj/DkVO5eKi4uN6lUOIr29vQF4//33q9yVp9Vqq/s4Jnx8fNDpdGRkZFQbpKrVap599llmzZrFW2+9xfLlyxk8eLBJUGmOp6cno0aNYsOGDSxYsIC1a9fi5OTEww8/bFSvb9++9O3bF51Ox+HDh3n//feZOnUqWq2Whx56qMrnq1Qq+vfvz/bt24mPj+fChQtGQVL//v2ZM2eOYXTv6iDJy8uL9PR0k2dWLG6u+Jlf3dbVavpztpSTkxNhYWEA9OjRg4EDB3LzzTczdepU7r77blxdXcnLy+P7779n9uzZzJgxw3BvcXGxSXBsrd69e/OPf/yDJ554AoAVK1agVst4gTBPfjOEsIG7776bc+fOodPpTEZszI3aNAd33303iqJw9uxZs5+pW7duQHl6BCcnJ0PumwoHDx40meqoCJh++eUXo/KK3WUV7rjjDjw8PEhKSjLbdlhYmGEkzVLDhg0Dyr8Ua/Lkk0/i4ODAo48+yokTJ3juuecsbmfChAn89ddfbNu2jY0bN3Lvvffi4eFhtq5Go6FXr16GUauEhIQanz9w4EAKCgpYunQpvr6+huk0KA+Szp07x/vvv2+oW2Hw4MHs3r3bZMfXhg0bcHZ2rjFFRKdOnfD392fTpk0oimIoT01N5eDBgzX2uypeXl4sWrSIzMxMQ79VKhWKopgE55988onJhoPaGDduHF988QVr165l7NixNnmmuDbJSJIQNvDQQw/x2WefMXz4cKZMmULPnj2xt7fnzz//ZM+ePYwaNYp77723sbtplTvuuIN//vOfTJgwgcOHD9OvXz9cXFxIT09n//79dOvWjaeffhpPT0+mT5/OggULePLJJ/nHP/7BmTNnmDNnjsk0TI8ePejUqRPTp0+nrKwMT09Pvv32W/bv329Uz9XVlffff59x48aRm5vL/fffj6+vL9nZ2fz8889kZ2dbFOxcrW/fvjz++OMsWLCAzMxM7r77bhwdHTl69CjOzs48//zzhroeHh6MHTuWFStW0LZtW0aOHGlxOxEREdxwww0888wzZGRkGE21AaxcuZLdu3czYsQI2rRpQ1FREWvWrAEgPDy8xudXBD7ffvst999/v9G1rl274uXlxbfffkvr1q258cYbDddmz57N999/z8CBA3nttddo1aoVn332GT/88ANLlizB3d292nbVajXz58/nySef5N5772XSpElcuHDB7J+ztcaOHcvbb7/Nm2++ybPPPoubmxv9+vVj6dKleHt7065dO/bu3cvq1aurDDitdf/99+Ps7Mz999/P5cuX2bRpk9WBt7j2yUiSEDag0WjYsmULs2bNYvPmzdx7772MHj2aRYsW4eTkZBh1aW4++ugjPvjgA/773//y0EMPMWLECF577TUKCgro2bOnod68efNYuHAh0dHR3HPPPbz//vusXLnSZARNo9GwdetWOnfuzOTJkxk7diyOjo588MEHJm0/9thj7Nmzh0uXLvHUU08RHh7OlClTSEhIqPVi23Xr1vH2229z8OBB7r//fh544AH+/e9/ExQUZFL3wQcfBODpp5+2ajpGrVYzduxY/vzzTwIDA0362r17d8rKypg9ezbDhg3j8ccfJzs7my1bthAREVHj84ODg/Hz80NRFKOpNigfgenbty+Kohjlp4LykaCDBw/SqVMnnn32WUaPHs2xY8dYu3Yt//d//2fRZ3viiSf45JNPSEpK4r777mPevHnMmjWLQYMGWXR/VdRqNYsWLSI3N5dly5YB8PnnnzNw4EBeeukl7rvvPg4fPszOnTtrDOasMXz4cLZt20Z0dDSjRo0yu9ZJXN9UytXjpkIIYUMVX9RN8Uy7mrz44ousWLGCM2fOmCwKFkJcH2S6TQghrvLjjz/y22+/sXz5cp566ikJkIS4jkmQJIQQV+nduzfOzs7cfffdLFiwoLG7I4RoRDLdJoQQQghhhizcFkIIIYQwQ4IkIYQQQggzJEgSQgghhDBDFm7Xkl6v56+//qJly5ZN8ogJIYQQQphSFIWLFy8SEBBQYw40CZJq6a+//jI5TVsIIYQQzcOZM2e44YYbqq0jQVItVRxYeubMGdzc3Bq5N0IIIYSwRH5+PoGBgSYHj5sjQVItVUyxubm5SZAkhBBCNDOWLJWRhdtCCCGEEGZIkCSEEEIIYYYESUIIIYQQZsiaJCGEECZ0Oh2lpaWN3Q0hrGZvb49Go7HJsyRIEkIIYaAoChkZGVy4cKGxuyJErXl4eODn51fnPIYSJAkhhDCoCJB8fX1xdnaWZLmiWVEUhcLCQrKysgDw9/ev0/MaPUhavnw5S5cuJT09nZtvvplly5bRt2/fKuvv3buXyMhIjh8/TkBAAC+99BKTJ082W/eLL77g4YcfZtSoUXz33Xd1alcIIa51Op3OECB5eXk1dneEqJUWLVoAkJWVha+vb52m3hp14faXX37J1KlTefnllzl69Ch9+/Zl2LBhpKWlma2fkpLC8OHD6du3L0ePHmXWrFm88MILfPPNNyZ1U1NTmT59utnAx9p2hRDielCxBsnZ2bmReyJE3VT8Dtd1XZ1KURTFFh2qjV69ehESEsKKFSsMZV26dGH06NEsXLjQpH5UVBRbtmwhOTnZUDZ58mR+/vln4uLiDGU6nY7+/fszYcIE9u3bx4ULF4xGkqxt15z8/Hzc3d3Jy8uTZJJCiGtCUVERKSkpBAUF4eTk1NjdEaLWqvtdtub7u9FGkkpKSjhy5AgRERFG5RERERw8eNDsPXFxcSb1hwwZwuHDh42ixXnz5uHj48MTTzxhk3Ybkk6v41DGIbb9sY1DGYfQ6XWN3SUhhBDiutRoa5JycnLQ6XRotVqjcq1WS0ZGhtl7MjIyzNYvKysjJycHf39/Dhw4wOrVq0lMTLRZuwDFxcUUFxcb3ufn51f38WolJjWGRfGLyCzM/Ltfzlpm9JxBeNtwm7cnhBBCiKo1ejLJyjsnFEWpdjeFufoV5RcvXuSxxx5j1apVeHt727TdhQsX4u7ubngFBgZW+3xrxaTGEBkbaRQgAWQVZhEZG0lMaoxN2xNCiGvNwYMH0Wg0DB06tLG7YpX8/HxeffVVbr75Zlq0aIGXlxc9evRgyZIlnD9/vrG7d11rtJEkb29vNBqNyehNVlaWyShPBT8/P7P17ezs8PLy4vjx45w+fZqRI0caruv1egDs7Ow4ceIEgYGBVrcLMHPmTCIjIw3vK04RtgWdXsei+EUomC4PU1BQoWJx/GIGBg5Eo7ZNgiwhhKgvOr1CfEouWReL8G3pRM+gVmjU9Z9KYM2aNTz//PN88sknpKWl0aZNm3pvs65yc3O58847yc/PZ/78+YSGhuLg4MCpU6f4/PPP+fzzz3n22WfN3ltSUoKDg0MD9/j60mgjSQ4ODoSGhrJz506j8p07d9KnTx+z9/Tu3dukfnR0NGFhYdjb29O5c2d+/fVXEhMTDa977rmHgQMHkpiYSGBgYK3aBXB0dMTNzc3oZSsJWQkmI0hXU1DIKMwgISvBZm0KIUR92H4snTsX7+bhVT8y5YtEHl71I3cu3s32Y+n12m5BQQFfffUVTz/9NHfffTfr1q0zqbNlyxZuvPFGWrRowcCBA1m/fj0qlcqQOHPdunV4eHiwY8cOunTpgqurK0OHDiU93bjva9eupUuXLjg5OdG5c2eWL19uuFZSUsJzzz2Hv78/Tk5OtGvXrtoNQbNmzSItLY2ffvqJCRMmcMstt9C5c2fuvvtuPv/8c5555hlD3Xbt2rFgwQLGjx+Pu7s7kyZNAspH0Pr160eLFi0IDAzkhRdeoKCgAChfo9utWzeTdkNDQ3nttdcs/vlerxp1ui0yMpJPPvmENWvWkJyczLRp00hLSzPkPZo5cyZjx4411J88eTKpqalERkaSnJzMmjVrWL16NdOnTwfAycmJrl27Gr08PDxo2bIlXbt2NUTcNbXb0LILs21aTwghGsP2Y+k8vTGB9Lwio/KMvCKe3phQr4HSl19+SadOnejUqROPPfYYa9eu5erN26dPn+b+++9n9OjRJCYm8tRTT/Hyyy+bPKewsJA333yTTz/9lP/+97+kpaUZvmMAVq1axcsvv8zrr79OcnIyb7zxBq+++irr168H4L333mPLli189dVXnDhxgo0bN9KuXTuzfdbr9Xz55Zc89thjtG7d2mydystAli5dSteuXTly5Aivvvoqv/76K0OGDOG+++7jl19+4csvv2T//v0899xzAEycOJGkpCQOHTpkeMYvv/zC0aNHGT9+vEU/2+tZoyaTfPDBBzl37hzz5s0jPT2drl27sm3bNtq2bQtAenq6Ue6ioKAgtm3bxrRp0/jwww8JCAjgvffeY8yYMTZtt6H5OPvYtJ4QQjQ0nV5h7tYkM4sGQAFUwNytSdwV7FcvU2+rV6/mscceA2Do0KFcunSJXbt2ER5evull5cqVdOrUiaVLlwLQqVMnjh07xuuvv270nNLSUlauXEmHDh0AeO6555g3b57h+vz583nrrbe47777gPLvpaSkJD766CPGjRtHWloaN954I3feeScqlara75Xs7GwuXLhAp06djMpDQ0M5ceIEACNHjmTTpk2Ga4MGDTIK2saOHcsjjzzC1KlTAbjxxht577336N+/PytWrOCGG25gyJAhrF27lh49egDlI2H9+/enffv2Fv50r1+NnnH7mWeeMRpOvJq54dL+/fuTkGD5tJO5Z9TUbkML8Q1B66wlqzDL7LoklaKgdfQgxDekEXonhBA1i0/JNRlBupoCpOcVEZ+SS+8Ots3mfeLECeLj49m8eTNQvgb1wQcfZM2aNYYg6cSJE4YgoULPnj1NnuXs7GwIkKD8WIuKIy6ys7M5c+YMTzzxhGGqC6CsrAx3d3cAxo8fz1133UWnTp0YOnQod999t0nKmcoqjxZ9++23lJSUEBUVxeXLl42uhYWFGb0/cuQIp06d4rPPPjOUKYqCXq8nJSWFLl26MGnSJCZOnMjbb7+NRqPhs88+46233qq2T6JcowdJAjRqDTN6ziAydhoqRUG56j8Y1ZXh4qgzv6P53w8QfE9jdVMIIaqUdbHqAKk29ayxevVqysrKjKasFEXB3t6e8+fP4+npaXYHs7lcyvb29kbvVSqVoV7FRqBVq1bRq1cvo3oVR1+EhISQkpLCf/7zH2JiYnjggQcIDw/n66+/NmnLx8cHDw8P/ve//xmVVyw4b9mypclBwy4uLkbv9Xo9Tz31FC+88ILJ8yueM3LkSBwdHfn2229xdHSkuLjY6hmY65UESU1EeOBA3r6oY1ELhUy7v/9YtDodUefOE15YBNtnQOcRIDvchBBNjG9LyzJ0W1rPUmVlZWzYsIG33nrLZMRmzJgxfPbZZzz33HN07tyZbdu2GV0/fPiwVW1ptVpat27NH3/8waOPPlplPTc3Nx588EEefPBB7r//foYOHUpubi6tWrUyqqdWq3nggQfYuHEjr776apXrkqoTEhLC8ePH6dixY5V17OzsGDduHGvXrsXR0ZGHHnpIjp6xkARJTUXqQcJzzjIQSHByJFujwUenI6SoGENIlH8WUg9CkBzEK4RoWnoGtcLf3YmMvCKz65JUgJ97eToAW/r+++85f/48TzzxhGHKq8L999/P6tWree6553jqqad4++23iYqK4oknniAxMdGwHKO6HHmVzZkzhxdeeAE3NzeGDRtGcXExhw8f5vz580RGRvLOO+/g7+9P9+7dUavV/Otf/8LPzw8PDw+zz3vjjTeIjY2lV69ezJs3j7CwMFxcXPjll1+Ii4uja9eu1fYnKiqK22+/nWeffZZJkybh4uJCcnIyO3fu5P333zfUe/LJJ+nSpQsABw4csPjzXu8aPZmkuOJSeQoADdCjqJjhBYX0uDpAqlRPCCGaEo1axeyRwUB5QHS1ivezRwbbfNH26tWrCQ8PNwmQoHwkKTExkYSEBIKCgvj666/ZvHkzt9xyCytWrDDsbnN0dLS4vSeffJJPPvmEdevW0a1bN/r378+6desICgoCwNXVlcWLFxMWFkaPHj04ffo027ZtQ602/3Xr5eVFfHw8Y8eOZenSpfTs2ZNu3boxZ84cHnzwQVatWlVtf2655Rb27t3LyZMn6du3L7fddhuvvvoq/v7+RvVuvPFG+vTpQ6dOnUymCkXVGvWA2+bM5gfcpuyD9XfXXG/c9zKSJISoF7Y44Hb7sXTmbk0yWsTt7+7E7JHBDO3qX82dDe/1119n5cqVnDlzprG7Uu8URaFz58489dRTRomRr1W2OuBWptuairZ9wC0A8tOhqsFqt4DyekII0UQN7erPXcF+jZJxuybLly+nR48eeHl5ceDAAZYuXWrIJ3Qty8rK4tNPP+Xs2bNMmDChsbvTrEiQ1FSoNTB0MXw1lvLB6asDpSt/uQxdJIu2hRBNnkatsvk2f1s4efIkCxYsIDc3lzZt2vDiiy8yc+bMxu5WvdNqtXh7e/Pxxx/j6enZ2N1pVmS6rZZsPt1WIWkLbI+C/L/+LnNrXR4gyfZ/IUQ9ssV0mxBNgUy3XauC7ynf5p96sHyRtqu2fIpNRpCEEEKIBiVBUlOk1sjibCGEEKKRSQoAIYQQQggzJEgSQgghhDBDgiQhhBBCCDNkTVIzo+h0FB4+Qll2NnY+PjiHhaLSyKJuIYQQwtYkSGpG8qOjyXxjIWUZGYYyOz8/tLNm4lbpYEchhBBC1I1MtzUT+dHRnJ0y1ShAAijLzOTslKnkR0c3Us+EEKLxjR8/ntGjRzdqH9atW4dKpTJ5Sc6p5ktGkpoBRacj842FYC7v55WyzDcW0nLwYJl6E0I0Pr3uus315ubmxokTJ4zKVKraH8lSWlqKvb19XbslaklGkpqBwsNHTEaQKivLyKDw8JEG6pEQQlQhaQss61p+YPc3T5T/c1nX8vIGsn37du688048PDzw8vLi7rvv5vfffzdcP336NCqVis2bNzNw4ECcnZ259dZbiYuLM3rOwYMH6devHy1atCAwMJAXXniBgoKCattWqVT4+fkZvbRaLQAbNmzAy8uL4uJio3vGjBnD2LFjAZgzZw7du3dnzZo1tG/fHkdHRxRFIS8vj3/+85/4+vri5ubGoEGD+Pnnn23x4xLVkCCpGSjLzrao3sXdu+u5J0IIUY2kLeXnT159rBKUH9z91dgGC5QKCgqIjIzk0KFD7Nq1C7Vazb333oterzeq9/LLLzN9+nQSExO56aabePjhhykrKwPg119/ZciQIdx333388ssvfPnll+zfv79OB+L+4x//QKfTsWXL3z+HnJwcvv/+e6ODZ0+dOsVXX33FN998Q2JiIgAjRowgIyODbdu2ceTIEUJCQhg8eDC5ubm17o+omQRJTZVeByn74NevsdOlW3RL/tatKDqd4b1OrxD3+zn+nXiWuN/PodPLMX1CiHqi15WfO4m5v2eulG2fUV6vno0ZM4b77ruPG2+8ke7du7N69Wp+/fVXkpKSjOpNnz6dESNGcNNNNzF37lxSU1M5deoUAEuXLuWRRx5h6tSp3HjjjfTp04f33nuPDRs2UFRUVGXbeXl5uLq6Gr0irmysadGiBY888ghr16411P/ss8+44YYbGDBggKGspKSETz/9lNtuu41bbrmFPXv28Ouvv/Kvf/2LsLAwbrzxRt588008PDz4+uuvbfiTE5XJmqSmqNIht856UDsFoK/6v0sAdLm5FB4+gkuvnmw/ls7crUmk5/19k7+7E7NHBjO0q3999l4IcT1KPWg6gmREgfyz5fXq+dil33//nVdffZUff/yRnJwcwwhSWloaXbt2NdS75ZZbDP/u71/+92JWVhadO3fmyJEjnDp1is8+++zvT6Ao6PV6UlJS6NKli9m2W7ZsSUJCglFZixYtDP8+adIkevTowdmzZ2ndujVr165l/PjxRuuW2rZti4+Pj+H9kSNHuHTpEl5eXkbPvXz5stE0orA9CZKamorh6qv+b0ylBvc2lzj/m2uNt5dlZ7P9WDpPb0ww+f+5jLwint6YwIrHQiRQEkLY1qVM29arg5EjRxIYGMiqVasICAhAr9fTtWtXSkpKjOpdvSC6IkipCKj0ej1PPfUUL7zwgsnz27RpU2XbarWajh07Vnn9tttu49Zbb2XDhg0MGTKEX3/9la1btxrVcXFxMXqv1+vx9/cnNjbW5HkeHh5VtiXqToKkpqSa4eqWrYssCpLU3t7M3ZpU5YC3Cpi7NYm7gv3QqGu/40IIIYy4am1br5bOnTtHcnIyH330EX37lo9Y7d+/3+rnhISEcPz48WoDntp68skneeeddzh79izh4eEEBgbW2JeMjAzs7Oxo166dzfsjqiZrkpqSaoarnX1KsGuhw/x8P6BSYefnx7FWQUZTbJUpQHpeEfEpsthPCGFDbfuAWwDl/ytmjgrcWpfXq0eenp54eXnx8ccfc+rUKXbv3k1kZKTVz4mKiiIuLo5nn32WxMRETp48yZYtW3j++eervU9RFDIyMkxeVy8af/TRRzl79iyrVq1i4sSJNfYlPDyc3r17M3r0aHbs2MHp06c5ePAgr7zyCocPH7b6swnLSZDUlFQzDK1SgzYkr4qL5X8paWfNJKuw1KKmsi7WsMBJCCGsodbA0MVX3lQOlK68H7qo3vIl6fV67OzsUKvVfPHFFxw5coSuXbsybdo0li5davXzbrnlFvbu3cvJkyfp27cvt912G6+++qph7VJV8vPz8ff3N3llZWUZ6ri5uTFmzBhcXV0tSoCpUqnYtm0b/fr1Y+LEidx000089NBDnD592pBeQNQPlaKYy1AoapKfn4+7uzt5eXm4ubnZ5qEp+8pzilTX7hknMk90oCznvKHs6qNJ4n4/x8OrfqyxqU2Tbqd3B68a6wkhrh9FRUWkpKQQFBRU+yzRlTaeAOUjSEMXQfA9tumoGUOHDqVjx4588MEH9daGLd1111106dKF9957r7G7ck2q7nfZmu9vWZPUlFQMV+enY35aTYXbzV60XBlLYUKi2UNuewa1wt/diYy8oqom5vBwtqdnUKv6+hRCiOtZ8D3QeUSDZdw+f/48Bw8eJDY2lsmTJ9dLG7aUm5tLdHQ0u3fvbjYB3fVMgqSmpGK4+quxlA9PXx3m/D1crbJ3wKVXT7OP0KhVzB4ZzOSNCWavA1woLGVnUobscBNC1A+1pt63+VeYOHEihw4d4sUXX2TUqFEN0mZdhISEcP78eRYvXkynTp0auzuiBhIkNTXB98ADG8wMVwdYPFx9V7AfHs72XKhifZLscBNCXCu+/fbbxu6CVU6fPt3YXRBWkCCpKarjcHV8Sm6VARIY73CTdUlCCCGEeRIkNVV1GK62dOea7HATQgghqiYpAK5Bvi0t25ViaT0hhBDietToQdLy5csNW/RCQ0PZt29ftfX37t1LaGgoTk5OtG/fnpUrVxpd37x5M2FhYXh4eODi4kL37t359NNPjerMmTMHlUpl9PLz87P5Z2ssFTvcqknphr+7k+xwE0IIIarRqEHSl19+ydSpU3n55Zc5evQoffv2ZdiwYaSlpZmtn5KSwvDhw+nbty9Hjx5l1qxZvPDCC3zzzTeGOq1ateLll18mLi6OX375hQkTJjBhwgR27Nhh9Kybb76Z9PR0w+vXX3+t18/akCp2uEGVKd2YPTJYFm0LIYQQ1WjUZJK9evUiJCSEFStWGMq6dOnC6NGjWbhwoUn9qKgotmzZQnJysqFs8uTJ/Pzzz8TFxVXZTkhICCNGjGD+/PlA+UjSd999R2JiYq37Xi/JJG1s+7F05m5NMjqmxN/didkjg2X7vxDChE2SSQrRBDT7ZJIlJSUcOXKEGTNmGJVHRERw8OBBs/fExcURERFhVDZkyBBWr15NaWmp0YnOUH6Gzu7duzlx4gSLFy82unby5EkCAgJwdHSkV69evPHGG7Rv377K/hYXF1NcXGx4n5+fb9HnbExDu/pzV7Af8Sm5ZF0swrdl+RSbjCAJIa4nlf/HePz48Vy4cIHvvvuuUfslmr5Gm27LyclBp9OZnDuj1WrJyMgwe09GRobZ+mVlZeTk5BjK8vLycHV1xcHBgREjRvD+++9z1113Ga736tWLDRs2sGPHDlatWkVGRgZ9+vTh3LlzVfZ34cKFuLu7G141ndrcVGjUKnp38GJU99b07uAlAZIQ4poycuRIwsPDzV6Li4tDpVIxaNAgdu3aVes2YmNjUalUXLhwwah8wIABTJ06tdbPFU1fo6cAUKmMv7QVRTEpq6l+5fKWLVuSmJjIpUuX2LVrF5GRkbRv354BAwYAMGzYMEPdbt260bt3bzp06MD69eurPC165syZRtfy8/ObTaAkhBANSafXkZCVQHZhNj7OPoT4hqCpp2NJnnjiCe677z5SU1Np27at0bU1a9bQvXt3+vXrVy9ti2tfo40keXt7o9FoTEaNsrKyqjzV2M/Pz2x9Ozs7vLz+ToqoVqvp2LEj3bt358UXX+T+++83u8apgouLC926dePkyZNV1nF0dMTNzc3oJYQQwlhMagxDvhnCxB0TidoXxcQdExnyzRBiUmPqpb27774bX19f1q1bZ1ReWFjIl19+yRNPPMGcOXPo3r17lc9QFIUlS5bQvn17WrRowa233srXX38NlGfIHjhwIACenp6oVCrGjx/P+PHj2bt3L++++65hl3RFNu2kpCSGDx+Oq6srWq2Wxx9/3Gi2QzQfjRYkOTg4EBoays6dO43Kd+7cSZ8+fcze07t3b5P60dHRhIWFmaxHupqiKEbriSorLi4mOTkZf39ZzCyEELUVkxpDZGwkmYWZRuVZhVlExkbWS6BkZ2fH2LFjWbduHVfvQ/rXv/5FSUkJjz76aI3PeOWVV1i7di0rVqzg+PHjTJs2jccee4y9e/cSGBho2EF94sQJ0tPTeffdd3n33Xfp3bs3kyZNMuySDgwMJD09nf79+9O9e3cOHz7M9u3byczM5IEHHrD5Zxf1r1Gn2yIjI3n88ccJCwujd+/efPzxx6SlpRlOcp45cyZnz55lw4YNQPlOtg8++IDIyEgmTZpEXFwcq1evZtOmTYZnLly4kLCwMDp06EBJSQnbtm1jw4YNRjvopk+fzsiRI2nTpg1ZWVksWLCA/Px8xo0b17A/ACGEuEbo9DoWxS9CwXTDtIKCChWL4xczMHCgzafeJk6cyNKlS4mNjTWM+qxZs4b77rsPT0/Pau8tKCjg7bffZvfu3fTu3RuA9u3bs3//fj766CP69+9Pq1blOeV8fX3x8PAw3Ovg4ICzs7NRnr0VK1YQEhLCG2+8YShbs2YNgYGB/Pbbb9x00022+tiiATRqkPTggw9y7tw55s2bR3p6Ol27dmXbtm2GeeX09HSjnElBQUFs27aNadOm8eGHHxIQEMB7773HmDFjDHUKCgp45pln+PPPP2nRogWdO3dm48aNPPjgg4Y6f/75Jw8//DA5OTn4+Phw++238+OPP5rMZwshhLBMQlaCyQjS1RQUMgozSMhKoIdfD5u23blzZ/r06cOaNWsYOHAgv//+O/v27SM6OrrGe5OSkigqKjLa3APlO7Bvu+02q/ty5MgR9uzZg6urq8m133//XYKkZqbRF24/88wzPPPMM2avVZ5jBujfvz8JCQlVPm/BggUsWLCg2ja/+OILq/oohBCietmF2TatZ60nnniC5557jg8//JC1a9fStm1bBg8eXON9er0egB9++IHWrVsbXXN0dLS6H3q9npEjR5qknQFkSUcz1OhBkmgYOr0i+ZKEEPXGx9nHpvWs9cADDzBlyhQ+//xz1q9fz6RJk6rdKV0hODgYR0dH0tLS6N+/v9k6Dg4OAOh0OpPyymUhISF88803tGvXDjs7+Ypt7uRP8DogmbeFEPUtxDcErbOWrMIss+uSVKjQOmsJ8Q2pl/ZdXV158MEHmTVrFnl5eYwfP96i+1q2bMn06dOZNm0aer2eO++8k/z8fA4ePIirqyvjxo2jbdu2qFQqvv/+e4YPH06LFi1wdXWlXbt2/PTTT5w+fRpXV1datWrFs88+y6pVq3j44Yf5v//7P7y9vTl16hRffPEFq1atQqOpn1QIon40+gG3on5tP5bO0xsTjAIkgIy8Ip7emMD2Y+mN1DMhxLVEo9Ywo2f5CQqqSqdGVryP6hlVb/mSoHzK7fz584SHh9OmTRuL75s/fz6vvfYaCxcupEuXLgwZMoStW7cSFBQEQOvWrZk7dy4zZsxAq9Xy3HPPAeWbgDQaDcHBwfj4+JCWlkZAQAAHDhxAp9MxZMgQunbtypQpU3B3d0etlq/c5qZRz25rzprD2W06vcKdi3ebBEgVVICfuxP7owbJ1JsQwiZnt8WkxrAofpHRIm4/Zz+iekYR3tZ8ZmwhbK3Zn90m6l98Sm6VARKAAqTnFRGfkkvvDl5V1hNCCEuFtw1nYODABsu4LUR9kiDpGpZ1seoAqTb1hBDCEhq1xubb/IVoDBIkNWV6HaQehEuZ4KqFtn3Aiv8b821p2XC5pfWEEEKI64kESU1V0hbYHgX5f/1d5hYAQxdD8D0WPaJnUCv83Z3IyCsys9fk7zVJPYNa2aTLQgghxLVElto3RUlb4KuxxgESQH56eXnSFoseo1GrmD0yGIDKy7Ir3s8eGSyLtoUQQggzJEhqavS68hEks2M/V8q2zyivZ4GhXf1Z8VgIfu7GU2p+7k6seCxE8iQJIYQQVZDptqYm9aDpCJIRBfLPltcL6mvRI4d29eeuYD/JuC2EEEJYQYKkpuZS1QdE1qreFRq1Srb5CyGEEFaQ6bamxlVr23pCCCGEqBUJkpqatn3Kd7GZLLWuoAK31uX1hBBCNKjY2FhUKhUXLlxoVs+uL3PmzKF79+5W3TNgwACmTp1aL/2xNQmSmhq1pnybP1DlnrShi6zKlySEENeqlStX0rJlS8rKygxlly5dwt7enr59jddt7tu3D5VKxW+//WbRsxv6y7xPnz6kp6fj7u5er+1UF4y1a9eOZcuWWfys6dOns2vXLtt17gqVSsV3331n8+daS4Kkpij4HnhgA7hV2nnmFlBebmGeJCGEaAyKTkfBT/Hkff8DBT/Fo+gs241bGwMHDuTSpUscPnzYULZv3z78/Pw4dOgQhYWFhvLY2FgCAgK46aab6q0/tVVaWoqDgwN+fn6oVM1nU42rqyteXtfuelcJkpqq4Htg6jEY9z2MWV3+z6m/SoAkhGjS8qOjOTU4nLRx4/hr+nTSxo3j1OBw8qOj66W9Tp06ERAQQGxsrKEsNjaWUaNG0aFDBw4ePGhUPnDgQADGjx/P6NGjjZ41depUBgwYYLi+d+9e3n33XVQqFSqVitOnTxvqHjlyhLCwMJydnenTpw8nTpwwetbWrVsJDQ3FycmJ9u3bM3fuXKPRLpVKxcqVKxk1ahQuLi4sWLDAZIRn3bp1eHh4sGPHDrp06YKrqytDhw4lPT3d8JyysjJeeOEFPDw88PLyIioqinHjxpl8ttrKy8vjn//8J76+vri5uTFo0CB+/vlnw/XK022W9kev1/PSSy/RqlUr/Pz8mDNnjuFau3btALj33ntRqVSG9z///DMDBw6kZcuWuLm5ERoaahQc1wcJkpoytaZ8m3+3+8v/KVNsQogmLD86mrNTplKWkWFUXpaZydkpU+stUBowYAB79uwxvN+zZw8DBgygf//+hvKSkhLi4uIMQVJN3n33XXr37s2kSZNIT08nPT2dwMBAw/WXX36Zt956i8OHD2NnZ8fEiRMN13bs2MFjjz3GCy+8QFJSEh999BHr1q3j9ddfN2pj9uzZjBo1il9//dXo/qsVFhby5ptv8umnn/Lf//6XtLQ0pk+fbri+ePFiPvvsM9auXcuBAwfIz8+32TSVoiiMGDGCjIwMtm3bxpEjRwgJCWHw4MHk5uaavcfS/qxfvx4XFxd++uknlixZwrx589i5cycAhw4dAmDt2rWkp6cb3j/66KPccMMNHDp0iCNHjjBjxgzs7e1t8lmrpIhaycvLUwAlLy+vsbsihBA2cfnyZSUpKUm5fPmy1ffqy8qU3/oPUJI6dTb/6txF+a3/AEVfVmbzfn/88ceKi4uLUlpaquTn5yt2dnZKZmam8sUXXyh9+vRRFEVR9u7dqwDK77//riiKoowbN04ZNWqU0XOmTJmi9O/f3/C+f//+ypQpU4zq7NmzRwGUmJgYQ9kPP/ygAIafW9++fZU33njD6L5PP/1U8ff3N7wHlKlTp5p99vnz5xVFUZS1a9cqgHLq1ClDnQ8//FDRarWG91qtVlm6dKnhfVlZmdKmTRuTz2auHRcXF5OXSqVS3nnnHUVRFGXXrl2Km5ubUlRUZHR/hw4dlI8++khRFEWZPXu2cuutt1rVn/79+yt33nmn0TN79OihREVFGf18vv32W6M6LVu2VNatW1fl57padb/L1nx/S54kIYQQdVZ4+IjJCJIRRaEsI4PCw0dw6dXTpm0PHDiQgoICDh06xPnz57npppvw9fWlf//+PP744xQUFBAbG0ubNm1o3769Tdq85ZZbDP/u71++fjQrK4s2bdpw5MgRDh06ZDRypNPpKCoqorCwEGdnZwDCwsJqbMfZ2ZkOHToYtZWVlQWUT4VlZmbSs+ffP0+NRkNoaCh6vb7GZ+/bt4+WLVsalVVMN0L5lOKlS5dM1hxdvnyZ33//3eR51vTn6p9f5c9VlcjISJ588kk+/fRTwsPD+cc//mH0s6kPEiQJIYSos7LsbJvWs0bHjh254YYb2LNnD+fPn6d///4A+Pn5ERQUxIEDB9izZw+DBg0y3KNWqykfsPhbaWmpxW1ePc1TsdC6IhDQ6/XMnTuX++67z+Q+J6e/j4hycXGxqp2Ktir3u/JC78rXqxIUFISHh4dRmZ3d32GBXq/H39/faL1Xhcr3Wdsfc5+rpsBuzpw5PPLII/zwww/85z//Yfbs2XzxxRfce++91d5XF7ImSQghRJ3Z+fjYtJ61Bg4cSGxsLLGxsUajIf3792fHjh38+OOPRuuRfHx8jBZAAyQmJhq9d3BwQFeLnXkhISGcOHGCjh07mrzUatt97bq7u6PVaomPjzeU6XQ6jh49apPnh4SEkJGRgZ2dncnn8Pb2rtf+2Nvbm/3Z33TTTUybNo3o6Gjuu+8+1q5da/WzrSFBkhBCiDpzDgvFzs8Pqtq+rlJh5+eHc1hovbQ/cOBA9u/fT2JiomEkCcqDpFWrVlFUVGQUJA0aNIjDhw+zYcMGTp48yezZszl27JjRM9u1a8dPP/3E6dOnycnJsWgKC+C1115jw4YNzJkzh+PHj5OcnMyXX37JK6+8YpsPe5Xnn3+ehQsX8u9//5sTJ04wZcoUzp8/b5M0AuHh4fTu3ZvRo0ezY8cOTp8+zcGDB3nllVeq3FVmq/60a9eOXbt2kZGRwfnz57l8+TLPPfccsbGxpKamcuDAAQ4dOkSXLl3q/DmrI0FSE6fT6ziUcYhtf2zjUMYhdPr6yzcihBC1pdJo0M6aeeVNpS/EK++1s2ai0tTPLt2BAwdy+fJlOnbsiFb797FN/fv35+LFi3To0MFod9qQIUN49dVXeemll+jRowcXL15k7NixRs+cPn06Go2G4OBgfHx8SEtLs6gvQ4YM4fvvv2fnzp306NGD22+/nbfffpu2bdva5sNeJSoqiocffpixY8fSu3dvXF1dGTJkiNG0Xm2pVCq2bdtGv379mDhxIjfddBMPPfQQp0+fNvoZ10d/3nrrLXbu3ElgYCC33XYbGo2Gc+fOMXbsWG666SYeeOABhg0bxty5c+v8OaujUiydvBRG8vPzcXd3Jy8vDzc3t3ppIyY1hkXxi8gs/PswW62zlhk9ZxDeNrxe2hRCXL+KiopISUkhKCio1l+y+dHRZL6x0GgRt52fH9pZM3GLiLBVV0UV9Ho9Xbp04YEHHmD+/PmN3Z1G6091v8vWfH/Lwu0mKiY1hsjYSBSMY9iswiwiYyN5e8DbEigJIZoct4gIWg4eXL7bLTsbOx8fnMNC620E6XqXmppKdHQ0/fv3p7i4mA8++ICUlBQeeeQR6Y8NSJDUBOn0OhbFLzIJkAAUFFSoWBy/mIGBA9FIgkkhRBOj0mhsvs1fmKdWq1m3bh3Tp09HURS6du1KTExMva/VaS79qSsJkpqghKwEoym2yhQUMgozSMhKoIdfjwbsmRBCiKYkMDCQAwcONHY3DJpaf+pKFm43QdmFluURsbSeEEIIIawnQVIT5ONsWR4RS+sJIYQ1ZD+PaO5s9TssQVITFOIbgtZZiwrzeSVUqPBz9iPEN6SBeyaEuJZVZEEuLCxs5J4IUTcVv8N1PQC30dckLV++nKVLl5Kens7NN9/MsmXL6Nu3b5X19+7dS2RkJMePHycgIICXXnqJyZMnG65v3ryZN954g1OnTlFaWsqNN97Iiy++yOOPP16ndhuSRq1hRs8ZRMZGokJltIC7InCK6hkli7aFEDal0Wjw8PAwnKHl7Oxsk6SEQjQURVEoLCwkKysLDw8PNHXcVdmoQdKXX37J1KlTWb58OXfccQcfffQRw4YNIykpiTZt2pjUT0lJYfjw4UyaNImNGzdy4MABnnnmGXx8fBgzZgwArVq14uWXX6Zz5844ODjw/fffM2HCBHx9fRkyZEit2m0M4W3DeXvA22bzJEX1jKrT9n+dXiE+JZesi0X4tnSiZ1ArNGr5i1AIUX7eGVDjYaNCNGUeHh6G3+W6aNRkkr169SIkJIQVK1YYyrp06cLo0aNZuHChSf2oqCi2bNlCcnKyoWzy5Mn8/PPPxMXFVdlOSEgII0aMMCSysrZdcxoimSSUpwNIyEoguzAbH2cfQnxD6jSCtP1YOnO3JpGeV2Qo83d3YvbIYIZ29bdFl4UQ1wCdTmfVga9CNBX29vbVjiA1i2SSJSUlHDlyhBkzZhiVR0REcPDgQbP3xMXFEVEpY+uQIUNYvXo1paWlJnOPiqKwe/duTpw4weLFi2vdLkBxcTHFxcWG9/n5+TV/SBvQqDU22+a//Vg6T29MMMm+lJFXxNMbE1jxWIgESkIIoHzqra5TFUI0d422cDsnJwedTmdy/otWqyXjqnT2V8vIyDBbv6ysjJycHENZXl4erq6uODg4MGLECN5//33uuuuuWrcLsHDhQtzd3Q2vq88Aag50eoW5W5PMpKfEUDZ3axI6vexqEUIIIaAJ7G6rvChQUZRqFwqaq1+5vGXLliQmJnLo0CFef/11IiMjiY2NrVO7M2fOJC8vz/A6c+ZMtZ+rqYlPyTWaYqtMAdLziohPyW24TgkhhBBNWKNNt3l7e6PRaExGb7Kysqo8XdjPz89sfTs7O7y8vAxlarWajh07AtC9e3eSk5NZuHAhAwYMqFW7AI6Ojjg6Olr1GZuSrItVB0i1qSeEEEJc6xptJMnBwYHQ0FB27txpVL5z50769Olj9p7evXub1I+OjiYsLKzaXAiKohjWE9Wm3aZO0em4FPcjWcveJWvZu1yKi0PR6Yzq+La07ERvS+sJIYQQ17pGTQEQGRnJ448/TlhYGL179+bjjz8mLS3NkPdo5syZnD17lg0bNgDlO9k++OADIiMjmTRpEnFxcaxevZpNmzYZnrlw4ULCwsLo0KEDJSUlbNu2jQ0bNhjtZKup3eYkPzqa9Ndmo79wwVB2buVK1B4e+M+bi9uVhe49g1rh7+5ERl6R2XVJKsDPvTwdgBBCCCEaOUh68MEHOXfuHPPmzSM9PZ2uXbuybds22rZtC0B6ejppaWmG+kFBQWzbto1p06bx4YcfEhAQwHvvvWfIkQRQUFDAM888w59//kmLFi3o3LkzGzdu5MEHH7S43aamqjQA+dHRnH1hitl79BculF97713cIiLQqFXMHhnM0xsTUIFRoFSxEmv2yGDJlySEEEJc0ah5kpqzhsqTFJMaYzah5IzQl2gz4Q10mZnV3A12fn503BWD6spWXsmTJIQQ4npmzfe3BEm11BBBUkxqDJGxkUbHkkD50STBqXpmf66r4k5jbdavx6VXT8N7ybgthBDietUskkmK6un0OhbFLzIJkAAUFDwuWf6ssuxso/catYreHbyqqC2EEEIIaAJ5koR5CVkJRlNslZ13tXwA0M7HxxZdEkIIIa4rEiQ1UdmF2dVeTw5UkeOK2Z1qV7Pz88M5LNR2HRNCCCGuExIkNVE+ztWP/ihqFesiav7j086aaVi0LYQQQgjLSZDURIX4hqB11qLC/IJqFSrSbgsg4N13UHt4mFzXeHjQ+sr2fyGEEEJYTxZuN1EatYYZPWcQGRuJCpXRAu6KwCmqZxQebcNxD7+LgvhDFP70EwDOvXri0rOnjCAJIYQQdSApAGqpMfMk+Tn7EdUzivC24fXWrhBCCHEtkhQA15DwtuEMDBxoNuO2EEIIIeqPBEnNgEatoYdfj8buhhBCCHFdkYXbQgghhBBmSJAkhBBCCGGGBElCCCGEEGZIkCSEEEIIYYYESUIIIYQQZkiQJIQQQghhhgRJQgghhBBmSJAkhBBCCGGGJJNsDvQ6SD0IlzLBVQtt+4Bk3BZCCCHqlQRJTV3SFtgeBfl//V3mFgBDF0PwPY3XLyGEEOIaJ9NtTVnSFvhqrHGABJCfXl6etKVx+iWEEEJcByRIaqr0uvIRJBQzF6+UbZ9RXk8IIYQQNidBUlOVetB0BMmIAvlny+sJIYQQwuYkSGqqLmXatp4QQgghrCJBUlPlqrVtPSGEEEJYRYKkpqptn/JdbKiqqKACt9bl9YQQQghhc1YHSbGxsfXQDWFCrSnf5g+YBkpX3g9dJPmShBBCiHpidZA0dOhQOnTowIIFCzhz5kx99ElUCL4HHtgAbv7G5W4B5eWSJ0kIIYSoNypFUcztMa9Sbm4uGzduZN26dfzyyy8MHjyYJ554gtGjR+Pg4FBf/Wxy8vPzcXd3Jy8vDzc3t/ptTDJuCyGEEDZhzfe31UHS1RITE1mzZg2bNm1Cr9fz6KOP8sQTT3DrrbfW9pHNRoMGSUIIIYSwCWu+v+u0cLt79+7MmDGDZ599loKCAtasWUNoaCh9+/bl+PHjdXm0EEIIIUSjqlWQVFpaytdff83w4cNp27YtO3bs4IMPPiAzM5OUlBQCAwP5xz/+Yeu+CiGEEEI0GKuDpOeffx5/f38mT57MTTfdxNGjR4mLi+PJJ5/ExcWFwMBAFi1axP/+9z+Lnrd8+XKCgoJwcnIiNDSUffv2VVt/7969hIaG4uTkRPv27Vm5cqXR9VWrVtG3b188PT3x9PQkPDyc+Ph4ozpz5sxBpVIZvfz8/Kz7QQghhBDimmZ1kJSUlMT777/PX3/9xbJly+jatatJnYCAAPbs2VPjs7788kumTp3Kyy+/zNGjR+nbty/Dhg0jLS3NbP2UlBSGDx9O3759OXr0KLNmzeKFF17gm2++MdSJjY3l4YcfZs+ePcTFxdGmTRsiIiI4e/as0bNuvvlm0tPTDa9ff/3Vyp9Ew9LpdRzKOMS2P7ZxKOMQOjmzTQghhKhXdVq4XVe9evUiJCSEFStWGMq6dOnC6NGjWbhwoUn9qKgotmzZQnJysqFs8uTJ/Pzzz8TFxZltQ6fT4enpyQcffMDYsWOB8pGk7777jsTExFr3vSEXbsekxrAofhGZhX8fQaJ11jKj5wzC24bXa9tCCCHEtaReF24vXLiQNWvWmJSvWbOGxYsXm7nDvJKSEo4cOUJERIRReUREBAcPmj+0NS4uzqT+kCFDOHz4MKWlpWbvKSwspLS0lFatWhmVnzx5koCAAIKCgnjooYf4448/qu1vcXEx+fn5Rq+GEJMaQ2RspFGABJBVmEVkbCQxqTEN0g8hhBDiemN1kPTRRx/RuXNnk/Kbb77ZZH1QdXJyctDpdGi1xmePabVaMjIyzN6TkZFhtn5ZWRk5OTlm75kxYwatW7cmPPzvEZdevXqxYcMGduzYwapVq8jIyKBPnz6cO3euyv4uXLgQd3d3wyswMNDSj1prOr2ORfGLUDAd7KsoWxy/WKbehBBCiHpgdZCUkZGBv7+/SbmPjw/p6elWd0ClMj5yQ1EUk7Ka6psrB1iyZAmbNm1i8+bNODk5GcqHDRvGmDFj6NatG+Hh4fzwww8ArF+/vsp2Z86cSV5enuHVENnGE7ISTEaQrqagkFGYQUJWQr33RQghhLje2Fl7Q2BgIAcOHCAoKMio/MCBAwQEBFj8HG9vbzQajcmoUVZWlsloUQU/Pz+z9e3s7PDy8jIqf/PNN3njjTeIiYnhlltuqbYvLi4udOvWjZMnT1ZZx9HREUdHx2qfY2vZhdk2rSeEEEIIy1k9kvTkk08ydepU1q5dS2pqKqmpqaxZs4Zp06YxadIki5/j4OBAaGgoO3fuNCrfuXMnffqYP9m+d+/eJvWjo6MJCwvD3t7eULZ06VLmz5/P9u3bCQsLq7EvxcXFJCcnmx0ha0w+zj42rSeEEEIIy1k9kvTSSy+Rm5vLM888Q0lJCQBOTk5ERUUxc+ZMq54VGRnJ448/TlhYGL179+bjjz8mLS2NyZMnA+VTXGfPnmXDhg1A+U62Dz74gMjISCZNmkRcXByrV69m06ZNhmcuWbKEV199lc8//5x27doZRp5cXV1xdXUFYPr06YwcOZI2bdqQlZXFggULyM/PZ9y4cdb+OOpViG8IWmctWYVZZtclqVChddYS4hvSCL0TQgghrm21TgFw6dIlkpOTadGiBTfeeGOtp6KWL1/OkiVLSE9Pp2vXrrzzzjv069cPgPHjx3P69GliY2MN9ffu3cu0adM4fvw4AQEBREVFGYIqgHbt2pGammrSzuzZs5kzZw4ADz30EP/973/JycnBx8eH22+/nfnz5xMcHGxxvxsqBUDF7jbAKFBSUb4G6+0Bb0saACGEEMJCDXbA7fWssfMkeTp68srtrxDRLqKaO4UQQghxNWu+v62ebisoKGDRokXs2rWLrKws9Hq90fWa8g0J64W3DUev6Fnw4wLOF58H4HzxeZYcWoJapbb5SJJOrxCfkkvWxSJ8WzrRM6gVGnXVOw6FEEKIa5HVQdKTTz7J3r17efzxx/H39692u76wjZjUGKbvnW6yLqkioaQtp9y2H0tn7tYk0vOKDGX+7k7MHhnM0K5Na2G7EEIIUZ+snm7z8PDghx9+4I477qivPjULDTXdptPrGPLNkCrzJVUs3t4+ZjsataZObW0/ls7TGxNMlohXhMErHguRQEkIIUSzVq/Hknh6epoc8SHqT0MllNTpFeZuTTKzhw5D2dytSej0soRNCCHE9cHqIGn+/Pm89tprFBYW1kd/RCUNlVAyPiXXaIqtMgVIzysiPiW3Tu0IIYQQzYXVa5Leeustfv/9d7RaLe3atTNK4giQkCBHZNiSxQklneo2upd1seoAqTb1hBBCiObO6iBp9OjR9dANUZUaE0oqClqdjpAvJsDQxRB8T63a8W3pVHMlK+oJIYQQzZ3kSaqlhs6TZDah5JU/urezcggvvDLC88CGWgVKOr3CnYt3k5FXZHZdkgrwc3dif9QgSQcghBCi2arXhdsAFy5c4JNPPmHmzJnk5pavUUlISODs2bO1eZyoQXjbcN4e8Da+zr5G5Vqd7kqAdBnD8urtM0Cvs7oNjVrF7JHlGccrh0AV72ePDJYASQghxHXD6pGkX375hfDwcNzd3Tl9+jQnTpygffv2vPrqq6SmphrOWbvWNeRIUgXdH3tJ+OofZGs0+Oh0hBQVY3bT/7jvIahvrdqQPElCCCGuZfWacTsyMpLx48ezZMkSWrZsaSgfNmwYjzzyiPW9FRbTFGTTo6i45oqXqk4ZUJOhXf25K9hPMm4LIYS47lkdJB06dIiPPvrIpLx169ZkZGTYpFOiCq5a29argkatoncHrzo9QwghhGjurA6SnJycyM/PNyk/ceIEPj6WbVcXtdS2D7gFQH46oKADEpwcjaffWgaU1xNCCCFEnVi9cHvUqFHMmzeP0tJSAFQqFWlpacyYMYMxY8bYvIPiKmpN+TZ/IMbZmSGBAUz01xLl681Efy1DAgOI0ZTC/35o5I4KIYQQzZ/VQdKbb75JdnY2vr6+XL58mf79+9OxY0datmzJ66+/Xh99FFcLvoeY8Cgifb3I1Bgv287SaIj0cCLm+6cgaUsjdVAIIYS4NtQ6T9Lu3btJSEhAr9cTEhJCeLhtTqFvLhpjdxtcdeBtQQaoTBdTVySX3J6nQjP11/LRJyGEEEIA9by7rcKgQYMYNGhQbW8XtWQ48NZMgASgqFRk2NmRUJJJj9SDtU4FIIQQQlzvrA6S5s2bV+311157rdadETWz+MBbjaZOqQCEEEKI653VQdK3335r9L60tJSUlBTs7Ozo0KGDBEn1zOIDb3W6OqcCEEIIIa5nVgdJR48eNSnLz89n/Pjx3HvvvTbplKia4cDbggyUatYkhTh4SyoAIYQQog5qdXZbZW5ubsybN49XX33VFo8T1dCoNczoOQNUKsMBtxUq3kedu4Bm6CJZtC2EEELUgU2CJCg/9DYvL89WjxPVKD/w9h18HdyNyrU6HW9f0hN+90cQfE8j9U4IIYS4Nlg93fbee+8ZvVcUhfT0dD799FOGDh1qs46J6oW3DWdg4EASMg6RfeYgPjo9IX490LS7U0aQhBBCCBuwOk9SUFCQ0Xu1Wo2Pjw+DBg1i5syZRofeXssaK0+SEEIIIWqvXvMkpaSk1LpjQgghhBDNhc3WJAkhhBBCXEusHkm69957UVWR7bmyzZs3W90hIYQQQoimwOqRJHd3d3bt2sXhw4cNZUeOHGH37t24ubnh7u5ueAkhhBBCNFdWjyRptVoeeOABVq5ciebKKfQ6nY5nnnkGNzc3li5davNOCiGEEEI0NKt3t/n4+LB//346depkVH7ixAn69OnDuXPnbNrBpkp2twkhhBDNjzXf31ZPt5WVlZGcnGxSnpycjF6vt/ZxQgghhBBNktVB0oQJE5g4cSJvvvkm+/fvZ//+/bz55ps8+eSTTJgwweoOLF++nKCgIJycnAgNDWXfvn3V1t+7dy+hoaE4OTnRvn17Vq5caXR91apV9O3bF09PTzw9PQkPDyc+Pr7O7QohhBDiOqNYSafTKYsXL1YCAgIUlUqlqFQqJSAgQFm8eLFSVlZm1bO++OILxd7eXlm1apWSlJSkTJkyRXFxcVFSU1PN1v/jjz8UZ2dnZcqUKUpSUpKyatUqxd7eXvn6668NdR555BHlww8/VI4ePaokJycrEyZMUNzd3ZU///yz1u2ak5eXpwBKXl6eVZ9ZCCGEEI3Hmu9vq9ckXS0/Px+g1mtyevXqRUhICCtWrDCUdenShdGjR7Nw4UKT+lFRUWzZssVoum/y5Mn8/PPPxMXFmW1Dp9Ph6enJBx98wNixY2vVrjmyJkkIIYRofup1TRKUr0uKiYlh06ZNhpxJf/31F5cuXbL4GSUlJRw5coSIiAij8oiICA4ePGj2nri4OJP6Q4YM4fDhw5SWlpq9p7CwkNLSUlq1alXrdgGKi4vJz883egkhhBDi2mV1kJSamkq3bt0YNWoUzz77LNnZ2QAsWbKE6dOnW/ycnJwcdDodWq3WqFyr1ZKRkWH2noyMDLP1y8rKyMnJMXvPjBkzaN26NeHh4bVuF2DhwoVGOaACAwNr/IxCCCGEaL6sDpKmTJlCWFgY58+fp0WLFobye++9l127dlndgcrZuxVFqTajt7n65sqhPHDbtGkTmzdvxsnJqU7tzpw5k7y8PMPrzJkzVdYVQgghRPNndTLJ/fv3c+DAARwcHIzK27Zty9mzZy1+jre3NxqNxmT0Jisry2SUp4Kfn5/Z+nZ2dnh5eRmVv/nmm7zxxhvExMRwyy231KldAEdHRxwdHS36bE2VotNRePgIZdnZ2Pn44BwWiupKQlAhhBBCGLN6JEmv16PT6UzK//zzT1q2bGnxcxwcHAgNDWXnzp1G5Tt37qRPnz5m7+ndu7dJ/ejoaMLCwrC3tzeULV26lPnz57N9+3bCwsLq3O61ID86mlODw0kbN46/pk8nbdw4Tg0OJz86urG7JoQQQjRJVgdJd911F8uWLTO8V6lUXLp0idmzZzN8+HCrnhUZGcknn3zCmjVrSE5OZtq0aaSlpTF58mSgfIqrYkcalO9kS01NJTIykuTkZNasWcPq1auN1kItWbKEV155hTVr1tCuXTsyMjLIyMgwWlReU7vXmvzoaM5OmUpZpdGzsowMzr4wRQIlIYQQwgyrUwCcPXuWQYMGodFoOHnyJGFhYZw8eRJvb2/++9//4uvra1UHli9fzpIlS0hPT6dr166888479OvXD4Dx48dz+vRpYmNjDfX37t3LtGnTOH78OAEBAURFRRkFN+3atSM1NdWkndmzZzNnzhyL2rVEc0kBoOh0nBocbhIgXU3t4cFNB/bL1JsQQohrnjXf37XKk3T58mW++OILjhw5gl6vJyQkhEcffdRoIfe1rrkESQU/xZM2blyN9byffx6fZ59pgB4JIYQQjcea72+rFm6XlpbSqVMnvv/+eyZMmFCrY0hEwyq7kqKhJrmffor35KdkNEkIIYS4wqo1Sfb29hQXF1e7VV40LXY+PhbV01+4QOHhI/XcGyGEEKL5sHrh9vPPP8/ixYspKyurj/4IG3MOC0Xt7m5RXUtHnYQQQojrgdV5kn766Sd27dpFdHQ03bp1w8XFxej65s2bbdY5UXcqjYZWYx8n5/0Paqxr6aiTtXR6hfiUXLIuFuHb0omeQa3QqGU0UgghRNNmdZDk4eHBmDFj6qMvop54T55M7qcb0V+4YL6CSoWdVotzWKjN295+LJ25W5NIzysylPm7OzF7ZDBDu/rbvD0hhBDCVize3bZ792769euHnZ3VcdU1qbnsbqtQkSuJyn/cV9aXtX53GW6VDv2tq+3H0nl6YwKVf8EqxpBWPBYigZIQQogGZc33t8Vrku666y5yc3MN72+//XarjiERjcstIoLW7y7Dzs/PqNxOq62XAEmnV5i7NckkQAIMZXO3JqHTW52BQgghhGgQFg8LVR5wOn78OMXFxTbvkKg/bhERtBw8uEHOb4tPyTWaYqtMAdLziohPyaV3B68q6wkhhBCNRebOrjMqjQaXXj3rvZ2si1UHSLWpJ4QQQjQ0i6fbVCqVUX6kyu+FuJpvSyeb1hNCCCEamlXTbYMHDzYs3C4sLGTkyJE4ODgY1UtISLBtD0Wz1DOoFf7uTmTkFZldl6QC/NzL0wEIIYQQTZHFQdLs2bON3o8aNcrmnRHXDo1axeyRwTy9MQEVGAVKFeOPs0cGS74kIYQQTVatDrgVzS8FQGORPElCCCGakno74FYIaw3t6s9dwX6ScVsIIUSzI0GSqHcatUq2+QshhGh2rD7gVgghhBDieiBBkhBCCCGEGRIkCSGEEEKYUas1SfHx8cTGxpKVlYVerze69vbbb9ukY0IIIYQQjcnqIOmNN97glVdeoVOnTmi1WpMs3EIIIYQQ1wKrg6R3332XNWvWMH78+HrojhBCCCFE02D1miS1Ws0dd9xRH30RQgghhGgyrA6Spk2bxocfflgffRFCCCGEaDKsnm6bPn06I0aMoEOHDgQHB2Nvb290ffPmzTbrnBBCCCFEY7E6SHr++efZs2cPAwcOxMvLSxZrCyGEEOKaZHWQtGHDBr755htGjBhRH/0RQgghhGgSrF6T1KpVKzp06FAffRFCCCGEaDKsDpLmzJnD7NmzKSwsrI/+CCGEEEI0CVZPt7333nv8/vvvaLVa2rVrZ7JwOyEhwWadE0IIIYRoLFYHSaNHj66HbgghhBBCNC1WBUllZWUATJw4kcDAwHrpkBBCCCFEU2DVmiQ7OzvefPNNdDqdzTqwfPlygoKCcHJyIjQ0lH379lVbf+/evYSGhuLk5ET79u1ZuXKl0fXjx48zZswY2rVrh0qlYtmyZSbPmDNnDiqVyujl5+dns8/UWHR6HYcyDrHtj20cyjiETm+7PychhBDiemP1wu3BgwcTGxtrk8a//PJLpk6dyssvv8zRo0fp27cvw4YNIy0tzWz9lJQUhg8fTt++fTl69CizZs3ihRde4JtvvjHUKSwspH379ixatKjawOfmm28mPT3d8Pr1119t8pkaS0xqDEO+GcLEHROJ2hfFxB0TGfLNEGJSYxq7a0IIIUSzpFIURbHmho8++og5c+bw6KOPEhoaiouLi9H1e+65x+Jn9erVi5CQEFasWGEo69KlC6NHj2bhwoUm9aOiotiyZQvJycmGssmTJ/Pzzz8TFxdnUr9du3ZMnTqVqVOnGpXPmTOH7777jsTERIv7Wll+fj7u7u7k5eXh5uZW6+fYQkxqDJGxkSgY/1GqKE/0+faAtwlvG94YXRNCCCGaFGu+v61euP30008D8Pbbb5tcU6lUFk/FlZSUcOTIEWbMmGFUHhERwcGDB83eExcXR0REhFHZkCFDWL16NaWlpSY77apz8uRJAgICcHR0pFevXrzxxhu0b9/e4vubCp1ex6L4RSYBEoCCggoVi+MXMzBwIBq1phF6KIQQQjRPVk+36fX6Kl/WrFXKyclBp9Oh1WqNyrVaLRkZGWbvycjIMFu/rKyMnJwci9vu1asXGzZsYMeOHaxatYqMjAz69OnDuXPnqrynuLiY/Px8o1dTkJCVQGZhZpXXFRQyCjNIyJLUDEIIIYQ1rA6SrlZUVFTnDlQ++01RlGrPgzNX31x5dYYNG8aYMWPo1q0b4eHh/PDDDwCsX7++ynsWLlyIu7u74dVUdvdlF2bbtJ4QQgghylkdJOl0OubPn0/r1q1xdXXljz/+AODVV19l9erVFj/H29sbjUZjMmqUlZVlMlpUwc/Pz2x9Ozs7vLy8rPwkf3NxcaFbt26cPHmyyjozZ84kLy/P8Dpz5kyt27MlH2cfm9YTQgghRDmrg6TXX3+ddevWsWTJEhwcHAzl3bp145NPPrH4OQ4ODoSGhrJz506j8p07d9KnTx+z9/Tu3dukfnR0NGFhYVatR6qsuLiY5ORk/P39q6zj6OiIm5ub0aspCPENQeusNSzSNsfDwZ0Q35AG7JUQQgjR/FkdJG3YsIGPP/6YRx99FI3m74XAt9xyC//73/+selZkZCSffPIJa9asITk5mWnTppGWlsbkyZOB8tGbsWPHGupPnjyZ1NRUIiMjSU5OZs2aNaxevZrp06cb6pSUlJCYmEhiYiIlJSWcPXuWxMRETp06Zagzffp09u7dS0pKCj/99BP3338/+fn5jBs3ztofR6PTqDXM6DnD7MJtABSFC8UX2HNwScN2TAghhGjmrN7ddvbsWTp27GhSrtfrKS0ttepZDz74IOfOnWPevHmkp6fTtWtXtm3bRtu2bQFIT083ypkUFBTEtm3bmDZtGh9++CEBAQG89957jBkzxlDnr7/+4rbbbjO8f/PNN3nzzTfp37+/Ib/Tn3/+ycMPP0xOTg4+Pj7cfvvt/Pjjj4Z2m5uBgQNxd3QnrzjP9KJKhUpRWHxiAwM9u6C5eXSD908IIYRojqzOkxQWFsbUqVN57LHHaNmyJT///DPt27dn7ty5xMTE1Jgx+1rRlPIkHco4xMQdE2ustyZPR4/nfoVmngpAp1eIT8kl62IRvi2d6BnUCo3a8oX7Qgghrl/1kidp4sSJvPvuu8yePZvHH3+cs2fPotfr2bx5MydOnGDDhg18//33de68sJ7FO9yKz0PqQQjqW889qj/bj6Uzd2sS6Xl/76z0d3di9shghnatek2ZEEIIYS2L1yStX7+ey5cvM3LkSL788ku2bduGSqXitddeIzk5ma1bt3LXXXfVZ19FFSze4abTwaWqcyo1dduPpfP0xgSjAAkgI6+IpzcmsP1YeiP1TAghxLXI4pGkq2flhgwZwpAhQ+qlQ8J6Ib4haB08yCo+j2ImX5RKUdDqdIQUFcO53xuhh3Wn0yvM3Zpkdnm6AqiAuVuTuCvYT6behBBC2IRVu9usSdgoGo5GrWFG71eB8oDoahXvo86dRwOQsB70lmdGbyriU3JNRpCupgDpeUXEp+Q2XKeEEEJc06za3XbTTTfVGCjl5sqXVGMIbxfB2779WZS+m0y7v/9YtTodUefOE154ubwg/2yzXJeUddGy7O6W1hNCCCFqYlWQNHfuXNzd3eurL6KOwgMHMjB+IwlOjmRrNPhcmWIz2ctm5bokRaej8PARyrKzsfPxwTksFJWmYXfI+bZ0smk9IYQQoiZWBUkPPfQQvr6+9dUXUVeuWjRAj6Li6us5e1v8yPzoaDLfWEjZVcfBqN3daTX2cbwnT26wYKlnUCv83Z3IyCuqKm0mHs729Axq1SD9EUIIce2zeE2SrEdqBtr2AbcAqOaIEgD+/TQkbanxcfnR0ZydMtUoQALQ5+WR8/4H/HbHneRHR9ehw5bTqFXMHhlcZYAEcKGwlJ1JGdXUEEIIISxncZBkZc5J0RjUGhi6+MqbagKl/HT4amy1gZKi05H5xkKo5s9df+ECZ6dMbbBA6a5gPzycqz6jr2KHm04vv6tCCCHqzuIgSa/Xy1RbcxB8DzywAVr6VVPpShCxfUaVO90KDx8xGUEy/yiFzDcWoujqf8dcfEouFwqrPvpGdrgJIYSwJasPuBXNQPA9cO9HNVRS/t7pZkZZtmVZvAHKMjLIfv8DCn6Kr9dgSXa4CSGEaEgSJF2rCiwMcqrY6WbnY1kW7wrnVq4kbdw4Tg0Or7fpN9nhJoQQoiFJkHStctXWqZ5zWCh2ftVN2ZlXlplZb+uUKna4VbXaSkX5OW6yw00IIYQtSJB0rapxp5sK3FqX1zN3VaNBO2um9e0qCigK6bPnkLdlq02n4Cp2uIHpp6p4P3tksBxLIoQQwiYkSLpWVbvT7cr7oYvK61XBLSKC1u+9i9rDw+rm9efP89dLL9l8Cm5oV39WPBaCn7vxlJqfuxMrHgthaFd/m7QjhBBCqBTZ218r+fn5uLu7k5eXh5ubW2N3p2pJW2B7FOT/9XeZW+vyACn4Hoseoeh05Kz8iNwNG9Dn5Vnfhys5tlq/uwy3iAjr7zdDp1eIT8kl62IRvi3Lp9hkBEkIIURNrPn+liCplppNkATl2/xTD5Yv0nbVlk+xVTOCVJWK40kK4uI4t3KldTerVNhptXTcFdPgR5oIIYQQFaz5/rbqWBLRTKk1NjnQVqXR4NKrJ85hoeR99x1lmZnVJps0oiiUZWRQePgILr161rkvQgghRH2TNUnCakaLuq08rsaa/EtCCCFEY5IgSdSKW0QErd9dhp3WwlQDV2i8vOqpR+bp9Apxv5/j34lnifv9nBxZIoQQwmKyJqmWmtWapHpUsU6pNDOTrIUL0V24UO0UnJ1Wi/blWTZbwF2d7cfSmbs1ifS8vzNw+7s7MXtksOyCE0KI65Q1398ykiTqpGKdksc9I/GbO+dKYdVTcGVZWQ1yKO72Y+k8vTHBKEACyMgr4umNCWw/ll6v7QshhGj+JEgSNlMxBaep7iDkK6NM9Xkork6vMHdrEubGsyrK5m5Nkqk3IYQQ1ZIgSdiUW0QEAYsWVl/pqp1u9SE+JddkBMmoeSA9r4j4lNx6aV8IIcS1QYIkYXO6c5YFH/W10y3rYtUBUm3qCSGEuD5JnqTrmY2STFZm5+Nj03rW8m3pVHMlK+oJIYS4PkmQdL0ye1xJQPl5bxYeV1IV57BQ7Pz8qk42eSX7tnNYaJ3aqUrPoFb4uzuRkVdkdl2SivKz3noGtaqX9oUQQlwbZLrtepS0Bb4aaxwgQfn7rx4vv14H1SabvPJeO2tmvR1PolGrmD0yuLw5M9cVYHhXP+JTcmXxthBCiCpJnqRaarZ5kvQ6WNYVXf5fJDg5kq3R4KPTEVJUjCFkcfKEl36v89RbfnQ0mW8spCwjw1Bm5+eHdtbMRsuTpFbB1XGR5E0SQojrixxw2wCabZCUso+Yf/2DRV6eZNr9PduqLStjxrnzhBdeLi+4+T74x9o6N1eRbLIsOxs7Hx+cw0Ib9IBbnV4hPiWXnUkZrDlwusp6Kx8LkUBJCCGuA5JMUlQp5kwskb7eZFYKVLI0GiJ9vYlxblFecHwzHP+uzu1VJJt0v3sELr16NmiABOVTbz2DWvGfYxnV1pux+VeZehNCCGFEgqTriE6vY9HZ6PLFzJXWCilX3i/28sSQ4vGHF8un55q5mvImAVwoLOW9XScbqEdCCCGag0YPkpYvX05QUBBOTk6Ehoayb9++auvv3buX0NBQnJycaN++PStXrjS6fvz4ccaMGUO7du1QqVQsW7bMJu1eCxKyEsgsuVDlsSGKSkWGnR0JTo7lBYU55SkCmjlL8yG9t+sk236R40qEEEKUa9Qg6csvv2Tq1Km8/PLLHD16lL59+zJs2DDS0tLM1k9JSWH48OH07duXo0ePMmvWLF544QW++eYbQ53CwkLat2/PokWL8PPzs0m714rsQsuSN2ZfPSV2KbOeetNwLM2HpADPfC7nugkhhCjXqAu3e/XqRUhICCtWrDCUdenShdGjR7NwoenRFlFRUWzZsoXk5GRD2eTJk/n555+Ji4szqd+uXTumTp3K1KlT69SuOc1x4fahjENM3DGxxnpr0jPpUVRc/mbc9xDUt557Vr90eoXQ+Tu5cLnUovr+7k7sjxqERl31Qb1CCCGap2axcLukpIQjR44QUWkreEREBAcPmp/iiYuLM6k/ZMgQDh8+TGmpZV+AtWkXoLi4mPz8fKNXcxPiG4LWWYvKbPYgQFFw1+nQQfm6JLfW5Vm464Gi01HwUzx53/9AwU/x9XbYLZQv3p5wRzuL68u5bkIIIaARg6ScnBx0Oh1ardaoXKvVkpFhfidSRkaG2fplZWXk5OTUW7sACxcuxN3d3fAKDAy0qL2mRKPWMKPnDADTQElRQKUiT6Nhkr+WIYEBxPR83CbHlFSWHx3NqcHhpI0bx1/Tp5M2bhynBoeTHx1t87YqPDfoRpwdLP8scq6bEEKIRl+4raq8y0pRTMpqqm+u3Nbtzpw5k7y8PMPrzJkzVrXXVIS3DeftAW/j6+xbbb0sOzsif99ETGqMTdvPj47m7JSpRgkmAcoyMjj7whSyP/ywXkaVNGoVT/Vrb3F9OddNCCFEowVJ3t7eaDQak9GbrKwsk1GeCn5+fmbr29nZ4eXlVW/tAjg6OuLm5mb0aq7C24azY8wOPon4BHcH9/LCykEjoKCwOH4xOhulAVB0OjLfWGj+PLcrct7/gFODBtfLqNJzg27EvUXNxxX6y7luQgghaMQgycHBgdDQUHbu3GlUvnPnTvr0Mb8Opnfv3ib1o6OjCQsLw97evt7avRZp1BrUKjV5JXnV1ssozCAhK8EmbRYePmIygmROWWYmZ6dMtXmgpFGrWDzmlhrrzR4ZLIu2hRBCNO50W2RkJJ988glr1qwhOTmZadOmkZaWxuTJk4HyKa6xY8ca6k+ePJnU1FQiIyNJTk5mzZo1rF69munTpxvqlJSUkJiYSGJiIiUlJZw9e5bExEROnTplcbvXC0tTArx56E2btFeWbVl7ACgK6bPnoC8psUnbFYZ29WflYyF4OJsG1Z7O9maPJykp07N63x+89u9jrN73ByVlepv2SQghRNPU6Ge3LV++nCVLlpCenk7Xrl1555136NevHwDjx4/n9OnTxMbGGurv3buXadOmcfz4cQICAoiKijIKbk6fPk1QUJBJO/379zd6TnXtWqI5pgCozNKUAADjgscxvcf0mitWo+CneNLGjbPqHo2nJ35z59j8QFydXuHH388R90cOoKJ3By9ub+9lMoK0cFsSq/alGB2KqwLuvsWPZQ+FyIiTEEI0M3LAbQO4FoIknV7HwK8Gcr74vEX1jzx6BAc7h1q3p+h0/NbnDvR51U/xmVCpaP3uMpsHSjVZuC2Jj/6bUuV1FwcNbz1wqxyMK4QQzUizyJMkGp9GreHu9ndbXH9+3Nw6tafSaGg19nHrb1QU/po5i8x33uFSXFy95lSqUFKmZ9W+qgMkgIISHZM3JjD9q0S+PXqWuN/PySG5QghxDZGRpFq6FkaSwLopN2e9wsGeC9DcPLrW7Sk6Hb/dcSf6Cxdq/Qy1hwf+8+bW68jS6n1/MP+H5JorVuLv7sTskcEyuiSEEE2UjCQJi4X4huBq72pR3UK1ioStT0HSllq3p9Jo8J83t8pDdi2hv3CBsy9Mqdfkk6m5hbW6Lz2viKc3yvlvQghxLZAg6TqnUWuY3Xu2xfX3OLeA7TOgDrmT3CIiaP3uMuyqOIDYUplvLKy3qbe2rZzrdP/crUky9SaEEM2cBEmCoUFD6e7T3aK637s6o8s/C6lVn3NnCbeICDruiqHN+vX4LVqEumVLq59RlpFB4eEjdepHVR7v3Y7ablxTkPPfhBDiWiBBkgBg3dB1OKoda6x3XqNhlYcbJG+BlH11GlFSaTS49OqJ5+hR+L++oHwKzsppOKtyL1nBwU7NpL6mqSSsIee/CSFE8yZBkgDKp90e6PSARXU/9HAn+tinsP5uWNoeYhfXKViCq6bgqjkaxhw7H586tVudmcODeapfUOWjgC129flvOr1C3O/n+Hei7IITQojmQna31dK1srvtatbsdFMrCkuzcogovFxeYO8KHQeD900Q1Bfa3QlqjdV9UHQ6CuIP8eeUKSj5+dXWtfPzo+OuGFQa69uxRkmZnlmbf+GHX9O5XFpztm0V4OfuxP6oQWjUKrYfS2fu1iTS8/4eWZJdcEII0TgkmWQDuBaDJJ1ex5BvhpBZmGnZDYrCs+fzmJSXj0mYYu8Cd0yBftNrFSzlR0dz9oUp1dYJWPYOdp6tKMvOxs7HB+ew0HoNmHR6hQ92n+KdmN+qracCVlw53mT7sXSe3phAVf+RLX/kNobfEmDzvgohhDBPgqQGcC0GSQAxqTFMi51m1T1uOh2P5100Hyy1aAUj34Xge6zuS350NOmvzTbJqaTx8MB9zH3k/7DN6MBctacnfrNfw33oUKvbsoa5kaEKV48Q6fQKdy7ebbZeBRUwZfCNPD/4RjniRAghGoAESQ3gWg2SAFYmruTDnz+0+r6KYKlNWRk+Oh0hRcVXgiYVPLChVoFSxfRb4U8/AeDcqyf6vDzOTouEKn51Ww4fRuulS+t9VCk+JZeMvMvkFpTQytURPzcnega1MgQ7cb+f4+FVP1r0PA9nexbd102m34QQop5JkNQAruUgyepptwqKYrQ7zVOn4+5LBQwsvEyIgzeaqb/WaurNqAmdjlODw41GkMxRe7jjP29eg5/3drV/J55lyheJVt3zxB3tCA/2Mwq2hBBC2I5k3BZ1olFrmNFzhvU3Vtq+f16j4VN3Nyb6axnirhBz6P06963w8JEaAyQA/YU8zk6ZWq9ZuWty9e42S60+cJqHV/3InYt3S9ZuIYRoZBIkCbPC24bzVv+3UKts8yuSpdEQmfwJMfsX1uk5VuVFUpR6zcpdk55BrfB3tz5QAsiQ402EEKLRSZAkqhTRLoKl/Zba5FnKlVGmxSc2oDv+Xa2fY21epLKMDHI/3dgogZJGrWL2yOBa3atcec369ldKympOOyCEEML2JEgS1YpoF8E7A97Bt4VvnZ+lqFRk2NmRsGtWrZNPOoeFovb0tOqerEWL+O3OvuRt316rNutiaFd/lj9yW62POMktKOX2hbtkREkIIRqBBEmiRuFtw4m+P5pnuz9rk+dlF58vP9KkFlQaDX6zX7P6Pv358/w1dRqZS20zMmaN4bcE8MHDIbW+P7egRKbehBCiEUiQJCyiUWuYfOtk3hnwDu4O7nV6lo9OB18+Cse+q9X97kOH0uoJyzKDV5a7eg35jTCiNPwWf1Y+FoKHs32tnzF3a5IcZyKEEA1IgiRhlfC24ex9cC/Pdn/W6mBJpSj4lZURUlQMJZfg63EQ/Wqt+qH9v/+j9bJ3ULu4WH1v+tx5jbJGaWhXf468chfTwm/Co4V1wZICpOcVEZ+SWz+dE0IIYULyJNXStZwnyVI6vY6ErASyC7NJu5jG1799XWVuJdWVX7O3s3IIrzjvrcI/1sPNo2vVB0WnI2flR+Ru2IA+L8/i+7yffx6fZ5+pVZu2UJGMcmdSBmsOnLb4vncf6s6o7q3rr2NCCHGNk2SSDUCCJFMVQdOexE/4/q99nL8q47VfWRlR584zsPAyCU6OZGs0f2flbuEF/3eyTokmFZ2O3E83krVokcX3BCx7p96PMLHE9mPpzPr2V3ILSmusu2nS7fTu4NUAvRJCiGuTBEkNQIKk6umOf0dCdCTZZZcNwdAe5xYs8vIk087OUE9bVsaMc+cJ7zkNBkTVqU1Fp+O3O/uiP3/eshvUalq//RZuTSBQKinTc/vCXeQWlJi9rgL83J3YHzVIMnELIUQdSMZt0eg0N4+mx6i1DC8opMeVACnS15vMSuepZWk0RPp6ExP/DiRtqVObVu980+s5O3Vao6QGqMzBTs0b93ZFRXlAdLWK97NHBhsFSDq9Qtzv5/h34lnifj8ni7qFEMLGZCSplmQkyQJ6Hbx5I7rCcwwJDCgPkFSmoyAqRUGr07H9XAmayGSwc6hTs5lLl5K7eo3lNzShEaXtx9KZuzWJ9LwiQ5m/uxOzRwYbHX5raT0hhBDGZLqtAUiQZKFj33Ho+38y0V9bY9U16Zn0KFNDnykw4KU6rVHKfv8Dcj780Kp7Wr/3bqMeiFuhYlF31sUifFs6mRx2u/1YOk9vTKDyf7gVNVY8FiKBkhBCVMGa72+7aq8KUVddR5P9+7/hwuEaq2ZrNFBUCP9dBD9+AKNXQPA9tWrW+5mnufD115Rlmt9tZ07G62+gbtkS3blc7Hx8cA4LRaWpfaBWWxq1qsrF2Tq9wtytSSYBEpSnCVABc7Ycp6WTPTmXis0GWUIIISwjI0m1JCNJljuUcYiJO2pO/vhJeiZqMN75NmAWeHUAVy207WPV6FJ+dDRnX5hS637b+fmhnTWzSYwuVYj7/RwPr/rRqnv83Bx5uGcb2nm74O3iCCokgBJCXLdkuq0BSJBkOZ1ex5BvhpBVkGE46PZqKkXBXa/HUVHM73yryKvk7AW3PAidhlscMOVt385fkS+CvhaHxF7pa+t3lzWZQOnfiWeZ8kWizZ4n65iEENcb2d0mmhSNWsOMnjNApTIklaygUhQU4IJabbLzLVOjYZqvN8vd3dABFJ6DH5fD+rvhzRstOtbEfehQWr/9Vu06fqWvmW8sbJQM3eb4tnSy6fMy8orkXDghhKiCBEmiQYS3DeftAe/gW+koE1+dDveKUZ7Ko0wqFahUrGjlQf82rYlxbvH3tcJzFh9r4jZ0KAHL3gF1LX7dFYWyjAwKDx/5u0ino+CnePK+/4GCn+IbNIDqGdQKf3cnkzQBtVURsl59LpykFhBCiHKycFs0mPC24QwMHEhC+k9k/+sxfIouoQMmWbDzLU+tZpqvN+9UPtbk4HvQOrTGY03chw5FBZydOq1WfS/LzgbK1zllvrGQsowMwzW1uzutxj6O9+TJ9b7QW6NWMXtkME9vTEAFZhdwW+vqc+HyLpfUmFqgpt13QghxrWj0kaTly5cTFBSEk5MToaGh7Nu3r9r6e/fuJTQ0FCcnJ9q3b8/KlStN6nzzzTcEBwfj6OhIcHAw3377rdH1OXPmoFKpjF5+fn42/VzCPI1aQ4/WfRge/jY9iorJtTSouDLKtNDLkx+dHNnm4swhJ8fyabgfXizPyVQDt6FDaf3eu9jV4s/azsenfCH4lKlGARKAPi+PnPc/4Lc77iQ/OtrqZ1traFd/VjwWgp+7bafediZl8PTGBKMACYyn5LYfS+fOxbt5eNWPTPkikYdX/cidi3fLdJ0Q4prUqAu3v/zySx5//HGWL1/OHXfcwUcffcQnn3xCUlISbdq0MamfkpJC165dmTRpEk899RQHDhzgmWeeYdOmTYwZMwaAuLg4+vbty/z587n33nv59ttvee2119i/fz+9evUCyoOkr7/+mpiYGMOzNRoNPj4+FvddFm7bQPSrHEr4yKIcSlUxLO7+x78gqK9F9yg6HYWHj1CWnY3Gy4v0GTMoy8oyrEEyolJhp9XSIXoHv0cMMQmQzNVvqIXeV4/oeLs48uK/fiYzv6jWo0utXByqPRbF3dmevMJSyc8khGjWms3utl69ehESEsKKFSsMZV26dGH06NEsXLjQpH5UVBRbtmwhOTnZUDZ58mR+/vln4uLiAHjwwQfJz8/nP//5j6HO0KFD8fT0ZNOmTUB5kPTdd9+RmJhY675LkGQbumObGfLTq2RqVGazcdekYiH42+0fJLxfzeuTzKkYIQKMA6Wrdrdp3D1IGzfOoufZ+fnRcVdMg+dYqkgyCdZNw6kATxd7iw7Yre4ZcracEKI5aBa720pKSjhy5AgRlf6POyIigoMHD5q9Jy4uzqT+kCFDOHz4MKWlpdXWqfzMkydPEhAQQFBQEA899BB//PFHXT+SqAVN1/uYMfidWgVIAIpKhQLM+3Mb3//+PYcyDqGzYOrtam4REbR+dxl2WuMRLTut1jAqVLEmyRKVF3o3lNpMw1X81O/t3rpObV+9rkkIIa4VjbZwOycnB51Oh7bSF5NWqyWjiimNjIwMs/XLysrIycnB39+/yjpXP7NXr15s2LCBm266iczMTBYsWECfPn04fvw4Xl7mMx0XFxdTXFxseJ+fn2/V5xVVC28XwVu8xfS901FqM1mkUnG+9BIz988EwNnOmTsC7uCBTg/Qw68HGgvyKblFRNBy8GDDNFzljNt2VkzFAlYFVbY0tKs/dwX7GabhTucUsik+jYz8IrP1/a4synZv4cDqA6fr3H7WRfPtCCFEc9Tou9tUlUYQFEUxKaupfuXymp45bNgww79369aN3r1706FDB9avX09kZKTZdhcuXMjcuXNr+DSitiLaRfAmb/Li3hfr/KzCskJ2pu1kZ9pO3B3dmdN7DuFtw2u8T6XR4NKrp9lrzmGh2Pn51bwm6QprgypbqnysyXODOhqtXTKXcVunV/B3dyIjr/ZrmqB2eZwq1lZl5F0mt6CEVq6O+LnJrjkhRONrtCDJ29sbjUZjMmqUlZVlMhJUwc/Pz2x9Ozs7wwhQVXWqeiaAi4sL3bp14+TJk1XWmTlzplEAlZ+fT2BgYJX1hfUi2kXwjuod5hycQ15Jnk2emVecx7TYabwz4B2LAqWqqDQatLNm1nzMyZWF3s5hobVq5+pF5bY6P666s+CurlNVaoGK9x5VLNyuqOPnXh7YWGP7sXSTlAMVJBu4EKKxNdqaJAcHB0JDQ9m5c6dR+c6dO+nTp4/Ze3r37m1SPzo6mrCwMOzt7autU9UzoXwqLTk5GX//qv8ydnR0xM3NzeglbC+8bTh7H9zLJxGf8M9u/+Sft/yTj8I/QuusRVWHFIpzDs6xeq1SZW4REbR+713UHh7mK1wZrdTOmlmrwCY/OppTg8NJGzeOv6ZPJ23cOH67sy8ZCxc2SNLKqtY0+bk7sfKxEBbd1w3A5E+h4v3skcFWjfxULDQ3FyBB+RqnitQDkuBSCNEYmkQKgJUrV9K7d28+/vhjVq1axfHjx2nbti0zZ87k7NmzbNiwAfg7BcBTTz3FpEmTiIuLY/LkyUYpAA4ePEi/fv14/fXXGTVqFP/+97955ZVXjFIATJ8+nZEjR9KmTRuysrJYsGABe/fu5ddff6Vt27YW9V12tzWsmNQYImPLR/JqtW4JeLb7s0y+dXKd+6LodOSs/IjcDRvQ5/094lWXA3ENO+yq+c+xoQ7crS5ZpLmRn9qM+Oj0Cncu3l1lgFShIvWAk53GaF2VjDIJIWqr2aQAgPJkkkuWLCE9PZ2uXbvyzjvv0K9fPwDGjx/P6dOniY2NNdTfu3cv06ZN4/jx4wQEBBAVFcXkycZffF9//TWvvPIKf/zxBx06dOD111/nvvvuM1x/6KGH+O9//0tOTg4+Pj7cfvvtzJ8/n+DgYIv7LUFSw4tJjWFR/CIyCzNrdb+LvQuv9HoFrYuWEN8QixZ0V8dWU2OKTsepweEW5WCCxj9w1xYZt+N+P8fDq36sdR8szc0k2cGFEJU1qyCpuZIgqXHo9DoSshLILMhkyaElnC8+X6vnaJ21zOg5g/DAgZB6EC5lgqsW2vaBOgZP1ir4Kd7iHExQfgxK62Xv4NKzZ4PnYrKVfyeeZcoXiXV6Rk25mcyNenk629G7vRftfVrSu4MXPdq14kjqeQmihLiOWPP93ei724SwhkatoYdfDwCc7JyYFlu7s9gyCzOZFjuNxy/rGXghm5CiYjQAbgEwdDEE32O7TtfA2nQB+rw8zkyY2KBnxtlabXbBVXZ1bqbKC9Mr1jtV/j/A84VlbDuWCWTywZ5TqFTGM5x+bo483LMN7bxdJGgSQshIUm3JSFLTEJMaY5PdcJ46HXdfKmBg4eXygKnfDBjwUoOMKlk7klSZ2sMD/3lzG3UKzlqWrkmyxLsPdWfUVckwbfnsVi723Nu9NYM6a82mThBCND8y3dYAJEhqOnR6HR/98hErf15Z60XdVzOcB6c4wcj36n1UybAmKTOz2oXb1brqzLj6SCNQH6oa7bHWpkm3G40k1XW9kyW0LR3oe6MPzo52tG3lzOO92+Fg1+jnhQshLCBBUgOQIKnpiT4dbZNklBWBSmhREbcVldDLN4QePrehcfECV19o6W/ztUuW7G6riZ2fH9oZUWQuWmy0CLyhdsXVRnV5kvzcHCkq09eYm6nymiRbrHeylloFk/oGMXO45Zs/hBCNQ4KkBiBBUtNU1x1wVWmh1zPxQj4T8/L52cmRbFdvfML+SUjP58vXMtlg8Xd+dDSZbyy0OKu3xczsiqtqtKkxRqGqy7i9MynD7KG91e1ua4iRpKo81U8CJSGaOgmSGoAESU1X5R1wF4ov2GQaDkClKChXHXGjVTsxI6+A8Jyzf1dSO0CrjuDkCvbOEBACHQZAuztrDJ4qgpSLu3eTv2ULuvO1271n2vHyTOAdd8Vwcdcuk2DMzs8PtxHDyf9hm1G52t0dz8cexTksDN253EaZvrM2N1PFmqS6HrFSG2oV/G/+MJl6E6IJkyCpAUiQ1DzYIgmlEUUxjMxAedAE8HZWDuGFl02q64DDTo7EOzmBSkMPj070uGUsGo/AGkecFJ2OgvhDnJ061ShpZV14P/88OR98UPdpvSvTdw018mRtviNbrXeqjVdHdOGJvu1rfb/kdhKifkmQ1AAkSGo+6msKroJKUdDqdGw/8xdXhwcxzi2Y492KvEpBg7tOx5ycXMI1HhAyDhRd+VxSUF+zo0350dE1nxlnIbW7e90DritBYquJE0xGnlQuLrjeeQfuDzyASq1utNEnqH69U30a27st80Z1rdW95vosaQmEsC0JkhqABEnNS8UU3J60PXya/Gm9tLEmPZMeRcVAeYA0zde7/IKq0hfalf/kHs+/+HfKgYprLVrByHdNdtTlR0eT/tps9BcumDZcOdlPE6TRavF84B84tG3XoEFTxajMzqQMvjr8J5eKy4yu18ePrrYjSZaOflUXNJWU6fk07jSpuYWy606IKkiQ1AAkSGq+6mtkaXFWDsMLCtEBEYEBZGk0pgGSGb5lZfwj/xI3lJVxXqPGU6dHe+dLhGhD0BRkGxaDKwpVnhnnOyOKrEWLq04joFKhdnOz2bRdXZnbcVcxvVj4008AOPfqadOs4jq9wo+/nyPujxxAZZJx+3ROIZvi04zOiLNWbdck1SW3U8X6rKNp51m1L4XKZ//2bu/JAz3aGhbDyyiUuN5JkNQAJEhq3q4eWdr62zdc0BXW+ZkVI0mHnByZ6K+1/MZK65wquOl0PJ53kUl5+WgcXKBDOPR4AiWwN4UJiSbrgAxpBCqeWeHKs72fe5ac9z+owye0oUo77qocKXN2xmvCBByDghpkBOrqkafvEv8it6DEqvtru7utLjvyVGDx2it/dydeHdEF9xYOhmAxNNCDXSeySM0tpJ2XM7OGB9PCoenl1RLCViRIagASJF07dHodq37+iA9/WVGr+yuvSdrm4kxUxVSbDbjrdLyWk4unXk+2RoOPypGQmx9C03mEyeJvc2kEKkZtWg4eXPeklbZ0ZceddkYUZ6dadryMRqvF4/4xoNMD0KJHGACXDx0G/h59Auq8oPzqBdTeLo6GjNs7kzLZ9mu60YhNXfMkNUZup+rc4NmCcb3b0tnPjdzCElkLJa4pEiQ1AAmSrj0WHXFiwe42q0eSalLxn+jVqQcMWcEdodczcOc0OPMTXMpEaeFDYY4DZTmmi6arHG1qRGoPD/NrrWpJ5eyMysHB6JlqT0/c7xlJy0GDcbqlGxe+/IqSM2dwCAzE85GHUTs4WNWGrdf+NGZuJ0u1crFnwaiuDOnqL7vvRLMmQVIDkCDp2qTT6ziceZgf//qRo5kJ/C/3OAW6YsN1NSr0V01u+KlbEJWeZrT939o1SRapIjh7MysHd72eeCcn9ICHXoeXTo9WZU/IDf3RhE0oH2m6am1TfkzVeZIufLPZpgFLs6BW02rCeLT/939GxVevkVL0ejSeHth7eWOn1dp82q8xcztZy8VBQ0GJzvC+YgqvpaM93xz9k4LiMrRuToS08cTfo4UEUaLJkSCpAUiQdH2oWLuUXZiNj7MPt3rfys85Pxveh/iGoEneCv9+DkouGu6rdnebrShK+XqUKp7vodPR43IRQaVlhBaVLwg+4u6Nvv0gPPxCCTh5jpLk/TiqLuDe2p4Q1zaoPQLJ+amA3K37qlzkXRFQ5a5eUz+fq5G0emKiIVCqdjchxrv1NF5egEJZdg663FzsWrWqVSBVsbsNLF9j1BxUXgelV8DT2YFWLg5cKDTOsC7BlGgIEiQ1AAmShBG9DlL2wen/Qm4qFGQTozvPHNV58jTN4y/+il12bcrK8FK7oHjcQ2JuJifJwsm+BR303mh8vMkPbk0P/150/jmXzNdeQ3+xoHYNqlTlU222yipeV2o1nRKPcik21iZ5qez8/PB56f/QZWVTnJqKCnDq1g19fj4aDw/KcnPLA1GVyrCWakdyVqPkdmoKHNQq2vu4MKCTL16ujrRycSDnUhHJ6RcpLNHRo10rxvWRlAai7iRIagASJAlL6PQ6Dv8VR3zCKlIK/mRnSZZVu5EaVBW77KripFcYk3eRIT8qOBxrgbrMyi8vlYqAd94mc+EidJn1k+jTWj4vvUTu+vWN0h+Viwvu992LXUBrUsscyHV2J9mnA5sOn602LUGT/X2qJyO6aYm42d9oMb2sjRLWkCCpAUiQJGqjvrN/NxaVXiE4Vc/NaeCiVwhzu0hISTG6Yg0lFzVc+N2Fsst/Tz2Vuegpvb2YW++8k4LSEM6+saoRe/83l/BwCmJiGrsbBnZ+fvjMnElyx9DyXE5ZF0n4fg+qc9m4F1/iooMzrTWl3NW7EyfKnFh0tgU61fU50lIxredib8fH+/8g73IJfu4tiAjWcrGoTKb1hIEESQ1AgiRRW1evc0q7mMbXv31dfdBk5QhPYzO340/Rw76LLflB05LTbmqSA1UoahUeOh1hl4u48ZSKO2LscSht3M/pds895G/Z0qh9MKFS0frdZQAmC+5Nqnp48HvATRxR3EnwbIeiUuNZlI9H0UXcSgtBgYuOLlxwdOWcY0vUKHTLSQEUfvHpyK/eHdBf40GWu5MddwVrueNGH3xdHdErCj+lnKMiwejt7b0kiLrGSZDUACRIErZSETRlFmTyU/pP7DmzxzgNgZkUAE1d5dxRMc4tiPT1Lp8WquJzqPQK9+3XMfIQOFeRw1GhfHqpOhUHGatqrFnpuWo1gfNe4Mwryyy+r0GoVH+fuVfPf10Xo+IP9xs45dEaBbhs74TX5TxUKhVZzp78fB0EUo52agZ19uWRnm3Q6xU2H/2TsxeKuMGzBWNCbqBPR28Jopo5CZIagARJor4Y7ahzasX5M3EsObmJTN3faQZUilJtwNFUrEnPJKSomCGBAWRamBJBpVfokqbgWQAXnMtH0TwKwO+8wrBDCm41rGkudACdBlpeNn+9cqBV8Rfgf3rC2R7FjF1rj0Ohyqog63pSgoqffW5k7w3dcS29zEUHZ9yKC3AvKcD7ch45LTy46OCMa2khCqprboRKDYS29eCuYD/cne2JScqksESHs4OGITf70drTWab0mjgJkhqABEmiIRkCp4JMfE7u4vz/tvKih1P5xSYcKC3OysFHp7NZcs2r1z4BJAWW/zP4jAKKiuNtIalt+ZdxlzMKYb8p9E1ScL/q1JnKQZJOBd/3VPHZoPI1Uz1P6Hlxc3lG76b7k21eitR2xGu7cKJVW0Pw9Kt3e5PpwGslqHK2hxs8XSgu06FSqeng68rtQV6yO6+JkCCpAUiQJBqVXkfMkQ+Zc2IjeboqhkyagDXpmWRrNDY9pqVKVazdUukVupxR8LwE513hhL/CkETQnodMT9geokJf6Yur5wk9/9ymr3LUyrJpPwmyaivPzokftTcTUHgOVPCjXzAp7v50PZeKWq/DpawIUFCU5jcleKOPCxFd/bg9yAu9XuGbhDMkpedTVKZH29KJITf7Mf6OIAmm6pEESQ1AgiTRFFRkCI9Pj0ePHg97N9LTj/BdxgEKlDLrHmbDBeJXr0lKsPUxLQ3EaNRKUbjUQkWeC/hdgMGJCt4Xq7+/4i/Wuv5E9ZRP8VxP6hpgFqntiPe6kcDLuTiXFKLTKTip9DjqSiiwd+IvV1/s9DqK7Rw46XkDib43NbnAyl4NDhoVns726FGhV6CDjwv/7NeBO2/0kem8OpAgqQFIkCSasquDJ1QQ6hsKwJHMI+XBlIMHnvYtyTv1HzzP/8mfukt8rSokU7Hu1HtzKu9u0wFDrhzTUlV28Obm6tGpinVTnpcU3AohzxnOt1Rx2ymFuw8paOrwN2zFrZdagMvl6y9YakilgB4VikpFvoMLSW6BdLmQRktdMZftHPnJqyPd8s7gWnKZCw4upHr4Y6/Xcdy7PVvb30GZ2q5B+9vSQU1pmR5FpUKvU9CrQK1W4e5kx/fP98OvYjpemJAgqQFIkCSuNVcvGPdq4UWprpStp7by24XfcLF3wdnOmV9yfqGgrPoM235lZUSdO290np0lu9uuReoyPUMTFLS5CioVnPSHlkUq8luUr5NyuQwBuXBzGribmTXNaQnr7ioPjV7cXH5qoARKTY8eyFc7ct7RFa+ifADK1BoURYUDOkpVagrtnNCoVJRpNCT6dOSTbvdQorHuYGVbcLZXs31Kf9p4Ozd4202FBEkNQIIkcT26Ol3B+eLzeDp64uPsg6Io5Bbl4uPoQcjpQ2jOxIN9C/DtCsV5kHeWmKK/WFT0B5l2FpxnVpupv2aWT+pqFSNTrS4aj0ZV5JOC8nVS43fqa5zmE82DApSiItWxFX4l+TgppaiAsivXdCo79Kj+v727j4q6SvgA/v3NK8OLSCiME6gIgi/4soLyYIuAlWVpZJ2n2tOaPVvsWmkqPluZme5uHqyeY+ZRa02zx55dcTc1WbMSj4Ci4AKKsmpqrIovIKHIDG8zzMx9/iB+OjIog8KM+v2cQ53fnTv3d+dehC+/l/uDVaVGrcYXl3V+OBnQ97aeGuzhpUR9kw0CLUGvlVYp4btZiQgL8rnlfXgihqRuwJBE5Dqb1YIDh/4X2ae/xea6MtQ7/Gi+SoIkr3fUIdf+GLtDg1JHXB+mjDqBHo0SetUKJB8GfG79bCndAexoCVICgFVS4ieNL0xKL4Q3XIQKrQEMUEABu0KJSu8AvDHuVdRpfG953xKAPj202DojAb17aG+5PXdgSOoGDElEt6b1uqmCCwWoqK+AEAIGXwPi+sRhVNAoHKo6gIvlebhkqkCtUoLocT+qGquxs3wnGqwNDm31VGgxxWTCZi8lapUdOFJ1Kzz0iJWz5RGEouVaKf96AZ+fT+e1XoB+xQeQBPDMHoHICzyNd7cT13y1kq55zdl3tFlS4uWH5uKyT5DL+/t6+gMY2b+ny+/rDgxJ3YAhicg9rr8ofXTwaIzWj4YSgO10Hooq9uOf5irYhUBPu0Cg3/3oHRIHcfEILl8oRGC9EcK3F6pVauy3VGNH7Q9osHf8EIxCCNivDUmuhCYPDVjytVOXBALrgcs+ACSgXgMMOg9EngfU/E1xT2oJUHbYXYjRAkDaL6bgRL8H2q3z38l9MeORYbfewU5gSOoGDElEd4frl1Hooe4Bk6UW4so59LTbEeDdG7VXTiGgyYRghQYjvPvjkPUSflJIKK85if+zXECt1MEfozcKSR4aoICWo1RDT9mQeATwMgM1fsBJw3UXoTcAvU0tF5vX6YCB54GYfwNaF1eiALjG1N3g+qNW7bu6yIUAsBnA50/+j/zq6SWP3/a+MSR1A4YkIgKcr1UVYKpCTeVh1DT+hItqFfTaQMQFDsEoyRtv/7QX39cea9uQB4ekzrp+ral6L8CnCYAkOT8dKEnQXxaI/wHo4pOm5KGchauW8HQB7/5Q6+QdrrujQtKqVavw4YcfoqKiAkOHDsWyZcuQkJDQbv3c3FykpaXhyJEjMBgMeOONNzB9+nSHOps2bcKCBQtQVlaG8PBwLF68GFOmTLml/V6PIYmIOstitWDD8Q04cPEAvNXemDxgMoYHDsfHB5bi9Nm98GqqRX8o8JNCDbvGG5JPEPRWG3paGrHTfgWHzVVd20E3BzaF1Y7HiuyIPQFAAooigDO9gcHnJcAu4Gu+erSpXgP0MgG9jEBEZeeOXJHna70DL/oHJ39guOiOCUkbN27E1KlTsWrVKjzwwAP485//jDVr1uDo0aPo27dvm/qnTp1CdHQ0UlNT8bvf/Q579+7Fq6++ig0bNuDpp58GAOTn5yMhIQF/+tOfMGXKFGzZsgXvvvsu8vLyEBcX16n9OsOQRETuYrFa8OWxL5F5MhOXzZehU+kQ6heKYb2HYYx+DBQAqs7sRun5fNjqq6C02zDUqw9q9UNQW3cOUmMNRtTVIFc0olylgJfSBwPsAqqmK1AqNPirphm17dx56Mkcjlw1C4z+N+DdBNjsgEYAXlagXg1UBAIqO6BrBkKrARXPp3i81im6HUHpjglJcXFxGDVqFD755BO5bPDgwXjyySeRnp7epv6bb76JzMxMHDt2dYCmT5+OQ4cOIT8/HwDw7LPPwmg04ttvv5XrPProowgICMCGDRs6tV9nGJKI6G4l33l4Ph8VFw/Bbm2EUGhRbTbigqUKSpsNAc0N6NlshVmtRmDQCBh6R2P0id1Q1Fdit0aJzUoL6uH5h3Uku0B0mQ2T84GoipajUyYv4Ic+wKAKwNcCNKqBov7A0IqW04UWJRBYz1OC3a01rHx1i6feXPn93b3rqF/DYrGguLgYb731lkP5hAkTsG/fPqfvyc/Px4QJExzKHnnkEaxduxbNzc1Qq9XIz8/HnDlz2tRZtmxZp/cLAGazGWazWd42Go03/YxERHcipUKJuD5xiOsT59ob494AAPwHgLnX3YX4i14jUHZyO87/Owv3my4jzNKI7b6+OKdSoUGjxmWFAgJAAJQYZmnGYSVQpwTqoYS25YEhqAFu+/EtoZBQOlCF0oGuvU+yCwz70Ybn8gDfBsD8c2IKrGv5v+XnbY0NsCpbTgN62XhB+q1oHbunYOi2fbotJFVXV8NmsyE42PHBl8HBwaisrHT6nsrKSqf1rVYrqqur0adPn3brtLbZmf0CQHp6Ov7whz90+PMREd3LnAWtX4aOA8YvkbfHudimzW7DPyv/icwfM9FgbcDwwGjYL5/G7gu7UWc2IsJshp9dQGh0uKjR4oStATWwQyEpoBNAEwCbBPgqFAjz6QeFpMDl+vMw2sz4SRIuJRihkHA4UoXDkR1/j9Jiw7SdAjEnWo5QmVVAtRegrwO0PwcoG1qCoE0JQAIsasDXDKjtDFitunMc3BaSWknXXRwohGhTdrP615d3pE1X9ztv3jykpaXJ20ajEaGhoe3WJyKi20upUCLeEI94Q7xDeeptaLv1Oq9tZdvQ1NwEbbMJPZobcBLNsACQ7ECg1YomCWhUSFAB8LO3LMhZq5RghwJCCZhtdthbTwxJ0tUvADaNEp8/Bnz+mOv9UzdY8c5fgYifri78KQBYFcAlb8CkBcIuQV5xW0JLvbsxWHXnNUJuC0m9evWCUqlsc/SmqqqqzVGeVnq93ml9lUqFwMDAG9ZpbbMz+wUArVYLrfbOXIKdiIhuTKPS4KVhL+GlYS/d1nYbLY1YnL8YW09vvVpol/9z9ZE6PwcpX7sdvWx22AFUKhWw/Byymr0UWPhfTu46vCaEXU9rtOLDz4HeTh6eDLS/4rYEzwxXreFoMy4gupv26baQpNFoEBMTg6ysLIfb87OyspCSkuL0PfHx8fjHP/7hULZjxw7ExsZCrVbLdbKyshyuS9qxYwfGjh3b6f0SERF1hk6jw3uJ7+G9xPe6pP26pjrM+OYVFNeVAHbHK7bMvgq8/rrrbSotdkz7Bnj4hGthqSvD1bV3t92u9ZI6wq2n29LS0jB16lTExsYiPj4eq1evRnl5ubzu0bx583D+/HmsX78eQMudbCtWrEBaWhpSU1ORn5+PtWvXynetAcCsWbMwbtw4vP/++0hJScHWrVuxc+dO5OXldXi/REREdwJfL1988fSXt73dU8+ewhNbn2gTvG4kpNSOD7e7HpQ6Gq5u1zpJrnBrSHr22Wdx6dIl/PGPf0RFRQWio6Oxfft29OvXDwBQUVGB8vJyuX5YWBi2b9+OOXPmYOXKlTAYDFi+fLm8RhIAjB07FhkZGXjnnXewYMEChIeHY+PGjfIaSR3ZLxER0b0srGcYSqeVuv7GpTevMmyRP9D3fvk04X++b8dTaD8o3e4Vt13h9hW371RcJ4mIiOjO48rv744/1peIiIjoHsKQREREROQEQxIRERGREwxJRERERE4wJBERERE5wZBERERE5ARDEhEREZETDElERERETjAkERERETnh1seS3MlaFyo3Go1u7gkRERF1VOvv7Y48cIQhqZNMJhMAIDQ01M09ISIiIleZTCb4+/vfsA6f3dZJdrsdFy5cgJ+fHyTJ1Wcet89oNCI0NBRnz57lM+HcgOPvfpwD9+L4ux/noGsJIWAymWAwGKBQ3PiqIx5J6iSFQoGQkJAua79Hjx78x+FGHH/34xy4F8ff/TgHXedmR5Ba8cJtIiIiIicYkoiIiIicYEjyMFqtFgsXLoRWq3V3V+5JHH/34xy4F8ff/TgHnoMXbhMRERE5wSNJRERERE4wJBERERE5wZBERERE5ARDEhEREZETDEkeZNWqVQgLC4OXlxdiYmKwZ88ed3fprrF7925MnjwZBoMBkiTh66+/dnhdCIFFixbBYDBAp9MhKSkJR44ccahjNpsxc+ZM9OrVCz4+PnjiiSdw7ty5bvwUd6709HSMHj0afn5+CAoKwpNPPonjx4871OEcdJ1PPvkEw4cPlxcnjI+Px7fffiu/zrHvXunp6ZAkCbNnz5bLOAeeiSHJQ2zcuBGzZ8/G/PnzcfDgQSQkJGDixIkoLy93d9fuCvX19RgxYgRWrFjh9PUPPvgAS5cuxYoVK1BYWAi9Xo+HH35YfkYfAMyePRtbtmxBRkYG8vLyUFdXh0mTJsFms3XXx7hj5ebm4rXXXkNBQQGysrJgtVoxYcIE1NfXy3U4B10nJCQES5YsQVFREYqKijB+/HikpKTIv4Q59t2nsLAQq1evxvDhwx3KOQceSpBHGDNmjJg+fbpD2aBBg8Rbb73lph7dvQCILVu2yNt2u13o9XqxZMkSuaypqUn4+/uLTz/9VAghxJUrV4RarRYZGRlynfPnzwuFQiG+++67buv73aKqqkoAELm5uUIIzoE7BAQEiDVr1nDsu5HJZBIDBw4UWVlZIjExUcyaNUsIwe9/T8YjSR7AYrGguLgYEyZMcCifMGEC9u3b56Ze3TtOnTqFyspKh/HXarVITEyUx7+4uBjNzc0OdQwGA6KjozlHnVBbWwsAuO+++wBwDrqTzWZDRkYG6uvrER8fz7HvRq+99hoef/xxPPTQQw7lnAPPxQfceoDq6mrYbDYEBwc7lAcHB6OystJNvbp3tI6xs/E/c+aMXEej0SAgIKBNHc6Ra4QQSEtLwy9/+UtER0cD4Bx0h9LSUsTHx6OpqQm+vr7YsmULhgwZIv+C5dh3rYyMDBw4cACFhYVtXuP3v+diSPIgkiQ5bAsh2pRR1+nM+HOOXDdjxgwcPnwYeXl5bV7jHHSdqKgolJSU4MqVK9i0aROmTZuG3Nxc+XWOfdc5e/YsZs2ahR07dsDLy6vdepwDz8PTbR6gV69eUCqVbf4aqKqqavOXBd1+er0eAG44/nq9HhaLBTU1Ne3WoZubOXMmMjMzkZ2djZCQELmcc9D1NBoNIiIiEBsbi/T0dIwYMQIff/wxx74bFBcXo6qqCjExMVCpVFCpVMjNzcXy5cuhUqnkMeQceB6GJA+g0WgQExODrKwsh/KsrCyMHTvWTb26d4SFhUGv1zuMv8ViQW5urjz+MTExUKvVDnUqKirwr3/9i3PUAUIIzJgxA5s3b8auXbsQFhbm8DrnoPsJIWA2mzn23eDBBx9EaWkpSkpK5K/Y2Fg8//zzKCkpwYABAzgHnso914vT9TIyMoRarRZr164VR48eFbNnzxY+Pj7i9OnT7u7aXcFkMomDBw+KgwcPCgBi6dKl4uDBg+LMmTNCCCGWLFki/P39xebNm0Vpaan41a9+Jfr06SOMRqPcxvTp00VISIjYuXOnOHDggBg/frwYMWKEsFqt7vpYd4xXXnlF+Pv7i5ycHFFRUSF/NTQ0yHU4B11n3rx5Yvfu3eLUqVPi8OHD4u233xYKhULs2LFDCMGxd4dr724TgnPgqRiSPMjKlStFv379hEajEaNGjZJvj6Zbl52dLQC0+Zo2bZoQouUW3IULFwq9Xi+0Wq0YN26cKC0tdWijsbFRzJgxQ9x3331Cp9OJSZMmifLycjd8mjuPs7EHINatWyfX4Rx0nd/85jfyz5bevXuLBx98UA5IQnDs3eH6kMQ58EySEEK45xgWERERkefiNUlERERETjAkERERETnBkERERETkBEMSERERkRMMSUREREROMCQREREROcGQREREROQEQxIREYD+/ftj2bJl7u4GACApKQmzZ892dzeI7nkMSUTkdp9++in8/PxgtVrlsrq6OqjVaiQkJDjU3bNnDyRJwokTJ7q1j4sWLYIkSZAkCQqFAgaDAc8//zzOnj3brf0gou7DkEREbpecnIy6ujoUFRXJZXv27IFer0dhYSEaGhrk8pycHBgMBkRGRrq8H5vNBrvd3ul+Dh06FBUVFTh37hw2btyI0tJSPPPMM51uj4g8G0MSEbldVFQUDAYDcnJy5LKcnBykpKQgPDwc+/btcyhPTk4GANTU1OCFF15AQEAAvL29MXHiRJw8eVKu+8UXX6Bnz57Ytm0bhgwZAq1WizNnzqCqqgqTJ0+GTqdDWFgY/vKXv3SonyqVCnq9HgaDAQkJCUhNTUVBQQGMRqNc580330RkZCS8vb0xYMAALFiwAM3NzfLrixYtwsiRI/Hll1+if//+8Pf3x3PPPQeTydTufr/77jv4+/tj/fr1HeonEd0eDElE5BGSkpKQnZ0tb2dnZyMpKQmJiYlyucViQX5+vhySXnzxRRQVFSEzMxP5+fkQQuCxxx5zCCUNDQ1IT0/HmjVrcOTIEQQFBeHFF1/E6dOnsWvXLnz11VdYtWoVqqqqXOpvZWUlNm/eDKVSCaVSKZf7+fnhiy++wNGjR/Hxxx/js88+w0cffeTw3rKyMnz99dfYtm0btm3bhtzcXCxZssTpfjIyMvDMM89g/fr1eOGFF1zqIxHdIjc/YJeISAghxOrVq4WPj49obm4WRqNRqFQqcfHiRZGRkSHGjh0rhBAiNzdXABBlZWXixIkTAoDYu3ev3EZ1dbXQ6XTib3/7mxBCiHXr1gkAoqSkRK5z/PhxAUAUFBTIZceOHRMAxEcffdRu/xYuXCgUCoXw8fEROp1OABAAxOuvv37Dz/XBBx+ImJgYh3a8vb2F0WiUy37/+9+LuLg4ebv1CfErV64U/v7+YteuXTcZPSLqCio35jMiIllycjLq6+tRWFiImpoaREZGIigoCImJiZg6dSrq6+uRk5ODvn37YsCAAcjMzIRKpUJcXJzcRmBgIKKionDs2DG5TKPRYPjw4fL2sWPHoFKpEBsbK5cNGjQIPXv2vGkfo6KikJmZCbPZjK1bt+Lvf/87Fi9e7FDnq6++wrJly/Djjz+irq4OVqsVPXr0cKjTv39/+Pn5ydt9+vRpcyRr06ZNuHjxIvLy8jBmzJib9o2Ibj+ebiMijxAREYGQkBBkZ2cjOzsbiYmJAAC9Xo+wsDDs3bsX2dnZGD9+PABACOG0HSEEJEmSt3U6ncN26/uuLesojUaDiIgIDB06FG+//TZGjhyJV155RX69oKAAzz33HCZOnIht27bh4MGDmD9/PiwWi0M7arXaYVuSpDYXlI8cORK9e/fGunXr2v2sRNS1GJKIyGMkJycjJycHOTk5SEpKkssTExPx/fffo6CgQL4eaciQIbBardi/f79c79KlSzhx4gQGDx7c7j4GDx4Mq9XqcCfd8ePHceXKFZf7u2DBAmzYsAEHDhwAAOzduxf9+vXD/PnzERsbi4EDB+LMmTMutwsA4eHhyM7OxtatWzFz5sxOtUFEt4YhiYg8RnJyMvLy8lBSUiIfSQJaQtJnn32GpqYmOSQNHDgQKSkpSE1NRV5eHg4dOoRf//rXuP/++5GSktLuPqKiovDoo48iNTUV+/fvR3FxMV5++WXodDqX+ztgwACkpKTg3XffBdByNKy8vBwZGRkoKyvD8uXLsWXLFpfbbRUZGYns7Gxs2rSJi0sSuQFDEhF5jOTkZDQ2NiIiIgLBwcFyeWJiIkwmE8LDwxEaGiqXr1u3DjExMZg0aRLi4+MhhMD27dvbnM663rp16xAaGorExEQ89dRT+O1vf4ugoKBO9Xnu3Ln45ptvsH//fqSkpGDOnDmYMWMGRo4ciX379mHBggWdardVVFQUdu3ahQ0bNmDu3Lm31BYRuUYSPNlNRERE1AaPJBERERE5wZBERERE5ARDEhEREZETDElERERETjAkERERETnBkERERETkBEMSERERkRMMSUREREROMCQREREROcGQREREROQEQxIRERGREwxJRERERE78P239nnJV2+82AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code below\n",
    "\n",
    "# Uncomment below for Ex. 1.3.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # plot the data\n",
    "for book, data in book_words_df.groupby(\"book\"):\n",
    "    plt.scatter(data[\"rank\"], data[\"term_frequency\"], label=book)\n",
    "\n",
    "# # add labels and legend\n",
    "plt.title(\"Term Frequency vs Word Rank\")\n",
    "plt.xlabel(\"Word Rank\")\n",
    "plt.ylabel(\"Term Frequency\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9LdA1Ng38_w"
   },
   "source": [
    "### Excercise 2 - TF-IDF\n",
    "\n",
    "1. Add a new idf column to your dataframe\n",
    "2. Add the final tf-idf column to your dataframe\n",
    "3. Display your dataframe's words in descending order of their tf-idf.\n",
    "\n",
    "Idf or inverse document frequency is computed as **idf = log(N / n)**\n",
    "\n",
    "where **N is the total number of documents (books)** in your dataset and **n is the number of documents containing the word**.\n",
    "\n",
    "Once you have tf and idf, the tf-idf is obtained by simply multiplying the two.\n",
    "\n",
    "Hint: For ex. 2.1 the pandas **transform** function could come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zgrfG1kG1KhM",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>word</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>n</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151.0</td>\n",
       "      <td>Heathcliff</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>413</td>\n",
       "      <td>121114</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.004727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>Linton</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>340</td>\n",
       "      <td>121114</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.003892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198.0</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>312</td>\n",
       "      <td>192766</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190.0</td>\n",
       "      <td>Catherine</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>333</td>\n",
       "      <td>121114</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305.0</td>\n",
       "      <td>Hareton</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>164</td>\n",
       "      <td>121114</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54097</th>\n",
       "      <td>437.0</td>\n",
       "      <td>With</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>32</td>\n",
       "      <td>192766</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54098</th>\n",
       "      <td>467.0</td>\n",
       "      <td>sentences</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>2</td>\n",
       "      <td>121114</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54099</th>\n",
       "      <td>467.0</td>\n",
       "      <td>succeed</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>2</td>\n",
       "      <td>121114</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54100</th>\n",
       "      <td>437.0</td>\n",
       "      <td>pleasant</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>32</td>\n",
       "      <td>192766</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54101</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>Vilette</td>\n",
       "      <td>7894</td>\n",
       "      <td>199315</td>\n",
       "      <td>0.039606</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54102 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank        word               book  word_appearances_in_book  \\\n",
       "0      151.0  Heathcliff  Wuthering Heights                       413   \n",
       "1      186.0      Linton  Wuthering Heights                       340   \n",
       "2      198.0   Rochester          Jane Eyre                       312   \n",
       "3      190.0   Catherine  Wuthering Heights                       333   \n",
       "4      305.0     Hareton  Wuthering Heights                       164   \n",
       "...      ...         ...                ...                       ...   \n",
       "54097  437.0        With          Jane Eyre                        32   \n",
       "54098  467.0   sentences  Wuthering Heights                         2   \n",
       "54099  467.0     succeed  Wuthering Heights                         2   \n",
       "54100  437.0    pleasant          Jane Eyre                        32   \n",
       "54101    1.0         the            Vilette                      7894   \n",
       "\n",
       "       book_total_word_count  term_frequency  n       idf    tf-idf  \n",
       "0                     121114        0.003410  1  1.386294  0.004727  \n",
       "1                     121114        0.002807  1  1.386294  0.003892  \n",
       "2                     192766        0.001619  1  1.386294  0.002244  \n",
       "3                     121114        0.002749  2  0.693147  0.001906  \n",
       "4                     121114        0.001354  1  1.386294  0.001877  \n",
       "...                      ...             ... ..       ...       ...  \n",
       "54097                 192766        0.000166  4  0.000000  0.000000  \n",
       "54098                 121114        0.000017  4  0.000000  0.000000  \n",
       "54099                 121114        0.000017  4  0.000000  0.000000  \n",
       "54100                 192766        0.000166  4  0.000000  0.000000  \n",
       "54101                 199315        0.039606  4  0.000000  0.000000  \n",
       "\n",
       "[54102 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "N = book_words_df['book'].nunique()\n",
    "n = book_words_df['n'] = book_words_df.groupby('word')['book'].transform('nunique')\n",
    "book_words_df['idf'] = np.log(N / n)\n",
    "book_words_df = book_words_df.rename(columns={'n_x': 'total_no_of_books', 'n_y': 'no_of_word_freq'}) # Give more meaningful names\n",
    "\n",
    "tf = book_words['term_frequency']\n",
    "idf = book_words_df['idf']\n",
    "book_words_df['tf-idf'] =  tf * idf\n",
    "\n",
    "sorted_book_words = book_words_df.sort_values(by='tf-idf', ascending = False)\n",
    "sorted_book_words.reset_index(drop = True, inplace = True)\n",
    "sorted_book_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_u0JGhQOglL"
   },
   "source": [
    "# Language Models\n",
    "\n",
    "A language model is a statistical model that can be used to estimate the probability of a sequence of words in a language. It is trained on a corpus of text data, and learns to predict the likelihood of observing a given sequence of words based on the frequency and context of those words in the training data.\n",
    "\n",
    "Language models can be used for a variety of natural language processing tasks, such as text generation, machine translation, speech recognition, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bm37SNTOvGA",
    "outputId": "11bca77e-e548-4213-c293-e754e1bb1422"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import FreqDist\n",
    "nltk.download('brown')\n",
    "\n",
    "# load the Brown corpus\n",
    "corpus = brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfxiAprLO-Mv"
   },
   "source": [
    "In this example, we're using the Brown corpus from the nltk library, which is a collection of text samples from a wide range of genres, including news, fiction, and academic writing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbFprAQ7O2Dr",
    "outputId": "0e873387-1b9e-488f-fb5f-bed10e0672cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['voters', '.', 'Despite', 'the', 'warning', ',', 'there', 'was', 'a', 'unanimous']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[1100:1110]) # Print a sample of 10 words from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYRy9zzpPXmU",
    "outputId": "a7c10de2-8845-4f63-f074-7a17ddcb345f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003970058353829513\n"
     ]
    }
   ],
   "source": [
    "# create a frequency distribution of the words in the corpus\n",
    "freq_dist = FreqDist(corpus)\n",
    "\n",
    "# calculate the total number of words in the corpus\n",
    "total_words = len(corpus)\n",
    "\n",
    "# calculate the probability of each word in the corpus\n",
    "word_probs = {word: freq_dist[word] / total_words for word in freq_dist.keys()}\n",
    "print(word_probs['high']) # Probability of the word 'high' to appear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R44oIEqZQ7ZH"
   },
   "source": [
    "### Naive sentence generation\n",
    "\n",
    "We're going to create a naive function that generates sentences using our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2Jvyrj5xP57X"
   },
   "outputs": [],
   "source": [
    "# generate a sentence using the language model\n",
    "import random\n",
    "\n",
    "def generate_sentence(word_length = 10):\n",
    "    sentence = []\n",
    "    while len(sentence) < word_length:\n",
    "        word = random.choices(list(word_probs.keys()), list(word_probs.values()))[0]\n",
    "        sentence.append(word)\n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Y1WFpEDRI8m",
    "outputId": "90c0bf86-007e-475b-9af9-9739c1867157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation protection of No. reason of from practice celebrated .\n"
     ]
    }
   ],
   "source": [
    "print(generate_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVKaPlxtTvDK"
   },
   "source": [
    "The sentences generated are likely not going to sound very good, since the model is extremely naive.\n",
    "\n",
    "All that is happening is that each word in the sentence gets semi-randomly generated with the likelihood of it being chosen depending on its frequency in the Brown corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5rdLQ64d8Sh"
   },
   "source": [
    "# N-grams\n",
    "\n",
    "So far we’ve considered words as individual units, and considered the relationship to their frequency of occurrence. However, many interesting text analyses are based on the relationships between words.\n",
    "One such relationship is given by n-grams.\n",
    "\n",
    "N-grams are groups of n consecutive words that appear in a given text corpus.\n",
    "\n",
    "Bigrams are groups of 2 consecutive words (e.g. she went, he ate, car crashed)\n",
    "\n",
    "Trigrams are groups of 3 consecutive words (e.g. she went home, he ate a, the car crashed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7ND9o70edTE",
    "outputId": "e63ce95e-b2b0-48a3-9b42-6aeabbd480fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what bigrams look like\n",
    "bigrams = list(nltk.bigrams(corpus))\n",
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdNw4vb3epgv",
    "outputId": "d2b39ea6-d856-4a90-c158-1a4aa63e4460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Fulton', 'County'),\n",
       " ('Fulton', 'County', 'Grand'),\n",
       " ('County', 'Grand', 'Jury'),\n",
       " ('Grand', 'Jury', 'said'),\n",
       " ('Jury', 'said', 'Friday'),\n",
       " ('said', 'Friday', 'an'),\n",
       " ('Friday', 'an', 'investigation'),\n",
       " ('an', 'investigation', 'of'),\n",
       " ('investigation', 'of', \"Atlanta's\"),\n",
       " ('of', \"Atlanta's\", 'recent')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of what trigrams look like\n",
    "trigrams = list(nltk.trigrams(corpus))\n",
    "trigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuGGY8x0UUQq"
   },
   "source": [
    "### Naive next word prediction\n",
    "\n",
    "Knowing that word relations are pretty important in our language, let's create a function that predicts what the next word in a sentence would be using a simple **bigram** language model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cD3005yIUgsa"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import random\n",
    "\n",
    "# get the words from the Brown corpus\n",
    "corpus = brown.words()\n",
    "\n",
    "# create bigrams from the corpus\n",
    "bigrams = list(nltk.bigrams(corpus))\n",
    "\n",
    "# calculate the frequency distribution of the bigrams\n",
    "bigram_freqdist = nltk.FreqDist(bigrams)\n",
    "\n",
    "# calculate the total number of bigrams in the corpus\n",
    "total_bigrams = len(bigrams)\n",
    "\n",
    "# create a function to generate the next word based on the previous word\n",
    "def generate_next_word(sentence):\n",
    "    prev_word = sentence.split()[-1]\n",
    "    possible_words = {}\n",
    "    for bigram in bigram_freqdist:\n",
    "        if bigram[0] == prev_word:\n",
    "            possible_words[bigram[1]] = bigram_freqdist[bigram] / total_bigrams\n",
    "    if possible_words:\n",
    "        return max(possible_words, key=possible_words.get)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDQ_R-uzWnGT",
    "outputId": "b2749b0e-63de-48a9-af76-f98809079fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted next word for 'The director' is 'of'\n"
     ]
    }
   ],
   "source": [
    "# predict the next word for a given context\n",
    "context = \"The director\"\n",
    "next_word = generate_next_word(context)\n",
    "print(f\"The predicted next word for '{context}' is '{next_word}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTYQq09KcDDi"
   },
   "source": [
    "### Exercise 3\n",
    "1. Create a function that takes as input the number of words and generates a sentence using the previous bigram language model. You can start with a random first word from the brown corpus and then use generate_next_word(sentence) function to help you. \n",
    "\n",
    "2. Create a function that predicts the next word of a sentence by looking at the previous two words. This means you will create a trigram language model - use the same Brown corpus as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "22aOcuOp1KhN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the same time , and\n"
     ]
    }
   ],
   "source": [
    "# Write your code below\n",
    "\n",
    "from nltk.corpus import brown\n",
    "import random\n",
    "\n",
    "corpus = brown.words()\n",
    "bigrams = list(nltk.bigrams(corpus))\n",
    "bigram_freqdist = nltk.FreqDist(bigrams)\n",
    "\n",
    "total_bigrams = len(bigrams)\n",
    "\n",
    "# create a function to generate the next word based on the previous word\n",
    "def generate_next_word(sentence):\n",
    "    prev_word = sentence.split()[-1]\n",
    "    possible_words = {}\n",
    "    for bigram in bigram_freqdist:\n",
    "        if bigram[0] == prev_word:\n",
    "            possible_words[bigram[1]] = bigram_freqdist[bigram] / total_bigrams\n",
    "    if possible_words:\n",
    "        next_word = max(possible_words, key=possible_words.get)\n",
    "        return next_word\n",
    "    else:\n",
    "        return None\n",
    "            \n",
    "def generate_sentence(no_of_words):\n",
    "    first_word = random.choice(corpus)\n",
    "    sentence = [first_word]\n",
    "    \n",
    "    for _ in range(no_of_words - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        next_word = generate_next_word(prev_word)\n",
    "        if next_word:\n",
    "            sentence.append(next_word)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return ' '.join(sentence)\n",
    "    \n",
    "print(generate_sentence(6))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL9S1oRBKDqW"
   },
   "source": [
    "### N-grams in dataframes\n",
    "\n",
    "Let's get back to our books.\n",
    "We'll create a dataframe containing information about the bigrams in our books corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "RH6clIKShSzo",
    "outputId": "be924a20-ff89-45b2-f61e-22908e60e6c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>eBook</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eBook</td>\n",
       "      <td>of</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Jane Eyre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1     Word 2       book\n",
       "0        The    Project  Jane Eyre\n",
       "1    Project  Gutenberg  Jane Eyre\n",
       "2  Gutenberg      eBook  Jane Eyre\n",
       "3      eBook         of  Jane Eyre\n",
       "4         of       Jane  Jane Eyre"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The simplest way to do this would be to create the dataframe directly from bigrams rather than unigrams (single words)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "bronte1_bigrams = list(nltk.bigrams(nltk.word_tokenize(bronte1)))\n",
    "bronte1_df = pd.DataFrame(bronte1_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "bronte2_bigrams = list(nltk.bigrams(nltk.word_tokenize(bronte2)))\n",
    "bronte2_df = pd.DataFrame(bronte2_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "bronte3_bigrams = list(nltk.bigrams(nltk.word_tokenize(bronte3)))\n",
    "bronte3_df = pd.DataFrame(bronte3_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "bronte4_bigrams = list(nltk.bigrams(nltk.word_tokenize(bronte4)))\n",
    "bronte4_df = pd.DataFrame(bronte4_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "\n",
    "# We’ll want to know which content comes from which book\n",
    "bronte1_df = bronte1_df.assign(book = 'Jane Eyre')\n",
    "bronte2_df = bronte2_df.assign(book = 'Wuthering Heights')\n",
    "bronte3_df = bronte3_df.assign(book = 'Vilette')\n",
    "bronte4_df = bronte4_df.assign(book = 'Agnes Grey')\n",
    "\n",
    "# Finally, we concatenate the books into one dataframe\n",
    "books = [bronte1_df, bronte2_df, bronte3_df, bronte4_df]\n",
    "bronte_books_df = pd.concat(books)\n",
    "bronte_books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bik8sbqukQ1A"
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "1. Add a **bigram** column that shows the entire bigrams (\"The Project\" and \"Project Gutenberg\" are examples of this column's values), not just the separate words.\n",
    "2. Clean the dataframe by removing stop words.\n",
    "3. Display the most frequently occuring 10 bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5ex48ATQLRmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>The Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Project Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>eBook</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Gutenberg eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eBook</td>\n",
       "      <td>of</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>eBook of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>of Jane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1     Word 2       book             bigram\n",
       "0        The    Project  Jane Eyre        The Project\n",
       "1    Project  Gutenberg  Jane Eyre  Project Gutenberg\n",
       "2  Gutenberg      eBook  Jane Eyre    Gutenberg eBook\n",
       "3      eBook         of  Jane Eyre           eBook of\n",
       "4         of       Jane  Jane Eyre            of Jane"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print('1')\n",
    "bronte_books_df['bigram'] = bronte_books_df['Word 1'] + ' ' + bronte_books_df['Word 2']\n",
    "bronte_books_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>The Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Project Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>eBook</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Gutenberg eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eBook</td>\n",
       "      <td>of</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>eBook of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>of Jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70908</th>\n",
       "      <td>newsletter</td>\n",
       "      <td>to</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>newsletter to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70909</th>\n",
       "      <td>to</td>\n",
       "      <td>hear</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>to hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70910</th>\n",
       "      <td>hear</td>\n",
       "      <td>about</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>hear about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70911</th>\n",
       "      <td>about</td>\n",
       "      <td>new</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>about new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70912</th>\n",
       "      <td>new</td>\n",
       "      <td>eBooks</td>\n",
       "      <td>Agnes Grey</td>\n",
       "      <td>new eBooks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574047 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1     Word 2        book             bigram\n",
       "0             The    Project   Jane Eyre        The Project\n",
       "1         Project  Gutenberg   Jane Eyre  Project Gutenberg\n",
       "2       Gutenberg      eBook   Jane Eyre    Gutenberg eBook\n",
       "3           eBook         of   Jane Eyre           eBook of\n",
       "4              of       Jane   Jane Eyre            of Jane\n",
       "...           ...        ...         ...                ...\n",
       "70908  newsletter         to  Agnes Grey      newsletter to\n",
       "70909          to       hear  Agnes Grey            to hear\n",
       "70910        hear      about  Agnes Grey         hear about\n",
       "70911       about        new  Agnes Grey          about new\n",
       "70912         new     eBooks  Agnes Grey         new eBooks\n",
       "\n",
       "[574047 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('2')\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "bronte_books_df = bronte_books_df[~bronte_books_df['bigram'].isin(english_stopwords)]\n",
    "bronte_books_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['good for', 'things that', 'speak truth', 'me without', 'tell what', 'and come', 'all very', 'he demanded', 'of whose', 'hills and', 'could she', 'made you', 'To my', 'put up', 'open it', 'by what', 'that might', 'Gutenberg eBooks', 'the aid', 'to inform', 'by Mrs', 'sat at', 'bell rang', 'lost the', 'was both', 'one can', 'I trembled', 'promise to', 'band of', 'Grange I', 'as strong', 'both in', 'a grave', 'owns a', 'the privilege', 'the act', 'I so', 'a ghost', 'thought a', 'my pocket', 'return the', 'hear her', 'that did', 'manage to', 'or he', 'into it', 'my hopes', 'one is', 'and help', 'pang of', 'still less', 'forgot to', 'house with', 'are they', 'some weeks', 'Ah you', 'much too', 'she only', 'fact of', 'stranger to', 'a mans', 'I leave', 'me is', 'the ceiling', 'finger and', 'between two', 'wrong to', 'the post', 'in upon', 'two miles', 'you What', 'has done', 'because they', 'was cold', 'have already', 'an excellent', 'a trifle', 'and watch', 'was some', 'at church', 'be you', 'governess and', 'more like', 'range of', 'far off', 'the strong', 'which your', 'too soon', 'the hill', 'read or', 'with strange', 'where a', 'was heard', 'he proceeded', 'I lifted', 'Besides I', 'I awoke', 'for being', 'think about', 'of happiness', 'her away', 'friend I', 'I resumed', 'might I', 'they thought', 'this young', 'such circumstances', 'held her', 'off his', 'eye I', 'from thence', 'woman who', 'mistress and', 'whence it', 'as when', 'a nice', 'flesh and', 'not worth', 'been her', 'thought as', 'doors and', 'liable to', 'knew her', 'we got', 'I experienced', 'had all', 'Madame had', 'way he', 'the greater', 'a beggar', 'about them', 'comes to', 'his absence', 'had set', 'fear and', 'Mr Bloomfield', 'she ran', 'treated me', 'no less', 'the nun', 'them But', 'if my', 'or so', 'father I', 'a husband', 'indeed it', 'No you', 'at work', 'by Mr', 'himself he', 'was another', 'asked in', 'day as', 'be taken', 'not because', 'like any', 'and called', 'means to', 'turned on', 'the lawn', 'shape of', 'are good', 'Well then', 'Earnshaw was', 'just what', 'cant help', 'Are they', 'you suppose', 'not likely', 'sat up', 'world was', 'this but', 'her there', 'your tongue', 'opened it', 'Miss Fanshawes', 'like them', 'believe in', 'all other', 'act of', 'a blow', 'black hair', 'convinced that', 'me good', 'dear I', 'him an', 'descended the', 'much less', 'A great', 'during which', 'he ought', 'the sallemanger', 'up by', 'the dogs', 'the fourth', 'a sofa', 'old acquaintance', 'something else', 'or something', 'her fingers', 'make of', 'time that', 'talk about', 'you Do', 'take his', 'Rochester was', 'pressure of', 'at liberty', 'will she', 'them away', 'the dim', 'waited till', 'she appeared', 'shocked at', 'wish for', 'for us', 'Isabella and', 'not altogether', 'substitute for', 'Im going', 'Mademoiselle St', 'said for', 'an odd', 'the berceau', 'that seemed', 'dint of', 'never come', 'that Miss', 'delight to', 'bright and', 'and mine', 'seated herself', 'so you', 'ground and', 'there will', 'kept his', 'strove to', 'shook her', 'to fulfil', 'duty and', 'and Edgar', 'you leave', 'order and', 'I brought', 'The whole', 'order of', 'hand as', 'knees and', 'son and', 'purpose of', 'dream of', 'the public', 'Where did', 'ill and', 'I certainly', 'refrain from', 'habits and', 'been an', 'fire of', 'you find', 'Heathcliff you', 'the upper', 'a soft', 'find the', 'of white', 'a similar', 'face the', 'held in', 'myself for', 'pupils and', 'she heard', 'heard from', 'her too', 'her lip', 'last to', 'asked for', 'suppose he', 'her friend', 'question I', 'clothes and', 'the liberty', 'the soul', 'sir You', 'same as', 'the stile', 'me Ill', 'that hour', 'my mistress', 'laughing at', 'did my', 'distance of', 'to trust', 'her so', 'there it', 'horses and', 'Mr and', 'the nearest', 'flow of', 'could hear', 'sure and', 'happy and', 'lost in', 'the causeway', 'happy as', 'Linton is', 'not forgotten', 'rather not', 'the opportunity', 'had its', 'again he', 'to cross', 'found me', 'the conclusion', 'was ever', 'his will', 'accompanied by', 'you wouldnt', 'was necessary', 'ask you', 'and been', 'them into', 'seeing me', 'and bid', 'something about', 'with pleasure', 'that house', 'wonder how', 'a spirit', 'to travel', 'hundreds of', 'had time', 'done so', 'you always', 'and partly', 'Mrs Murray', 'and added', 'glance at', 'that so', 'while it', 'doubt and', 'existence of', 'woman in', 'the existence', 'was good', 'variety of', 'Is this', 'reach the', 'came here', 'went down', 'lady I', 'the funeral', 'at Bretton', 'forgive me', 'to dine', 'wondered what', 'his last', 'still as', 'breath of', 'coming in', 'himself the', 'air was', 'path and', 'done to', 'his shoulder', 'standing at', 'to blame', 'the silent', 'would he', 'set in', 'if ever', 'walk in', 'frock and', 'felt sure', 'attempts to', 'made some', 'an air', 'He and', 'the will', 'didnt know', 'All this', 'He does', 'all sorts', 'the drive', 'you by', 'she in', 'and another', 'there be', 'present I', 'to M', 'influence of', 'Now you', 'cried Catherine', 'gentleman and', 'they should', 'her will', 'and quite', 'poor and', 'the pillow', 'the attic', 'are quite', 'like his', 'the large', 'glow of', 'care not', 'a clergyman', 'them The', 'But when', 'lady was', 'her now', 'wanted me', 'looked and', 'have all', 'and hands', 'of existence', 'said Madame', 'on our', 'the birds', 'a general', 'that which', 'Come in', 'said Yes', 'and wondered', 'a morsel', 'oclock and', 'her curls', 'one moment', 'He now', 'reader will', 'did Mr', 'it well', 'kissed me', 'to recall', 'copy of', 'then there', 'tempted to', 'Mr Heathcliffs', 'themselves with', 'to mention', 'was half', 'the works', 'them of', 'ignorant of', 'the porch', 'of affection', 'a model', 'done it', 'they say', 'than myself', 'With a', 'Dr Johns', 'some things', 'mixture of', 'forget that', 'At that', 'even for', 'Mrs Dent', 'the lesson', 'Such a', 'a deal', 'her an', 'her cheeks', 'the side', 'cried and', 'Yes yes', 'like your', 'closed and', 'a quick', 'a blessing', 'peace of', 'how do', 'on every', 'off with', 'off at', 'pleasant to', 'Heights I', 'turned the', 'it rather', 'I mounted', 'The young', 'feet I', 'the calm', 'you about', 'which to', 'never do', 'wont be', 'door in', 'to settle', 'the chimney', 'manner in', 'You said', 'heart of', 'and each', 'of flowers', 'Rochester has', 'minute I', 'by heart', 'opened my', 'the farm', 'him up', 'on for', 'so on', 'my dress', 'had little', 'as all', 'visit the', 'She will', 'her But', 'in French', 'a loss', 'eyes with', 'one word', 'daresay you', 'Catherine had', 'mode of', 'what could', 'Heathcliff to', 'Were you', 'said her', 'but Im', 'Joseph and', 'a square', 'as some', 'The old', 'should do', 'returned the', 'to attract', 'and pleasant', 'and lifted', 'kind I', 'saw nothing', 'near a', 'turned his', 'of money', 'they call', 'imagine that', 'endeavouring to', 'name was', 'of more', 'are an', 'your mother', 'happiness and', 'us for', 'to obtain', 'the speaker', 'me very', 'the leaves', 'the street', 'about and', 'shes a', 'Here was', 'of beauty', 'stayed to', 'half in', 'be said', 'that Dr', 'wont let', 'younger than', 'a cool', 'was lit', 'into which', 'be only', 'into that', 'informed me', 'of fire', 'my door', 'Fairfax had', 'ready and', 'youth and', 'two days', 'watching the', 'stood up', 'sunshine and', 'must make', 'my faculties', 'you knew', 'found in', 'soon I', 'set me', 'had happened', 'looking on', 'endure the', 'do in', 'attempting to', 'him than', 'among them', 'them too', 'law in', 'her back', 'were there', 'told that', 'smile I', 'You did', 'than it', 'my pillow', 'the ball', 'corner and', 'Dent and', 'evidence of', 'in doing', 'any longer', 'down his', 'her what', 'and our', 'species of', 'have one', 'work of', 'be all', 'limited to', 'the owner', 'wonder at', 'Im sorry', 'He will', 'back with', 'the inner', 'My little', 'sisters and', 'before we', 'a page', 'not aware', 'his words', 'follow the', 'nor was', 'may come', 'she do', 'thing she', 'them at', 'I laid', 'home but', 'John was', 'a favourite', 'God bless', 'know and', 'Must I', 'here to', 'considered it', 'of getting', 'vain I', 'she ought', 'was walking', 'the common', 'and sister', 'her beauty', 'my old', 'beside the', 'head on', 'the love', 'we heard', 'country where', 'rather too', 'at school', 'where to', 'sound and', 'I bent', 'with more', 'might do', 'charged with', 'am to', 'Gods sake', 'surprise and', 'sake I', 'yet but', 'seeming to', 'and mind', 'the true', 'my throat', 'not fail', 'most other', 'to laugh', 'for Gods', 'in by', 'the flesh', 'time a', 'had written', 'pain and', 'enter into', 'he often', 'God is', 'own eyes', 'in accordance', 'saying that', 'she showed', 'agreed to', 'your name', 'is and', 'be bound', 'rather the', 'meaning of', 'my home', 'laugh and', 'hold the', 'help you', 'eyes he', 'before us', 'neither the', 'me who', 'hard and', 'ask what']\n"
     ]
    }
   ],
   "source": [
    "print('3')\n",
    "occurences = list()\n",
    "for word, count in bronte_books_df['bigram'].value_counts().items():\n",
    "    if count == 10:\n",
    "        occurences.append(word)\n",
    "print(occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSWoIcukmqZ-"
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "1. Create a dataframe containing the **bigram, word1, word2** and **book** columns for the following 4 books and remove stop words:\n",
    "        https://www.gutenberg.org/cache/epub/1228/pg1228.txt - On the Origin of Species, by Charles Darwin\n",
    "\n",
    "        https://www.gutenberg.org/cache/epub/4363/pg4363.txt - Beyond Good and Evil, by Friedrich Nietzsche\n",
    "\n",
    "        https://www.gutenberg.org/cache/epub/3296/pg3296.txt - The Confessions of Saint Augustine, by Saint Augustine\n",
    "\n",
    "        https://www.gutenberg.org/files/1661/1661-0.txt - The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
    "\n",
    "2. Display the most frequent 8 words of each book (use word1 column when counting)\n",
    "\n",
    "3. Display the most relevant 8 words of each book based on tf-idf (use word1 column when counting)\n",
    "\n",
    "4. Display the most relevant 5 bigrams of each book based on tf-idf\n",
    "\n",
    "5. Display the most frequent 5 street names found in the entire 4 book corpus. The book they are coming from should also be visible.\n",
    "\n",
    "6. Choose a fixed word1 of your choice and find the most common 5 bigrams in each book that have word1 equal to the word you chose.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "OaylSr6OLM6W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of On the Origin of Species By Means of Natural Selection\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever You may copy it give it away or reuse it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at wwwgutenbergorg If you are not located in the United States\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook\n",
      "\n",
      "Title On the Origin of Species By Means of Natural Selection\n",
      "\n",
      "Author Charles Darwin\n",
      "\n",
      "Release date March 1 1998 eBook 1228\n",
      "                Most recently updated October 28 2023\n",
      "\n",
      "Language English\n",
      "\n",
      "Credits Sue Asscher and David Widger\n",
      "\n",
      "\n",
      " START OF THE PROJECT GUTENBERG EBOOK ON THE ORIGIN OF SPECIES BY MEANS OF NATURAL SELECTION \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "There are several editions of this ebook in the Project Gutenberg collection\n",
      "Various characteristics of each ebook are listed to aid in selecting the\n",
      "preferred file\n",
      "\n",
      "Click on any of the filenumbers below to quickly view each ebook\n",
      "\n",
      "1228    1859 First Edition\n",
      "22764   1860 Second Edition\n",
      "2009    1872 Sixth Edition considered the definitive edition\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "On\n",
      "the Origin of Species\n",
      "\n",
      "BY MEANS OF NATURAL SELECTION\n",
      "\n",
      "OR THE\n",
      "PRESERVATION OF FAVOURED RACES IN THE STRUGGLE FOR LIFE\n",
      "\n",
      "By Charles Darwin MA\n",
      "\n",
      "Fellow Of The Royal Geological Linnan Etc Societies\n",
      "Author Of Journal Of Researches During HMS Beagles Voyage\n",
      "Round The World\n",
      "\n",
      "LONDON\n",
      "JOHN MURRAY ALBEMARLE STREET\n",
      "1859\n",
      "\n",
      "But with regard to the material world we can at least go so far as\n",
      "thiswe can perceive that events are brought about not by insulated\n",
      "interpositions of Divine power exerted in each particular case but by the\n",
      "establishment of general laws\n",
      "\n",
      "W WHEWELL Bridgewater Treatise\n",
      "\n",
      "To conclude therefore let no man out of a weak conceit of sobriety or\n",
      "an illapplied moderation think or maintain that a man can search too far or\n",
      "be too well studied in the book of Gods word or in the book of\n",
      "Gods works divinity or philosophy but rather let men endeavour an\n",
      "endless progress or proficience in both\n",
      "\n",
      "BACON Advancement of Learning\n",
      "\n",
      "Down Bromley Kent\n",
      "    October 1st 1859\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      " INTRODUCTION\n",
      " 1 VARIATION UNDER DOMESTICATION\n",
      " 2 VARIATION UNDER NATURE\n",
      " 3 STRUGGLE FOR EXISTENCE\n",
      " 4 NATURAL SELECTION\n",
      " 5 LAWS OF VARIATION\n",
      " 6 DIFFICULTIES ON THEORY\n",
      " 7 INSTINCT\n",
      " 8 HYBRIDISM\n",
      " 9 ON THE IMPERFECTION OF THE GEOLOGICAL RECORD\n",
      " 10 ON THE GEOLOGICAL SUCCESSION OF ORGANIC BEINGS\n",
      " 11 GEOGRAPHICAL DISTRIBUTION\n",
      " 12 GEOGRAPHICAL DISTRIBUTIONcontinued\n",
      " 13 MUTUAL AFFINITIES OF ORGANIC BEINGS MORPHOLOGY\n",
      " 14 RECAPITULATION AND CONCLUSION\n",
      " INDEX\n",
      "\n",
      "DETEAILED CONTENTS ON THE ORIGIN OF SPECIES\n",
      "\n",
      "INTRODUCTION\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CHAPTER I VARIATION UNDER DOMESTICATION\n",
      "\n",
      "  Causes of Variability\n",
      "  Effects of Habit\n",
      "  Correlation of Growth\n",
      "  Inheritance\n",
      "  Character of Domestic Varieties\n",
      "  Difficulty of distinguishing between Varieties and Species\n",
      "  Origin of Domestic Varieties from one or more Species\n",
      "  Domestic Pigeons their Differences and Origin\n",
      "  Principle of Selection anciently followed its Effects\n",
      "  Methodical and Unconscious Selection\n",
      "  Unknown Origin of our Domestic Productions\n",
      "  Circumstances favourable to Mans power of Selection\n",
      "\n",
      "CHAPTER 2 VARIATION UNDER NATURE\n",
      "\n",
      "  Variability\n",
      "  Individual Differences\n",
      "  Doubtful species\n",
      "  Wide ranging much diffused and common species vary most\n",
      "  Species of the larger genera in any country vary more than the\n",
      "  species of the smaller genera\n",
      "  Many of the species of the larger genera resemble varieties in being\n",
      "  very closely but unequally related to each other and in having\n",
      "  restricted ranges\n",
      "\n",
      "CHAPTER 3 STRUGGLE FOR EXISTENCE\n",
      "\n",
      "  Bears on natural selection\n",
      "  The term used in a wide sense\n",
      "  Geometrical powers of increase\n",
      "  Rapid increase of naturalised animals and plants\n",
      "  Nature of the checks to increase\n",
      "  Competition universal\n",
      "  Effects of climate\n",
      "  Protection from the number of individuals\n",
      "  Complex relations of all animals and plants throughout nature\n",
      "  Struggle for life most severe between individuals and varieties of\n",
      "  the same species often severe between species of the same genus\n",
      "  The relation of organism to organism the most important of all\n",
      "  relations\n",
      "\n",
      "CHAPTER 4 NATURAL SELECTION\n",
      "\n",
      "  Natural Selection its power compared with mans selection its power\n",
      "  on characters of trifling importance its power at all ages and on\n",
      "  both sexes\n",
      "  Sexual Selection\n",
      "  On the generality of intercrosses between individuals of the same\n",
      "  species\n",
      "  Circumstances favourable and unfavourable to Natural Selection\n",
      "  namely intercrossing isolation number of individuals\n",
      "  Slow action\n",
      "  Extinction caused by Natural Selection\n",
      "  Divergence of Character related to the diversity of inhabitants of\n",
      "  any small area and to naturalisation\n",
      "  Action of Natural Selection through Divergence of Character and\n",
      "  Extin\n",
      "The Project Gutenberg eBook of Beyond Good and Evil\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever You may copy it give it away or reuse it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at wwwgutenbergorg If you are not located in the United States\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook\n",
      "\n",
      "Title Beyond Good and Evil\n",
      "\n",
      "Author Friedrich Wilhelm Nietzsche\n",
      "\n",
      "Translator Helen Zimmern\n",
      "\n",
      "Release date August 1 2003 eBook 4363\n",
      "                Most recently updated January 9 2019\n",
      "\n",
      "Language English\n",
      "\n",
      "Credits Produced by John Mamoun Charles Franks David Widger and the Online\n",
      "        Distributed Proofreading Team\n",
      "\n",
      "\n",
      " START OF THE PROJECT GUTENBERG EBOOK BEYOND GOOD AND EVIL \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Produced by John Mamoun Charles Franks and the Online\n",
      "Distributed Proofreading Team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "BEYOND GOOD AND EVIL\n",
      "\n",
      "By Friedrich Nietzsche\n",
      "\n",
      "\n",
      "Translated by Helen Zimmern\n",
      "\n",
      "\n",
      "\n",
      "TRANSCRIBERS NOTE ABOUT THIS ETEXT EDITION\n",
      "\n",
      "The following is a reprint of the Helen Zimmern translation from German\n",
      "into English of Beyond Good and Evil as published in The Complete\n",
      "Works of Friedrich Nietzsche 19091913 Some adaptations from the\n",
      "original text were made to format it into an etext Italics in the\n",
      "original book are capitalized in this etext except for most foreign\n",
      "language phrases that were italicized Original footnotes are put in\n",
      "brackets  at the points where they are cited in the text Some\n",
      "spellings were altered Today and Tomorrow are spelled today\n",
      "and tomorrow Some words containing the letters ise in the original\n",
      "text such as idealise had these letters changed to ize such as\n",
      "idealize Sceptic was changed to skeptic\n",
      "\n",
      "\n",
      "TABLE OF CONTENTS\n",
      "\n",
      "    PREFACE\n",
      "    BEYOND GOOD AND EVIL\n",
      "\n",
      "    CHAPTER I    PREJUDICES OF PHILOSOPHERS\n",
      "    CHAPTER II   THE FREE SPIRIT\n",
      "    CHAPTER III  THE RELIGIOUS MOOD\n",
      "    CHAPTER IV   APOPHTHEGMS AND INTERLUDES\n",
      "    CHAPTER V    THE NATURAL HISTORY OF MORALS\n",
      "    CHAPTER VI   WE SCHOLARS\n",
      "    CHAPTER VII  OUR VIRTUES\n",
      "    CHAPTER VIII PEOPLES AND COUNTRIES\n",
      "    CHAPTER IX   WHAT IS NOBLE\n",
      "\n",
      "    FROM THE HEIGHTS POEM TRANSLATED BY LA MAGNUS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a womanwhat then Is there not ground\n",
      "for suspecting that all philosophers in so far as they have been\n",
      "dogmatists have failed to understand womenthat the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to Truth have been unskilled and unseemly methods for\n",
      "winning a woman Certainly she has never allowed herself to be won and\n",
      "at present every kind of dogma stands with sad and discouraged mienIF\n",
      "indeed it stands at all For there are scoffers who maintain that it\n",
      "has fallen that all dogma lies on the groundnay more that it is at\n",
      "its last gasp But to speak seriously there are good grounds for hoping\n",
      "that all dogmatizing in philosophy whatever solemn whatever conclusive\n",
      "and decided airs it has assumed may have been only a noble puerilism\n",
      "and tyronism and probably the time is at hand when it will be once\n",
      "and again understood WHAT has actually sufficed for the basis of such\n",
      "imposing and absolute philosophical edifices as the dogmatists have\n",
      "hitherto reared perhaps some popular superstition of immemorial time\n",
      "such as the soulsuperstition which in the form of subject and\n",
      "egosuperstition has not yet ceased doing mischief perhaps some\n",
      "play upon words a deception on the part of grammar or an\n",
      "audacious generalization of very restricted very personal very\n",
      "humanalltoohuman facts The philosophy of the dogmatists it is to\n",
      "be hoped was only a promise for thousands of years afterwards as was\n",
      "astrology in still earlier times in the service of which probably more\n",
      "labour gold acuteness and patience have been spent than on any\n",
      "actual science hitherto we owe to it and to its superterrestrial\n",
      "pretensions in Asia and Egypt the grand style of architecture It seems\n",
      "that in order to inscribe themselves upon the heart of humanity with\n",
      "everlasting claims all great things have first to wander about the\n",
      "earth as enormous and aweinspiring caricatures dogmatic philosophy has\n",
      "been a caricature of this kindfor instance the Vedanta doctrine in\n",
      "Asia and Platonism in Europe Let us not be ungrateful to it although\n",
      "it must certainly be confessed that the worst the most tiresome\n",
      "and the most dangerous of errors hitherto has been a dogmatist\n",
      "errornamely Platos invention of Pure Spirit and the Good in Itself\n",
      "But now when it has been surmounted when Europe rid of this nightmare\n",
      "can again draw breath freely and at least enjoy a healthiersleep\n",
      "we WHOSE DUTY IS WAKEFULNESS ITSELF are the heirs of all the strength\n",
      "which the struggle against this error has fostered It amounted to\n",
      "the very inversion of truth and the denial of the PERSPECTIVEthe\n",
      "fundamental conditionof life to s\n",
      "The Project Gutenberg eBook of The Confessions of St Augustine\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever You may copy it give it away or reuse it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at wwwgutenbergorg If you are not located in the United States\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook\n",
      "\n",
      "Title The Confessions of St Augustine\n",
      "\n",
      "Author Bishop of Hippo Saint Augustine\n",
      "\n",
      "Translator E B Pusey\n",
      "\n",
      "Release date June 1 2002 eBook 3296\n",
      "                Most recently updated May 5 2023\n",
      "\n",
      "Language English\n",
      "\n",
      "Credits Robert S Munday\n",
      "\n",
      "\n",
      " START OF THE PROJECT GUTENBERG EBOOK THE CONFESSIONS OF ST AUGUSTINE \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE CONFESSIONS OF SAINT AUGUSTINE\n",
      "\n",
      "By Saint Augustine\n",
      "\n",
      "Bishop of Hippo\n",
      "\n",
      "Translated by E B Pusey Edward Bouverie\n",
      "\n",
      "\n",
      "AD 401\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "BOOK I\n",
      "\n",
      "\n",
      "Great art Thou O Lord and greatly to be praised great is Thy power\n",
      "and Thy wisdom infinite And Thee would man praise man but a particle\n",
      "of Thy creation man that bears about him his mortality the witness of\n",
      "his sin the witness that Thou resistest the proud yet would man praise\n",
      "Thee he but a particle of Thy creation Thou awakest us to delight in\n",
      "Thy praise for Thou madest us for Thyself and our heart is restless\n",
      "until it repose in Thee Grant me Lord to know and understand which is\n",
      "first to call on Thee or to praise Thee and again to know Thee or\n",
      "to call on Thee for who can call on Thee not knowing Thee for he that\n",
      "knoweth Thee not may call on Thee as other than Thou art Or is it\n",
      "rather that we call on Thee that we may know Thee but how shall they\n",
      "call on Him in whom they have not believed or how shall they believe\n",
      "without a preacher and they that seek the Lord shall praise Him for\n",
      "they that seek shall find Him and they that find shall praise Him\n",
      "I will seek Thee Lord by calling on Thee and will call on Thee\n",
      "believing in Thee for to us hast Thou been preached My faith Lord\n",
      "shall call on Thee which Thou hast given me wherewith Thou hast\n",
      "inspired me through the Incarnation of Thy Son through the ministry of\n",
      "the Preacher\n",
      "\n",
      "And how shall I call upon my God my God and Lord since when I call\n",
      "for Him I shall be calling Him to myself and what room is there within\n",
      "me whither my God can come into me whither can God come into me God\n",
      "who made heaven and earth is there indeed O Lord my God aught in me\n",
      "that can contain Thee do then heaven and earth which Thou hast made\n",
      "and wherein Thou hast made me contain Thee or because nothing which\n",
      "exists could exist without Thee doth therefore whatever exists contain\n",
      "Thee Since then I too exist why do I seek that Thou shouldest enter\n",
      "into me who were not wert Thou not in me Why because I am not gone\n",
      "down in hell and yet Thou art there also For if I go down into hell\n",
      "Thou art there I could not be then O my God could not be at all\n",
      "wert Thou not in me or rather unless I were in Thee of whom are all\n",
      "things by whom are all things in whom are all things Even so Lord\n",
      "even so Whither do I call Thee since I am in Thee or whence canst\n",
      "Thou enter into me for whither can I go beyond heaven and earth that\n",
      "thence my God should come into me who hath said I fill the heaven and\n",
      "the earth\n",
      "\n",
      "Do the heaven and earth then contain Thee since Thou fillest them or\n",
      "dost Thou fill them and yet overflow since they do not contain Thee\n",
      "And whither when the heaven and the earth are filled pourest Thou\n",
      "forth the remainder of Thyself or hast Thou no need that aught contain\n",
      "Thee who containest all things since what Thou fillest Thou fillest\n",
      "by containing it for the vessels which Thou fillest uphold Thee not\n",
      "since though they were broken Thou wert not poured out And when Thou\n",
      "art poured out on us Thou art not cast down but Thou upliftest us\n",
      "Thou art not dissipated but Thou gatherest us But Thou who fillest\n",
      "all things fillest Thou them with Thy whole self or since all things\n",
      "cannot contain Thee wholly do they contain part of Thee and all at\n",
      "once the same part or each its own part the greater more the smaller\n",
      "less And is then one part of Thee greater another less or art Thou\n",
      "wholly every where while nothing contains Thee wholly\n",
      "\n",
      "What art Thou then my God what but the Lord God For who is Lord\n",
      "but the Lord or who is God save our God Most highest most good most\n",
      "potent most omnipotent most merciful yet most just most hidden\n",
      "yet most present most beautiful yet most strong stable yet\n",
      "incomprehensible unchangeable yet allchanging never new never old\n",
      "allrenewing and bringing age upon the proud and they know it not\n",
      "ever working ever at rest still gathering yet nothing lacking\n",
      "supporting filling and overspreading creating nourishing and\n",
      "maturing seeking yet having all things Thou lovest without passion\n",
      "art jealous without anxiety repentest yet grievest not art angry\n",
      "yet serene changest Thy works Thy\n",
      "The Project Gutenberg eBook of The Adventures of Sherlock Holmes\n",
      "by Arthur Conan Doyle\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever You may copy it give it away or reuse it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "wwwgutenbergorg If you are not located in the United States you\n",
      "will have to check the laws of the country where you are located before\n",
      "using this eBook\n",
      "\n",
      "Title The Adventures of Sherlock Holmes\n",
      "\n",
      "Author Arthur Conan Doyle\n",
      "\n",
      "Release Date November 29 2002 eBook 1661\n",
      "Most recently updated October 10 2023\n",
      "\n",
      "Language English\n",
      "\n",
      "Character set encoding UTF8\n",
      "\n",
      "Produced by an anonymous Project Gutenberg volunteer and Jose Menendez\n",
      "\n",
      " START OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK\n",
      "HOLMES \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Adventures of Sherlock Holmes\n",
      "\n",
      "by Arthur Conan Doyle\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "   I     A Scandal in Bohemia\n",
      "   II    The RedHeaded League\n",
      "   III   A Case of Identity\n",
      "   IV    The Boscombe Valley Mystery\n",
      "   V     The Five Orange Pips\n",
      "   VI    The Man with the Twisted Lip\n",
      "   VII   The Adventure of the Blue Carbuncle\n",
      "   VIII  The Adventure of the Speckled Band\n",
      "   IX    The Adventure of the Engineers Thumb\n",
      "   X     The Adventure of the Noble Bachelor\n",
      "   XI    The Adventure of the Beryl Coronet\n",
      "   XII   The Adventure of the Copper Beeches\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I A SCANDAL IN BOHEMIA\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "To Sherlock Holmes she is always the woman I have seldom heard him\n",
      "mention her under any other name In his eyes she eclipses and\n",
      "predominates the whole of her sex It was not that he felt any emotion\n",
      "akin to love for Irene Adler All emotions and that one particularly\n",
      "were abhorrent to his cold precise but admirably balanced mind He\n",
      "was I take it the most perfect reasoning and observing machine that\n",
      "the world has seen but as a lover he would have placed himself in a\n",
      "false position He never spoke of the softer passions save with a gibe\n",
      "and a sneer They were admirable things for the observerexcellent for\n",
      "drawing the veil from mens motives and actions But for the trained\n",
      "reasoner to admit such intrusions into his own delicate and finely\n",
      "adjusted temperament was to introduce a distracting factor which might\n",
      "throw a doubt upon all his mental results Grit in a sensitive\n",
      "instrument or a crack in one of his own highpower lenses would not\n",
      "be more disturbing than a strong emotion in a nature such as his And\n",
      "yet there was but one woman to him and that woman was the late Irene\n",
      "Adler of dubious and questionable memory\n",
      "\n",
      "I had seen little of Holmes lately My marriage had drifted us away\n",
      "from each other My own complete happiness and the homecentred\n",
      "interests which rise up around the man who first finds himself master\n",
      "of his own establishment were sufficient to absorb all my attention\n",
      "while Holmes who loathed every form of society with his whole Bohemian\n",
      "soul remained in our lodgings in Baker Street buried among his old\n",
      "books and alternating from week to week between cocaine and ambition\n",
      "the drowsiness of the drug and the fierce energy of his own keen\n",
      "nature He was still as ever deeply attracted by the study of crime\n",
      "and occupied his immense faculties and extraordinary powers of\n",
      "observation in following out those clues and clearing up those\n",
      "mysteries which had been abandoned as hopeless by the official police\n",
      "From time to time I heard some vague account of his doings of his\n",
      "summons to Odessa in the case of the Trepoff murder of his clearing up\n",
      "of the singular tragedy of the Atkinson brothers at Trincomalee and\n",
      "finally of the mission which he had accomplished so delicately and\n",
      "successfully for the reigning family of Holland Beyond these signs of\n",
      "his activity however which I merely shared with all the readers of\n",
      "the daily press I knew little of my former friend and companion\n",
      "\n",
      "One nightit was on the twentieth of March 1888I was returning from a\n",
      "journey to a patient for I had now returned to civil practice when\n",
      "my way led me through Baker Street As I passed the wellremembered\n",
      "door which must always be associated in my mind with my wooing and\n",
      "with the dark incidents of the Study in Scarlet I was seized with a\n",
      "keen desire to see Holmes again and to know how he was employing his\n",
      "extraordinary powers His rooms were brilliantly lit and even as I\n",
      "looked up I saw his tall spare figure pass twice in a dark silhouette\n",
      "against the blind He was pacing the room swiftly eagerly with his\n",
      "head sunk upon his chest and his hands clasped behind him To me who\n",
      "knew his every mood and habit his attitude and manner told their own\n",
      "story He was at work again He had risen out of his drugcreated\n",
      "dreams and was hot upon the scent of some new problem I rang the bell\n",
      "and was shown up to the chamber which had formerly been in part my own\n",
      "\n",
      "His manner was not effusive It seldom was but he was glad I think\n",
      "to see me With hardly a word spoken but wit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>The Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>Project Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>eBook</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>Gutenberg eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eBook</td>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>eBook of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>On</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>of On</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word 1     Word 2                      book             bigram\n",
       "0        The    Project  On the Origin of Species        The Project\n",
       "1    Project  Gutenberg  On the Origin of Species  Project Gutenberg\n",
       "2  Gutenberg      eBook  On the Origin of Species    Gutenberg eBook\n",
       "3      eBook         of  On the Origin of Species           eBook of\n",
       "4         of         On  On the Origin of Species              of On"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code below\n",
    "\n",
    "import requests\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "print('1')\n",
    "# On the Origin of Species, by Charles Darwin\n",
    "book_url = 'https://www.gutenberg.org/cache/epub/1228/pg1228.txt'\n",
    "response = requests.get(book_url)\n",
    "on_the_origin_of_species = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "on_the_origin_of_species = ''.join(c for c in on_the_origin_of_species if c in allowed_chars)\n",
    "\n",
    "print(on_the_origin_of_species[:5000])\n",
    "\n",
    "# Beyond Good and Evil, by Friedrich Nietzsche\n",
    "book_url = 'https://www.gutenberg.org/cache/epub/4363/pg4363.txt'\n",
    "response = requests.get(book_url)\n",
    "beyond_good_evil = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "beyond_good_evil = ''.join(c for c in beyond_good_evil if c in allowed_chars)\n",
    "\n",
    "print(beyond_good_evil[:5000])\n",
    "\n",
    "# The Confessions of Saint Augustine, by Saint Augustine\n",
    "book_url = ' https://www.gutenberg.org/cache/epub/3296/pg3296.txt'\n",
    "response = requests.get(book_url)\n",
    "the_confessions_of_saint_augustine = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "the_confessions_of_saint_augustine = ''.join(c for c in the_confessions_of_saint_augustine if c in allowed_chars)\n",
    "\n",
    "print(the_confessions_of_saint_augustine[:5000])\n",
    "\n",
    "# The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
    "book_url = 'https://www.gutenberg.org/files/1661/1661-0.txt'\n",
    "response = requests.get(book_url)\n",
    "the_adventures_of_sherlock_holmes = response.text\n",
    "allowed_chars = string.ascii_letters + string.digits + string.whitespace\n",
    "the_adventures_of_sherlock_holmes = ''.join(c for c in the_adventures_of_sherlock_holmes if c in allowed_chars)\n",
    "\n",
    "print(the_adventures_of_sherlock_holmes[:5000])\n",
    "\n",
    "# Creating dataframes\n",
    "on_the_origin_of_species_lines = on_the_origin_of_species.splitlines()\n",
    "on_the_origin_of_species_df = pd.DataFrame({\n",
    "    \"line\": on_the_origin_of_species_lines,\n",
    "    \"line_number\": list(range(len(on_the_origin_of_species_lines)))\n",
    "})\n",
    "\n",
    "beyond_good_evil_lines = beyond_good_evil.splitlines()\n",
    "beyond_good_evil_df = pd.DataFrame({\n",
    "    \"line\": beyond_good_evil_lines,\n",
    "    \"line_number\": list(range(len(beyond_good_evil_lines)))\n",
    "})\n",
    "\n",
    "the_confessions_of_saint_augustine_lines = the_confessions_of_saint_augustine.splitlines()\n",
    "the_confessions_of_saint_augustine_df = pd.DataFrame({\n",
    "    \"line\": the_confessions_of_saint_augustine_lines,\n",
    "    \"line_number\": list(range(len(the_confessions_of_saint_augustine_lines)))\n",
    "})\n",
    "\n",
    "the_adventures_of_sherlock_holmes_lines = the_adventures_of_sherlock_holmes.splitlines()\n",
    "the_adventures_of_sherlock_holmes_df = pd.DataFrame({\n",
    "    \"line\": the_adventures_of_sherlock_holmes_lines,\n",
    "    \"line_number\": list(range(len(the_adventures_of_sherlock_holmes_lines)))\n",
    "})\n",
    "\n",
    "# Tokenizing the data \n",
    "on_the_origin_of_species_bigrams = list(nltk.bigrams(nltk.word_tokenize(on_the_origin_of_species)))\n",
    "on_the_origin_of_species_df = pd.DataFrame(on_the_origin_of_species_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "beyond_good_evil_bigrams = list(nltk.bigrams(nltk.word_tokenize(beyond_good_evil)))\n",
    "beyond_good_evil_df = pd.DataFrame(beyond_good_evil_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "the_confessions_of_saint_augustine_bigrams = list(nltk.bigrams(nltk.word_tokenize(the_confessions_of_saint_augustine)))\n",
    "the_confessions_of_saint_augustine_df = pd.DataFrame(the_confessions_of_saint_augustine_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "the_adventures_of_sherlock_holmes_bigrams = list(nltk.bigrams(nltk.word_tokenize(the_adventures_of_sherlock_holmes)))\n",
    "the_adventures_of_sherlock_holmes_df = pd.DataFrame(the_adventures_of_sherlock_holmes_bigrams, columns=['Word 1', 'Word 2'])\n",
    "\n",
    "\n",
    "\n",
    "# Assigning the name to each book\n",
    "on_the_origin_of_species_df = on_the_origin_of_species_df.assign(book='On the Origin of Species')\n",
    "beyond_good_evil_df = beyond_good_evil_df.assign(book='Beyond Good and Evil')\n",
    "the_confessions_of_saint_augustine_df = the_confessions_of_saint_augustine_df.assign(book='The Confessions of Saint Augustine')\n",
    "the_adventures_of_sherlock_holmes_df = the_adventures_of_sherlock_holmes_df.assign(book='The Adventures of Sherlock Holmes')\n",
    "\n",
    "books = [on_the_origin_of_species_df, beyond_good_evil_df, the_confessions_of_saint_augustine_df, the_adventures_of_sherlock_holmes_df]\n",
    "four_author_books_df = pd.concat(books)\n",
    "four_author_books_df.head()\n",
    "\n",
    "four_author_books_df['bigram'] = four_author_books_df['Word 1'] + ' ' + four_author_books_df['Word 2']\n",
    "four_author_books_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['Means', 'restrictions', 'reuse', 'Means', 'START', 'EBOOK', 'NATURAL', 'file', 'NATURAL', 'World', 'NATURAL', '7', '9', 'distinguishing', 'Struggle', 'NATURAL', 'Sexual', 'lowly', 'Means', 'non', 'facit', 'saltum', '7', 'Sterility', 'Sterility', 'Hybrids', '9', 'Means', 'fifteen', 'Struggle', 'kingdoms', 'distinguishing', 'treatment', 'treatment', 'tame', 'sets', 'copious', 'Sterility', 'treatment', 'treatment', 'larva', 'cats', 'breeder', 'viewing', 'caterpillar', 'boldly', 'Whether', 'assert', 'poultry', 'uniformity', 'competent', 'competent', 'endurance', 'competent', 'poultry', 'kingdoms', 'expressly', 'nostrils', 'heels', 'pouter', 'tailfeathers', 'vertebr', 'nostrils', 'remarkably', 'pouter', 'pouter', 'pouter', 'tailfeathers', 'tailfeathers', 'tailfeathers', 'firstly', 'carriers', 'firstly', 'tailfeathers', 'bill', 'poultry', 'breeder', 'bold', 'host', 'devoted', 'competent', 'acquainted', 'skilful', 'breeder', 'breeder', 'requisite', 'skilful', 'pick', 'objected', 'methodical', 'rude', 'improve', 'methodical', 'improve', 'competent', 'carriers', 'acquainted', 'kitchen', 'improve', 'pouter', 'methodical', 'tailfeathers', 'tailfeathers', 'communication', 'slightest', 'cats', 'cats', 'endurance', 'temporary', 'II', 'implied', 'collect', 'competent', '251', '139', 'Azores', 'lastly', 'descend', 'tables', 'tables', 'sets', 'tables', 'inorganic', 'tables', 'oftener', 'ie', 'tables', 'tables', 'sections', 'firstly', 'Struggle', 'Struggle', 'kingdoms', 'twentyfive', 'breeder', 'fifteen', 'incredible', 'diffusion', 'assert', 'attack', 'winter', 'winter', 'southward', 'oftener', 'diffusion', 'winter', 'twentyfive', 'flourished', 'Surrey', 'yard', 'vigorously', 'southward', 'hawks', 'alter', 'nicely', 'web', 'Lobelia', 'visits', 'visits', 'cats', 'cats', 'Russia', 'hunt', 'vigorously', 'prompt', 'NATURAL', 'Sexual', 'surrounded', 'occurring', 'nicely', 'methodical', 'appearances', 'slightest', 'slightest', 'preserving', 'silently', 'inorganic', 'winter', 'preserving', 'hawks', 'host', 'caterpillar', 'poultry', 'larva', 'larva', 'Sexual', 'Sexual', 'Sexual', 'Sexual', 'improve', 'wounds', 'hooked', 'carriers', 'improve', 'methodical', 'hunting', 'hunt', 'bulky', 'petals', 'largest', 'weather', 'commence', 'push', 'weather', 'entrance', 'push', 'visits', 'visits', 'Lobelia', 'sets', 'Lobelia', 'surrounded', 'objected', 'kingdoms', 'Though', 'methodical', 'breeder', 'alter', 'polity', 'uniformity', 'uniformity', 'preserving', 'inorganic', 'checking', 'checking', 'surrounded', 'yielded', 'polity', 'improve', 'polity', 'oftener', 'intermittent', 'accords', 'polity', 'Struggle', 'bulky', 'noted', 'polity', 'Take', 'struggled', 'representing', 'numbered', 'failing', 'numbered', 'distinguishing', 'distinguishing', 'polity', 'capital', 'fifteen', 'lastly', 'capital', 'representing', 'crust', 'throws', 'polity', 'kingdoms', 'Sexual', 'Whether', 'balance', 'distinguishing', 'sections', 'file', 'connexion', 'flourished', 'crust', 'lowly', 'accords', 'warm', 'slightest', 'wingless', 'beast', 'wingless', 'wingless', 'membrane', 'struggled', 'requisite', 'Azores', 'positively', 'push', 'China', 'Jerusalem', 'collect', 'larva', 'petals', 'Hilaire', 'cats', 'pick', 'flow', 'loses', 'petals', 'petals', 'slightest', 'occurring', 'copious', 'poultry', 'distinguishing', 'loses', 'Hilaire', 'vertebr', 'proposition', 'unusually', 'unusually', 'largest', 'remarkably', 'shaken', 'carriers', 'carriers', 'unusually', 'comparatively', 'Hilaire', 'connexion', 'proposition', 'tailfeathers', 'pouter', 'representing', 'occurring', 'inquiries', 'China', 'appearances', 'asserts', 'plainer', 'assert', 'Means', 'non', 'facit', 'saltum', 'staggered', 'crust', 'crust', 'sounding', 'comparatively', 'comparatively', 'improve', 'firstly', 'polity', 'intermittent', 'winter', 'collect', 'membrane', 'lengthened', 'plainer', 'membrane', 'plainer', 'membrane', 'nerve', 'nerve', 'descend', 'stratum', 'commence', 'nerve', 'nerve', 'membrane', 'nerve', 'surfaces', 'watching', 'alteration', 'alteration', 'pick', 'larva', 'asserts', 'non', 'facit', 'saltum', 'incredible', 'driving', 'charming', 'copious', 'balance', 'withdrawn', 'assert', 'non', 'facit', 'saltum', 'inorganic', 'remarkably', 'recover', 'P', 'caterpillar', 'caterpillar', 'sixth', 'caterpillar', 'sixth', 'caterpillar', 'sixth', 'acquainted', 'preserving', 'non', 'facit', 'saltum', 'acquainted', 'assert', 'tame', 'tastes', 'driving', 'hunt', 'heels', 'methodical', 'improve', 'hunt', 'sufficed', 'tame', 'tame', 'tame', 'attack', 'poultry', 'attack', 'poultry', 'attack', 'cats', 'sufficed', 'slavemaking', 'hunting', 'Formica', 'hunger', 'slavemaking', 'Formica', 'P', 'slavemaking', 'Surrey', 'Surrey', 'unusually', 'twentyfive', 'Switzerland', 'expressly', 'Switzerland', 'vigorously', 'slavemaking', 'attack', 'slavemaking', 'file', 'collect', 'Formica', 'Switzerland', 'slavemaking', 'Switzerland', 'collect', 'collect', 'Switzerland', 'Switzerland', 'Formica', 'skilful', 'hive', 'hive', 'surfaces', 'surfaces', 'surfaces', 'centres', 'centres', 'centres', 'surfaces', 'requisite', 'rude', 'ie', 'sixth', 'hive', 'plates', 'plates', 'hive', 'push', 'warm', 'plates', 'plates', 'rude', 'plates', 'plates', 'balance', 'alternately', 'commence', 'fifteen', 'hive', 'hive', 'winter', 'hive', 'collect', 'winter', 'closer', 'surfaces', 'surfaces', 'simpler', 'plates', 'hooked', 'fat', 'breeder', 'watching', 'flourished', 'incredible', 'simpler', 'Formica', 'assert', 'positively', 'lastly', 'instruments', 'non', 'facit', 'saltum', 'deduction', 'satisfactory', 'Sterility', 'Sterility', 'Hybrids', 'Hybrids', 'devoted', 'asserts', 'positively', 'Hybrids', 'visits', 'Lobelia', 'Lobelia', 'asserts', 'breeder', 'P', 'P', 'Sterility', 'kingdoms', 'inorganic', 'Hybrids', 'remarkably', 'lastly', 'flow', 'yielded', 'Lobelia', 'rude', 'endurance', 'Sterility', 'closer', 'unwilling', 'Hybrids', 'unusually', 'occurring', 'methodical', 'alter', 'hostile', 'asserts', 'incredible', 'hostile', 'asserts', 'yielded', 'Hybrids', 'uniformity', 'sixth', 'occurring', 'stratum', 'pouter', 'pouter', 'objected', 'sufficed', 'stratum', 'charged', 'sand', 'sand', 'crust', 'implied', 'Mississippi', 'river', 'viewing', 'volcanic', 'crust', 'Though', 'requisite', 'yard', 'yard', 'sand', 'partially', 'Russia', 'skilful', 'charged', 'accords', 'intermittent', 'streams', 'balance', 'bulky', 'intermittent', 'requisite', 'noted', 'Mississippi', 'Mississippi', 'intermittent', 'representing', 'Russia', 'sand', 'Pictet', 'comparatively', 'stratum', '50', 'skilful', 'stratum', 'positively', 'Pictet', 'Ocean', 'stratum', 'satisfactory', 'stratum', 'competent', 'Russia', 'partially', 'Ocean', 'Switzerland', 'Pictet', 'temporary', 'satisfactory', 'Whether', 'inorganic', 'intermittent', 'inorganic', 'incredible', 'Pictet', 'accords', 'stratum', 'slower', 'ie', 'slower', 'unusually', 'accords', 'sections', 'Russia', 'skilful', 'competent', 'temporary', 'diffusion', 'diffusion', 'slower', 'accords', 'alter', 'asserts', 'objected', 'proposition', 'numbered', 'objected', 'satisfactory', 'sixth', 'carriers', 'Pictet', 'shaken', 'Pictet', 'acquainted', 'occurring', 'skilful', 'Pictet', 'comparatively', 'accords', 'World', 'bold', 'latitude', 'uniformity', 'failing', 'link', 'closer', 'Means', 'World', 'World', 'World', 'latitude', 'impassable', 'impassable', 'southward', 'impassable', 'impassable', 'Ocean', 'latitude', 'positively', 'checking', 'sections', 'comparatively', 'incredible', 'sections', 'volcanic', 'centres', 'centres', 'Means', 'impassable', 'volcanic', 'volcanic', 'seawater', '87', '18', '18', 'alternately', 'drifted', '50', 'seawater', 'positively', '18', 'hawks', 'hawks', 'hawks', 'charged', 'icebergs', 'Azores', 'latitude', 'icebergs', 'seawater', 'Ocean', 'inorganic', 'surfaces', 'streams', 'glaciers', 'drifted', 'icebergs', 'southward', 'descend', 'southward', 'remarkably', 'satisfactory', 'warm', 'satisfactory', 'uniformity', 'Ocean', 'latitude', 'latitude', 'uniformity', 'warm', 'Ocean', 'impassable', 'southward', 'World', 'host', 'World', 'southward', 'glaciers', 'glaciers', 'host', 'intertropical', 'volcanic', 'representing', 'representing', 'oftener', 'closer', 'twentyfive', 'intertropical', 'twentyfive', 'latitude', 'intertropical', 'southward', 'intertropical', 'surrounded', 'cover', 'intertropical', 'yielded', 'intertropical', 'yielded', 'yielded', 'intertropical', 'icebergs', 'icebergs', 'flowed', 'flowed', 'impassable', 'flow', 'occurring', 'charged', 'theories', 'latitude', 'ie', 'Bermuda', 'Bermuda', 'Bermuda', 'struggled', 'wingless', 'hooked', 'hooked', 'hooked', 'hooked', 'Azores', 'seawater', 'icebergs', 'volcanic', 'Though', 'Island', 'Ocean', 'Bermuda', 'sections', 'seawater', 'drifted', 'seawater', 'seawater', 'seawater', 'twentyfive', 'volcanic', 'volcanic', 'icebergs', 'drifted', 'partially', 'closer', 'sets', 'Island', 'Island', 'Island', 'Island', 'Island', 'checking', 'diffusion', 'firstly', 'slower', 'centres', 'communication', 'endurance', 'partially', 'revealed', 'serviceable', 'serviceable', 'nostrils', 'Hilaire', 'connexion', 'serviceable', 'sections', 'fifteen', 'sections', 'requisite', 'serviceable', 'appearances', 'failing', 'partially', 'link', 'link', 'pick', 'representing', 'connexion', 'web', 'Hilaire', 'connexion', 'expressly', 'membrane', 'lengthened', 'membrane', 'alter', 'connexion', 'connexion', 'vertebr', 'petals', 'transformed', 'simpler', 'petals', 'vertebr', 'vertebr', 'kingdoms', 'vertebr', 'vertebr', 'larva', 'larva', 'caterpillar', 'larva', 'answering', 'magnificent', 'lowly', 'positively', 'caterpillar', 'largest', 'carriers', 'firstly', 'requisite', 'connexion', 'partially', 'plainer', 'membrane', 'petals', 'lastly', 'failing', 'non', 'facit', 'saltum', 'diffusion', 'diffusion', 'charged', 'objected', 'link', 'intermittent', 'preserving', 'Struggle', 'balance', 'slightest', 'balance', 'struggled', 'slightest', 'non', 'facit', 'saltum', 'waste', 'throws', 'diffusion', 'oftener', 'endurance', 'intertropical', 'serviceable', 'vertebr', 'petals', 'demand', 'essence', 'essence', 'simpler', 'throws', 'loses', 'crust', 'simpler', 'slower', 'accords', 'largest', 'implied', 'Struggle', '375', '139', '139', '139', 'glaciers', 'slavemaking', 'Jerusalem', '163', 'eating', '375', '72', 'Azores', 'hive', 'wingless', 'Bermuda', 'Bermuda', 'wingless', '134', '451', '18', '163', 'Azores', 'hawks', '251', '375', 'hawks', '201', '72', '375', '76', 'checking', '139', '76', '451', 'drifted', 'centres', '20', 'grafts', '139', '134', '18', '7', '87', 'Island', 'eating', 'intermittent', 'Formica', 'Formica', 'Formica', 'Hilaire', 'Hilaire', 'grafts', '134', 'Azores', '72', '163', 'eating', 'glaciers', '375', 'glaciers', '375', '18', '72', '163', 'P', 'Hybrids', '375', 'Bermuda', '7', '451', '76', 'Lobelia', 'Lobelia', 'P', 'icebergs', 'wingless', 'tame', '451', 'Means', '76', 'Mississippi', '375', 'Russia', '201', '201', '251', '50', '134', '134', 'Ocean', '201', '72', '201', '251', 'grafts', '251', 'Pictet', '20', '87', 'carriers', 'hawks', '451', '163', '139', 'grafts', '76', '201', '72', '251', 'grafts', 'grafts', 'hooked', '20', 'hooked', '87', '87', 'Sexual', '87', '76', 'slavemaking', 'grafts', '9', '72', 'Sterility', '9', 'Hilaire', 'cats', '18', '163', '201', 'Struggle', '76', '451', 'grafts', '451', '134', '7', '251', 'Azores', '134', '451', 'wingless', 'World', '163', 'EBOOK', 'NATURAL', 'Terms', 'concept', 'registered', 'START', 'FULL', 'LICENSE', 'FULL', 'LICENSE', 'promoting', 'available', 'file', 'Terms', 'registered', '1C', '1E', '1C', 'promoting', '1E', 'prominently', 'restrictions', 'reuse', 'prominently', 'Plain', 'Vanilla', 'ASCII', 'Plain', 'Vanilla', 'ASCII', 'viewing', '20', 'agreed', 'Royalty', 'Royalty', 'email', 'computer', 'computer', 'WARRANTY', 'DAMAGES', 'damages', 'AGREE', 'BREACH', 'WARRANTY', 'BREACH', 'AGREE', 'DAMAGES', 'SUCH', 'lieu', 'electronically', 'electronically', 'lieu', 'demand', 'WARRANTIES', 'WARRANTIES', 'implied', 'damages', 'disclaimer', 'interpreted', 'disclaimer', 'alteration', 'computers', 'computers', 'walks', 'available', 'Mississippi', 'federal', 'federal', 'Donations', 'widespread', '50', 'solicit', 'wwwgutenbergorgdonate', 'solicit', 'treatment', 'web', 'Donations', 'wwwgutenbergorgdonate', 'concept', 'email', 'restrictions', 'reuse', '9', 'START', 'EBOOK', 'GOOD', 'GOOD', 'GOOD', 'II', 'NATURAL', 'sufficed', 'superstition', 'attack', 'plainer', 'magnificent', 'GOOD', 'impatiently', 'teaches', 'covetousness', 'lap', 'firstly', 'estimates', 'tastes', 'anew', 'anew', 'proposition', 'cheerful', 'HIS', 'terror', 'SUCH', '7', 'envy', '9', 'extravagant', 'fruitful', 'eagerness', 'subtlety', 'extravagant', 'vigorously', 'throws', 'market', 'loses', 'boldly', 'theories', 'flourished', 'superstition', 'contains', '18', 'owes', 'deduction', 'firstly', 'obeying', 'obeying', 'commence', 'instruments', 'obeying', '20', 'paths', 'extravagant', 'push', 'modes', 'equality', 'modes', 'tyranny', 'psychology', 'psychology', 'envy', 'covetousness', 'drifted', 'demand', 'psychology', 'psychology', 'II', 'cheerful', 'Take', 'enmity', 'GOOD', 'watching', 'tastes', 'hunger', 'motives', 'river', 'loses', 'equality', 'viewing', 'vice', 'tastes', 'turns', 'impatiently', 'China', 'superstition', 'interpreted', 'agreed', 'deceiving', 'estimates', 'Does', 'interpreted', 'HIS', 'extravagant', 'paths', 'communication', 'push', 'vice', 'expressly', 'comfort', 'vigorously', 'subtlety', 'formula', 'agreeable', 'acute', 'tables', 'hunt', 'alas', 'hunting', 'HIS', 'subtlety', 'serviceable', 'hunt', 'widespread', 'agreeable', 'terribly', 'implied', 'formula', 'formula', 'attitude', 'superstition', 'psychology', 'psychology', 'pious', 'throws', 'balance', 'nice', 'SUCH', 'attitude', '50', 'feminine', 'girls', 'sayings', 'literature', 'tame', 'amazed', 'Book', 'subtlety', 'religions', 'Island', 'glances', 'modes', 'religions', 'centres', 'solve', 'pious', 'religions', 'envy', 'teaches', 'astray', 'selfcontrol', 'selfcontrol', 'religions', 'religions', 'HIS', 'terribly', 'attitude', 'religions', 'religions', 'comfort', 'estimates', 'Men', 'sublime', 'equality', 'teacher', '72', '76', 'tyranny', 'ashes', '87', 'simpler', 'turns', 'pious', 'hostile', 'HIS', '134', '139', 'gets', '163', 'wheels', 'meanwhile', 'NATURAL', 'awkward', 'GOOD', 'awkward', 'agreed', 'proposition', 'proposition', 'proposition', 'essence', 'tyranny', 'tyranny', 'tyranny', 'tyranny', 'extravagant', 'tyranny', 'magnificent', 'teaches', 'teaches', 'hunger', 'anew', 'unpleasant', 'teacher', 'motives', 'awkward', 'satisfactory', 'motives', 'silently', 'hostile', 'slightest', 'desirable', 'desirable', 'desirable', 'awkward', 'gets', 'HIS', 'teacher', 'beast', 'Does', 'bold', 'eagerness', 'obeying', 'instruments', 'Napoleon', 'Napoleon', 'subtlety', 'selfcontrol', '201', 'estimates', 'equality', 'unwilling', 'awkward', 'formula', 'feminine', 'threatened', 'estimates', 'paths', 'transformed', 'alteration', 'sigh', 'extravagant', 'estimates', 'magnificent', 'gets', 'gets', 'hesitating', 'file', 'envy', 'instruments', 'oftener', 'sets', 'HIS', 'alas', 'impatiently', 'impatiently', 'cloud', 'comprehended', 'charming', 'Russia', 'attitude', 'Russia', 'entrance', 'masculine', 'masculine', 'resolute', 'expressly', 'feminine', 'Though', 'instruments', 'instruments', 'equality', 'transformed', 'equality', 'asserts', 'bold', 'incredible', 'hesitating', 'subtlety', 'bold', 'shine', 'shine', 'alternately', 'formula', 'attitude', 'enmity', 'subtlety', 'forgive', 'fat', 'plainer', 'goods', 'equality', 'appearances', 'tastes', 'wonders', 'waste', 'tastes', 'religions', 'sixth', 'hesitating', 'expressly', 'brave', 'selfcontrol', 'hostile', 'GOOD', 'shine', 'checking', 'Whether', 'modes', 'modes', 'misfortune', 'misfortune', 'appearances', 'appearances', 'sigh', 'agreeable', 'vice', 'desirable', 'desirable', 'literature', 'vice', 'motives', 'partially', 'beast', 'beast', 'pious', 'anew', 'boldly', 'beast', 'sublime', 'psychology', 'attitude', 'sublime', 'extravagant', 'SUCH', 'anew', 'feminine', 'charming', 'agreeable', 'sets', 'hostile', 'glances', 'Napoleon', 'eloquent', 'feminine', 'kitchen', 'girls', 'turns', 'interpreted', 'feminine', 'masculine', 'alas', 'hostile', 'descend', 'desirable', 'masculine', 'masculine', 'feminine', 'masculine', 'lastly', 'Napoleon', 'magnificent', 'oftener', 'anew', 'excitement', 'hesitating', 'meanwhile', 'tastes', 'Whether', 'formula', 'serviceable', 'assert', 'alas', 'Napoleon', 'acquainted', 'gets', 'hesitating', 'sand', 'extravagant', 'Napoleon', 'Napoleon', 'Switzerland', 'threatened', 'silently', 'endurance', 'modes', 'owes', '251', 'alternately', 'resolute', 'alter', 'alter', 'hostile', 'pious', 'nostrils', 'unpleasant', 'SUCH', 'alas', 'appearances', 'literature', 'requisite', 'noted', 'HIS', 'alternately', 'anew', 'anew', 'Napoleon', 'modes', 'literature', 'sublime', 'boldly', 'cheerful', 'meanwhile', 'instruments', 'obeying', 'formula', 'Men', 'brilliant', 'sublime', 'instruments', 'unwilling', 'revealed', 'oftener', 'distinguishing', 'noted', 'glances', 'brave', 'enmity', 'warm', 'envy', 'estimates', 'warm', 'subtlety', 'brilliant', 'owes', 'owes', 'demand', 'uniformity', 'teaches', 'owes', 'magnificent', 'brotherly', 'owes', 'tyranny', 'shoes', 'rude', 'appearances', 'envy', 'essence', 'sublime', 'drinking', 'occurring', 'closer', 'closer', 'prompt', 'desirable', 'estimates', 'unusually', 'expressly', 'devoted', 'psychology', 'unwilling', 'temporary', 'acquainted', 'Men', 'Does', 'agreeable', 'plates', 'hunger', 'tables', 'selfcontrol', 'selfcontrol', 'motives', 'cheerful', 'vice', 'sublime', 'comprehended', 'II', 'eloquent', 'formula', 'deceiving', 'representing', 'desirable', 'stranger', 'wounds', 'wounds', 'alas', 'descend', 'closer', 'teaches', 'sand', 'hushed', 'agreeable', 'cover', 'agreeable', 'brave', 'charming', 'glaciers', 'cloud', 'glaciers', '7', 'Go', '9', 'EBOOK', 'GOOD', 'Terms', 'concept', 'registered', 'START', 'FULL', 'LICENSE', 'FULL', 'LICENSE', 'promoting', 'available', 'file', 'Terms', 'registered', '1C', '1E', '1C', 'promoting', '1E', 'prominently', 'restrictions', 'reuse', 'prominently', 'Plain', 'Vanilla', 'ASCII', 'Plain', 'Vanilla', 'ASCII', 'viewing', '20', 'agreed', 'Royalty', 'Royalty', 'email', 'computer', 'computer', 'WARRANTY', 'DAMAGES', 'damages', 'AGREE', 'BREACH', 'WARRANTY', 'BREACH', 'AGREE', 'DAMAGES', 'SUCH', 'lieu', 'electronically', 'electronically', 'lieu', 'demand', 'WARRANTIES', 'WARRANTIES', 'implied', 'damages', 'disclaimer', 'interpreted', 'disclaimer', 'alteration', 'computers', 'computers', 'walks', 'available', 'Mississippi', 'federal', 'federal', 'Donations', 'widespread', '50', 'solicit', 'wwwgutenbergorgdonate', 'solicit', 'treatment', 'web', 'Donations', 'wwwgutenbergorgdonate', 'concept', 'email', 'restrictions', 'reuse', 'START', 'EBOOK', 'contains', 'gathering', 'eloquent', 'offend', 'ashes', 'riches', 'elders', 'essence', 'essence', 'flowed', 'flow', 'elders', 'elders', 'glances', 'elders', 'riches', 'paths', 'elders', 'elders', 'elders', 'eagerness', 'pious', 'confessing', 'obeying', 'numbered', 'wept', 'wept', 'entrance', 'temper', 'confessing', 'feigned', 'lap', 'setting', 'lap', 'drunk', 'astray', 'seest', 'darkened', 'waste', 'darkened', 'teacher', 'offend', 'wounds', 'enmity', 'surrounded', 'heed', 'heed', 'envy', 'deceiving', 'eagerness', 'liked', 'meanwhile', 'quarrel', 'II', 'failing', 'gathering', 'meanwhile', 'confessing', 'chaste', 'copious', 'vice', 'chaste', 'fled', 'heed', 'temper', 'hunger', 'stole', 'stole', 'eating', 'liked', 'goods', 'goods', 'goods', 'riches', 'stole', 'deceiving', 'withdrawn', 'turns', 'darkened', 'confessing', 'stole', 'sufficed', 'inflamed', 'excitement', 'stole', 'stole', 'liked', 'astray', 'wanting', 'longed', 'feigned', 'transformed', 'feigned', 'inflamed', 'deceiving', 'contains', 'longed', 'inflamed', 'devout', 'inflamed', 'drunk', 'resolved', 'lowly', 'answering', 'confessing', 'bold', 'cover', 'obeying', 'flow', 'offences', 'guilty', 'offences', 'agreed', 'restored', 'envy', 'offences', 'guilty', 'boldly', 'covetousness', 'offences', 'offences', 'offend', 'wept', 'capital', 'cheerful', 'answering', 'chaste', 'puffed', 'Go', 'deceiving', 'hunting', 'guilty', 'Though', 'superstition', 'astray', 'Lords', 'skilful', 'acquainted', 'agreeable', 'meanwhile', 'restored', 'amazed', 'comfort', 'darkened', 'beheld', 'wanting', 'wept', 'loses', 'wept', 'unwilling', 'feigned', 'impatiently', 'wept', 'withdrawn', 'fled', 'restored', 'turns', 'loses', 'turns', 'Out', 'descend', 'Go', 'bridegroom', 'amazed', 'numbered', 'wonders', 'bulky', 'drunk', 'astray', 'sand', 'comprehended', 'slower', 'seest', 'fled', 'fled', 'fled', 'sand', 'puffed', 'failing', 'paths', 'numbered', 'descend', 'darkened', 'Surely', 'teacher', 'sayings', 'longed', 'solve', 'eloquent', 'copious', 'teacher', 'shine', 'communicate', 'liked', 'literature', 'meanwhile', 'teacher', 'feigned', 'preserving', 'streams', 'enmity', 'recover', 'chaste', 'altar', 'deceiving', 'resolved', 'comprehended', 'host', 'eagerness', 'slower', 'liked', 'offences', 'liked', 'setting', 'devout', 'eloquent', 'teacher', 'flowed', 'resolved', 'resolute', 'shaken', 'copious', 'pious', 'superstition', 'communication', 'Lords', 'yielded', 'comfort', 'busy', 'preserving', 'enquiring', 'Lords', 'enquiring', 'comprehended', 'lastly', 'sounding', 'offend', 'temporary', 'plainer', 'unwilling', 'superstition', 'incredible', 'eagerness', 'Though', 'fight', 'bold', 'resolute', 'drunk', 'drinking', 'guilty', 'fight', 'beheld', 'lawyer', 'gathering', 'goods', 'enquiring', 'covetousness', 'enmity', 'unwilling', 'riches', 'acute', 'viewing', 'teaches', 'amazed', 'fantastic', 'resolved', 'Out', 'acute', 'acute', 'paths', 'comfort', 'staggered', 'fight', 'sayings', 'sufficed', 'enquiring', 'feigned', 'goods', 'struggled', 'acute', 'paths', 'riches', 'telling', 'longed', 'attack', 'noted', 'sufficed', 'ashes', 'puffed', 'comprehended', 'lowly', 'lowly', 'darkened', 'beast', 'beheld', 'sigh', 'beheld', 'fruitful', 'puffed', 'lowly', 'sayings', 'puffed', 'wounds', 'withdrawn', 'lowly', 'revealed', 'host', 'shone', 'devoted', 'Out', 'setting', 'paths', 'inflamed', 'marry', 'Surely', 'recover', 'revealed', 'contains', 'offend', 'enmity', 'guilty', 'Go', 'hushed', 'restored', 'restored', 'walks', 'drinking', 'hunger', 'Men', 'alternately', 'inflamed', 'serviceable', 'obeying', 'eloquent', 'resolute', 'fight', 'wanting', 'amazed', 'fruitful', 'resolved', 'unwilling', 'setting', 'beheld', 'kingdoms', 'superstition', 'host', 'longed', 'Take', 'heed', 'rent', 'rent', 'covetousness', 'rent', 'sets', 'sets', 'recover', 'hesitating', 'chaste', 'fruitful', 'Take', 'Take', 'checking', 'Go', 'riches', 'resolved', 'buy', 'resolved', 'agreed', 'burned', 'lengthened', 'recover', 'feigned', 'covetousness', 'masculine', 'beheld', 'setting', 'waste', 'goods', 'Selfsame', 'Selfsame', 'Lords', 'fifteen', 'wonders', 'flowed', 'devout', 'amazed', 'confessing', 'shone', 'Court', 'devout', 'girls', 'heed', 'drinking', 'elders', 'quarrel', 'quarrel', 'chaste', 'temper', 'husbands', 'husbands', 'endurance', 'enquiring', 'streams', 'Selfsame', 'shine', 'hushed', 'hushed', 'hushed', 'hushed', 'hushed', 'hushed', 'withdrawn', 'withdrawn', 'amazed', 'checking', 'Lords', 'altar', 'amazed', 'Whether', 'flowed', 'comfort', 'rent', 'answering', 'deceiving', 'interpreted', 'wept', 'wept', 'shaken', 'enquiring', 'wounds', 'forgive', 'forgive', 'offences', 'owes', 'devout', 'Jerusalem', 'longed', 'silently', 'silently', 'brotherly', 'brotherly', 'stranger', 'brotherly', 'sigh', 'offences', 'sigh', 'ashes', 'eating', 'report', 'ie', 'nostrils', 'tastes', 'throat', 'flowed', 'Out', 'wanting', 'beheld', 'literature', 'Whether', 'nostrils', 'heed', 'collect', 'ie', 'objected', 'objected', 'contains', 'contains', 'Does', 'enquiring', 'noted', 'restored', 'loses', 'recover', 'eloquent', 'eloquent', 'hunger', 'burned', 'wounds', 'endurance', 'enjoinest', 'enjoinest', 'enjoinest', 'enjoinest', 'enjoinest', 'enjoinest', 'eating', 'drinking', 'fight', 'hunger', 'eating', 'drinking', 'Go', 'enjoinest', 'Take', 'eating', 'drinking', 'throat', 'brotherly', 'devout', 'withdrawn', 'shoes', 'pious', 'waste', 'report', 'wonders', 'Jerusalem', 'telling', 'offend', 'beast', 'forgive', 'tame', 'enjoinest', 'riches', 'goods', 'fat', 'brotherly', 'seest', 'wounds', 'report', 'distinguishing', 'ie', 'beheld', 'covetousness', 'communicate', 'confessing', 'burned', 'brotherly', 'seest', 'forgive', 'report', 'cloud', 'sounding', 'sounding', 'assure', 'astray', 'boldly', 'boldly', 'wonders', 'boldly', 'lengthened', 'Whether', 'slower', 'Does', 'sounding', 'lengthened', 'sixth', 'report', 'sounding', 'report', 'report', 'lengthened', 'comfort', 'rent', 'flow', 'copious', 'enquiring', 'Lords', 'Lords', 'longed', 'Selfsame', 'Selfsame', 'Selfsame', 'numbered', 'numbered', 'darkened', 'astray', 'Lords', 'wonders', 'sublime', 'chaste', 'chaste', 'Selfsame', 'sigh', 'astray', 'Jerusalem', 'Jerusalem', 'Jerusalem', 'Though', 'rude', 'comprehended', 'ie', 'confessing', 'alteration', 'Out', 'comprehended', 'gathering', 'teaches', 'terribly', 'brotherly', 'puffed', 'offend', 'sayings', 'sayings', 'streams', 'streams', 'streams', 'sounding', 'alas', 'cheerful', 'Book', 'copious', 'offend', 'revealed', 'flow', 'owes', 'wanting', 'restored', 'inflamed', 'Jerusalem', 'essence', 'lastly', 'Surely', 'Selfsame', 'transformed', 'streams', 'sigh', 'cloud', 'gathering', 'temporary', 'Book', 'shine', 'fruitful', 'Go', 'covetousness', 'shine', 'shine', 'wonders', 'Book', 'flowed', 'sayings', 'entrance', 'entrance', 'wonders', 'entrance', 'Go', 'heed', 'transformed', 'transformed', 'Book', 'gathering', 'devout', 'sayings', 'modes', 'fruitful', 'devout', 'yielded', 'flourished', 'flourished', 'communicate', 'flourished', 'fruitful', 'enmity', 'seest', 'seest', 'flow', 'setting', 'Book', 'riches', 'Book', 'fruitful', 'seest', 'setting', 'Book', 'seest', 'EBOOK', 'Terms', 'concept', 'registered', 'START', 'FULL', 'LICENSE', 'FULL', 'LICENSE', 'promoting', 'available', 'file', 'Terms', 'registered', '1C', '1E', '1C', 'promoting', '1E', 'prominently', 'restrictions', 'reuse', 'prominently', 'Plain', 'Vanilla', 'ASCII', 'Plain', 'Vanilla', 'ASCII', 'viewing', '20', 'agreed', 'Royalty', 'Royalty', 'email', 'computer', 'computer', 'WARRANTY', 'DAMAGES', 'damages', 'AGREE', 'BREACH', 'WARRANTY', 'BREACH', 'AGREE', 'DAMAGES', 'SUCH', 'lieu', 'electronically', 'electronically', 'lieu', 'demand', 'WARRANTIES', 'WARRANTIES', 'implied', 'damages', 'disclaimer', 'interpreted', 'disclaimer', 'alteration', 'computers', 'computers', 'walks', 'available', 'Mississippi', 'federal', 'federal', 'Donations', 'widespread', '50', 'solicit', 'wwwgutenbergorgdonate', 'solicit', 'treatment', 'web', 'Donations', 'wwwgutenbergorgdonate', 'concept', 'email', 'restrictions', 'reuse', 'START', 'EBOOK', 'II', 'Copper', 'Beeches', 'motives', 'drifted', 'lodgings', 'clearing', 'clearing', 'attitude', 'burned', 'deduction', 'weather', 'walks', 'deduction', 'capital', 'theories', 'theories', 'P', 'P', 'cloud', 'wheels', 'nice', 'wore', 'suggestive', 'communicate', 'shrugged', 'impatiently', 'resolute', 'marry', 'wheels', 'II', 'surrounded', 'failing', 'inflamed', 'pockets', 'watching', 'lawyer', 'visits', 'remarkably', 'twentyfive', 'altar', 'altar', 'altar', 'marry', 'bridegroom', 'prompt', 'driving', 'busy', 'acute', 'remarkably', 'lawyer', 'resolved', 'wheels', 'quarrel', 'heels', 'Hes', 'brave', 'Surely', 'nicely', 'watching', 'prompt', 'pockets', 'Ive', 'coffee', 'lawyer', 'staggered', 'resolute', 'threatened', 'II', 'proposition', 'Jabez', 'puffed', 'column', 'wore', 'frockcoat', 'glances', 'China', 'Jabez', 'telling', 'China', 'China', 'literature', 'China', 'Jabez', 'column', '7', 'Court', 'telling', 'Jabez', 'Spaulding', 'market', 'vice', 'Spaulding', 'Men', 'gets', 'nice', 'Men', 'Spaulding', 'Court', 'Spaulding', 'Spaulding', 'Jabez', 'lengthened', 'awkward', 'Spaulding', 'Jabez', 'Spaulding', 'Court', '9', 'staggered', 'temporary', 'Jabez', 'pick', 'Spaulding', 'excitement', 'prompt', 'bill', 'fight', 'vigorously', 'coffee', 'alternately', 'brilliant', 'hunt', 'frockcoat', 'hunting', 'hunting', 'fantastic', 'stranger', 'Hes', 'Hes', 'Ive', 'Ive', 'turns', 'brave', 'gets', 'lantern', 'lantern', 'lantern', 'sufficed', 'contains', 'lantern', 'lantern', 'assure', 'acute', 'bulky', 'lengthened', 'withdrawn', 'lantern', 'hunting', 'Hes', 'fantastic', 'temporary', 'inquiries', 'Jabez', 'link', 'shrugged', 'lodgings', 'stranger', 'wanting', 'report', 'essence', 'husbands', 'column', 'push', 'clearing', 'drifted', 'Take', 'brilliant', 'simpler', 'hesitating', 'communication', 'fifteen', 'Court', 'nicely', 'fifteen', 'stole', 'shrugged', 'walks', 'suggestive', 'throat', 'hesitating', 'wore', 'marry', 'coffee', 'deduction', 'noted', 'frockcoat', 'bridegroom', 'busy', 'girls', 'misfortune', 'devoted', 'waste', 'fantastic', 'solve', 'pockets', 'girls', 'girls', 'hunting', 'suggestive', 'revealed', 'prompt', 'largest', 'equality', 'quarrel', 'fight', 'noted', 'positively', 'feigned', 'guilty', 'suggestive', 'wheels', 'yard', 'yard', 'temper', 'terribly', 'Coroner', 'Coroner', 'Coroner', 'quarrel', 'Coroner', 'assure', 'Coroner', 'Coroner', 'Coroner', 'Coroner', 'column', 'alternately', 'quarrel', 'wore', 'nice', 'cloud', 'plainer', 'excitement', 'shrugged', 'quarrel', 'glances', 'wheels', 'clearing', 'lodgings', 'nice', 'charming', 'marry', 'Bermuda', 'failing', 'rent', 'Does', 'theories', 'theories', 'widespread', 'wore', 'transformed', 'Men', 'darkened', 'shone', 'nostrils', 'silently', 'heels', 'largest', 'gathering', 'busy', 'Surely', 'shrugged', 'lodgings', 'commence', 'ashes', 'devoted', 'ashes', 'nostrils', 'answering', 'market', 'rent', 'threatened', 'marry', 'Though', 'beast', 'cover', 'cloud', 'partially', '87', 'deduction', 'clearing', 'weather', 'solve', 'liked', 'liked', 'terror', 'lawyer', 'lawyer', 'ashes', 'burned', 'descend', 'lawyer', 'terror', 'cover', 'brave', 'comfort', 'suggestive', 'burned', 'ashes', 'burned', 'assert', 'web', 'guilty', 'meanwhile', 'threatened', 'Waterloo', 'fantastic', 'link', 'literature', 'lawyer', 'Men', 'charming', 'Does', 'driving', 'fantastic', 'flourished', 'weather', 'busy', 'inquiries', 'commence', 'coffee', 'Waterloo', 'Waterloo', 'Waterloo', 'river', 'shaken', 'web', 'river', 'resolute', 'glances', 'lap', 'selfcontrol', 'husbands', 'Swandam', 'Lane', 'surrounded', 'Swandam', 'Lane', 'river', 'fantastic', 'Out', 'heed', 'nerve', 'selfcontrol', 'bill', 'wheels', 'river', 'shrugged', 'nicely', 'Swandam', 'Lane', 'Swandam', 'Lane', 'Swandam', 'Lane', 'terribly', 'feminine', 'wore', 'staggered', 'Out', 'Out', 'husbands', 'lap', 'walks', 'Surely', 'pockets', 'river', 'pockets', 'throws', 'Surrey', 'inquiries', 'eagerness', 'shrugged', 'forgive', 'wanting', 'eagerness', 'Surely', 'husbands', 'husbands', 'husbands', 'Swandam', 'Lane', 'throat', 'Swandam', 'Lane', 'busy', 'twentyfive', 'Surrey', 'Waterloo', 'river', 'charged', 'inquiries', 'rent', 'Hes', 'vigorously', 'charged', 'charged', 'bill', 'fight', 'pockets', 'Swandam', 'Lane', 'cover', 'terribly', 'watching', 'telling', 'recover', 'fat', 'Court', 'stranger', 'stranger', 'heels', 'Court', 'fled', 'restored', 'suggestive', 'balance', 'buy', 'waste', 'kitchen', 'Countess', 'market', 'Countess', 'recover', 'Countess', 'Countess', 'Countess', 'Countess', 'struggled', 'solve', 'Court', 'buy', 'China', 'Countess', 'winter', 'frockcoat', 'excitement', 'sigh', 'host', 'largest', 'driving', 'warm', 'warm', 'inquiries', 'buy', 'poultry', 'Ive', 'buy', 'Ive', 'longed', 'awkward', 'stranger', 'weather', 'staggered', 'shone', 'brilliant', 'Hes', 'staggered', 'link', 'Countess', 'market', 'market', 'yard', 'stole', 'pick', 'yard', 'bill', 'throat', 'struggled', 'market', 'expressly', 'yard', 'terribly', 'fantastic', 'Surrey', 'widespread', 'Grimesby', 'excitement', 'communicate', 'coffee', 'terror', 'glances', 'throws', 'Waterloo', 'Surrey', 'capital', 'visits', 'temper', 'terror', 'visits', 'communication', 'misfortune', 'terror', 'throat', 'satisfactory', 'terror', 'shaken', 'impassable', 'frockcoat', 'burned', 'Grimesby', 'bulky', 'girls', 'motives', 'Waterloo', 'Waterloo', 'Surrey', 'Grimesby', 'comparatively', 'suggestive', 'throws', 'communicate', 'nice', 'Grimesby', 'turns', 'assure', 'brave', 'Grimesby', 'gathering', 'communication', 'Does', 'nerve', 'cheerful', 'shone', 'vice', 'nice', 'shoes', 'silently', 'Take', 'heels', 'brilliant', 'Grimesby', 'lap', 'puffed', 'lap', 'Grimesby', 'telling', 'threatened', 'revealed', 'driving', 'temper', 'Grimesby', 'acute', 'Ive', 'masculine', 'attack', 'driving', 'column', 'lodgings', 'heels', 'preserving', 'forgive', 'awkward', 'buy', 'comparatively', 'link', 'buy', 'capital', 'buy', 'unpleasant', 'lantern', 'terribly', 'wheels', 'shone', 'unpleasant', 'shaken', 'fat', 'unpleasant', 'crust', 'nerve', 'waste', 'staggered', 'answering', 'lantern', 'shaken', 'telling', 'lodgings', 'busy', 'simpler', 'column', 'widespread', 'excitement', 'bulky', 'driving', 'bulky', 'remarkably', 'unusually', 'bold', 'bridegroom', 'revealed', 'clearing', 'weather', 'surrounded', 'cloud', 'watching', 'assure', 'wanting', 'column', 'misfortune', 'Hes', 'column', 'market', 'charming', 'prompt', 'bridegroom', 'unpleasant', 'bridegroom', 'communication', 'inquiries', 'clearing', 'suggestive', 'bridegroom', 'frockcoat', 'shoes', 'inquiries', 'temper', 'cheerful', 'shrugged', 'push', 'excitement', 'communicate', 'solve', 'prompt', 'shoes', 'brilliant', 'bill', 'Ive', 'theories', 'gets', 'vigorously', 'frockcoat', 'altar', 'marry', 'nicely', 'altar', 'altar', 'lodgings', 'attitude', 'forgive', 'stranger', 'bridegroom', 'bill', 'bill', 'solve', 'pockets', 'frockcoat', 'largest', 'magnificent', 'misfortune', 'alter', 'charming', 'brilliant', 'marry', 'alas', 'coffee', 'coffee', 'demand', 'threatened', 'telling', 'guilty', 'sounding', 'motives', 'entrance', 'kitchen', 'entrance', 'silently', 'shoes', 'theories', 'impatiently', 'kitchen', 'answering', 'contains', 'magnificent', 'shoes', 'clearing', 'rude', 'hunt', 'coffee', 'heels', 'misfortune', 'cover', 'fled', 'misfortune', 'kitchen', 'struggled', 'wore', 'pick', 'shoes', 'Ive', 'deduction', 'answering', 'shone', 'temper', 'deduction', 'throat', 'capital', 'fat', 'commence', 'Copper', 'Beeches', 'watching', 'nicely', 'busy', 'lodgings', 'Copper', 'Beeches', 'nice', 'pick', 'assure', 'impatiently', 'nicely', 'capital', 'threatened', 'cover', 'Copper', 'Beeches', 'weather', 'devoted', 'unpleasant', 'drunk', 'unpleasant', 'Copper', 'Beeches', 'assure', 'lap', 'commence', 'Surely', 'Copper', 'Beeches', 'kitchen', 'assure', 'Rucastles', 'rude', 'drinking', 'drunk', 'shone', 'terror', 'fled', 'drunk', 'pockets', 'drunk', 'Rucastles', 'brave', 'Copper', 'Beeches', 'Rucastles', 'wore', 'girls', 'communicate', 'solve', 'Copper', 'Beeches', 'setting', 'kitchen', 'Rucastles', 'Rucastles', 'fat', 'fat', 'Hes', 'Rucastles', 'throat', 'Rucastles', 'devoted', 'Rucastles', 'EBOOK', 'Terms', 'concept', 'registered', 'START', 'FULL', 'LICENSE', 'FULL', 'LICENSE', 'promoting', 'available', 'file', 'Terms', 'registered', '1C', '1E', '1C', 'promoting', '1E', 'prominently', 'restrictions', 'reuse', 'prominently', 'Plain', 'Vanilla', 'ASCII', 'Plain', 'Vanilla', 'ASCII', 'viewing', '20', 'agreed', 'Royalty', 'Royalty', 'email', 'computer', 'computer', 'WARRANTY', 'DAMAGES', 'damages', 'AGREE', 'BREACH', 'WARRANTY', 'BREACH', 'AGREE', 'DAMAGES', 'SUCH', 'lieu', 'electronically', 'electronically', 'lieu', 'demand', 'WARRANTIES', 'WARRANTIES', 'implied', 'damages', 'disclaimer', 'interpreted', 'disclaimer', 'alteration', 'computers', 'computers', 'walks', 'available', 'Mississippi', 'federal', 'federal', 'Donations', 'widespread', '50', 'solicit', 'wwwgutenbergorgdonate', 'solicit', 'treatment', 'web', 'Donations', 'wwwgutenbergorgdonate', 'concept', 'email']\n"
     ]
    }
   ],
   "source": [
    "print('2')\n",
    "occurences = four_author_books_df[four_author_books_df['Word 1'].map(four_author_books_df['Word 1'].value_counts()) == 8]['Word 1'].tolist()\n",
    "print(occurences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>The Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>Project Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>eBook</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>Gutenberg eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eBook</td>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>eBook of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>On</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>of On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107559</th>\n",
       "      <td>newsletter</td>\n",
       "      <td>to</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>newsletter to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107560</th>\n",
       "      <td>to</td>\n",
       "      <td>hear</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>to hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107561</th>\n",
       "      <td>hear</td>\n",
       "      <td>about</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>hear about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107562</th>\n",
       "      <td>about</td>\n",
       "      <td>new</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>about new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107563</th>\n",
       "      <td>new</td>\n",
       "      <td>eBooks</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>new eBooks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446945 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word 1     Word 2                               book  \\\n",
       "0              The    Project           On the Origin of Species   \n",
       "1          Project  Gutenberg           On the Origin of Species   \n",
       "2        Gutenberg      eBook           On the Origin of Species   \n",
       "3            eBook         of           On the Origin of Species   \n",
       "4               of         On           On the Origin of Species   \n",
       "...            ...        ...                                ...   \n",
       "107559  newsletter         to  The Adventures of Sherlock Holmes   \n",
       "107560          to       hear  The Adventures of Sherlock Holmes   \n",
       "107561        hear      about  The Adventures of Sherlock Holmes   \n",
       "107562       about        new  The Adventures of Sherlock Holmes   \n",
       "107563         new     eBooks  The Adventures of Sherlock Holmes   \n",
       "\n",
       "                   bigram  \n",
       "0             The Project  \n",
       "1       Project Gutenberg  \n",
       "2         Gutenberg eBook  \n",
       "3                eBook of  \n",
       "4                   of On  \n",
       "...                   ...  \n",
       "107559      newsletter to  \n",
       "107560            to hear  \n",
       "107561         hear about  \n",
       "107562          about new  \n",
       "107563         new eBooks  \n",
       "\n",
       "[446945 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_author_books_df.groupby(['Word 1']).size().sort_values(ascending=False).reset_index(name='count')\n",
    "four_author_books_df.groupby(['Word 1', 'book']).size().sort_values(ascending=False).reset_index(name='count')\n",
    "four_author_books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>Word 1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoneit</th>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zones</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoological</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoologist</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoologists</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                book  Word 1\n",
       "Word 1                                      \n",
       "1           On the Origin of Species      15\n",
       "10          On the Origin of Species       7\n",
       "100         On the Origin of Species       7\n",
       "1000        On the Origin of Species       9\n",
       "101         On the Origin of Species       5\n",
       "...                              ...     ...\n",
       "zoneit          Beyond Good and Evil       1\n",
       "zones       On the Origin of Species      12\n",
       "zoological  On the Origin of Species       1\n",
       "zoologist   On the Origin of Species       1\n",
       "zoologists  On the Origin of Species       1\n",
       "\n",
       "[24022 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We group our data by words, then we aggregate and can decide what information we want to display for each column\n",
    "\n",
    "# setting 'first' for the book column means that in the new dataframe we will display the first book on which each word occurs (in the book column)\n",
    "# setting 'count' for the word column means that in the new dataframe we will display the count of given word (in the word column)\n",
    "count_df = four_author_books_df.groupby('Word 1').agg({'book': 'first', 'Word 1': 'count'}) \n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>23748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>17019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>14160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>11222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>8725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interstices</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samos</th>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervalsindispensable</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intervene</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoologists</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            book  count\n",
       "Word 1                                                 \n",
       "the                     On the Origin of Species  23748\n",
       "of                      On the Origin of Species  17019\n",
       "and                     On the Origin of Species  14160\n",
       "to                      On the Origin of Species  11222\n",
       "in                      On the Origin of Species   8725\n",
       "...                                          ...    ...\n",
       "interstices             On the Origin of Species      1\n",
       "Samos                       Beyond Good and Evil      1\n",
       "intervalsindispensable  On the Origin of Species      1\n",
       "intervene               On the Origin of Species      1\n",
       "zoologists              On the Origin of Species      1\n",
       "\n",
       "[24022 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = count_df.rename(columns={'Word 1': 'count'})\n",
    "count_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>10018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>7938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>4589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>4419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37452</th>\n",
       "      <td>modificationthe</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37453</th>\n",
       "      <td>modificationsnamely</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37454</th>\n",
       "      <td>modificationseach</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37455</th>\n",
       "      <td>modificationfor</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37456</th>\n",
       "      <td>zoologists</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37457 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Word 1                                book  count\n",
       "0                      the            On the Origin of Species  10018\n",
       "1                       of            On the Origin of Species   7938\n",
       "2                      the   The Adventures of Sherlock Holmes   5425\n",
       "3                      the  The Confessions of Saint Augustine   4589\n",
       "4                      and            On the Origin of Species   4419\n",
       "...                    ...                                 ...    ...\n",
       "37452      modificationthe            On the Origin of Species      1\n",
       "37453  modificationsnamely                Beyond Good and Evil      1\n",
       "37454    modificationseach            On the Origin of Species      1\n",
       "37455      modificationfor            On the Origin of Species      1\n",
       "37456           zoologists            On the Origin of Species      1\n",
       "\n",
       "[37457 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df_1 = four_author_books_df.groupby(['Word 1', 'book']).size().sort_values(ascending=False).reset_index(name='count') # How many appearances each word has in each book\n",
    "count_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>114926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>107564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>65749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 book   count\n",
       "0            On the Origin of Species  158706\n",
       "1  The Confessions of Saint Augustine  114926\n",
       "2   The Adventures of Sherlock Holmes  107564\n",
       "3                Beyond Good and Evil   65749"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df_2 = four_author_books_df.groupby(['book']).size().sort_values(ascending=False).reset_index(name='count') # How many words each book has\n",
    "count_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>10018</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>7938</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>4419</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>3816</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>3652</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>2418</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>2051</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>have</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1767</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>be</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1671</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>as</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>1492</td>\n",
       "      <td>158706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word 1                      book  word_appearances_in_book  \\\n",
       "0    the  On the Origin of Species                     10018   \n",
       "1     of  On the Origin of Species                      7938   \n",
       "2    and  On the Origin of Species                      4419   \n",
       "3     in  On the Origin of Species                      3816   \n",
       "4     to  On the Origin of Species                      3652   \n",
       "5      a  On the Origin of Species                      2418   \n",
       "6   that  On the Origin of Species                      2051   \n",
       "7   have  On the Origin of Species                      1767   \n",
       "8     be  On the Origin of Species                      1671   \n",
       "9     as  On the Origin of Species                      1492   \n",
       "\n",
       "   book_total_word_count  \n",
       "0                 158706  \n",
       "1                 158706  \n",
       "2                 158706  \n",
       "3                 158706  \n",
       "4                 158706  \n",
       "5                 158706  \n",
       "6                 158706  \n",
       "7                 158706  \n",
       "8                 158706  \n",
       "9                 158706  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words = count_df_1.merge(count_df_2, on='book')\n",
    "book_words = book_words.rename(columns={'count_x': 'word_appearances_in_book', 'count_y': 'book_total_word_count'}) # Give more meaningful names\n",
    "book_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>10018</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.063123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>7938</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.050017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>4419</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.027844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>3816</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.024044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>3652</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.023011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word 1                      book  word_appearances_in_book  \\\n",
       "0    the  On the Origin of Species                     10018   \n",
       "1     of  On the Origin of Species                      7938   \n",
       "2    and  On the Origin of Species                      4419   \n",
       "3     in  On the Origin of Species                      3816   \n",
       "4     to  On the Origin of Species                      3652   \n",
       "\n",
       "   book_total_word_count  term_frequency  \n",
       "0                 158706        0.063123  \n",
       "1                 158706        0.050017  \n",
       "2                 158706        0.027844  \n",
       "3                 158706        0.024044  \n",
       "4                 158706        0.023011  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_words['term_frequency'] = book_words['word_appearances_in_book'].div(book_words['book_total_word_count'])\n",
    "book_words.dropna(subset = ['term_frequency'], inplace=True)\n",
    "book_words.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>book</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>10018</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>7938</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.050017</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>4419</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>3816</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.024044</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>3652</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37452</th>\n",
       "      <td>capo</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37453</th>\n",
       "      <td>modification</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37454</th>\n",
       "      <td>moles</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37455</th>\n",
       "      <td>candidly</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37456</th>\n",
       "      <td>modificationsnamely</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37457 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Word 1                      book  \\\n",
       "0                      the  On the Origin of Species   \n",
       "1                       of  On the Origin of Species   \n",
       "2                      and  On the Origin of Species   \n",
       "3                       in  On the Origin of Species   \n",
       "4                       to  On the Origin of Species   \n",
       "...                    ...                       ...   \n",
       "37452                 capo      Beyond Good and Evil   \n",
       "37453         modification      Beyond Good and Evil   \n",
       "37454                moles      Beyond Good and Evil   \n",
       "37455             candidly      Beyond Good and Evil   \n",
       "37456  modificationsnamely      Beyond Good and Evil   \n",
       "\n",
       "       word_appearances_in_book  book_total_word_count  term_frequency   rank  \n",
       "0                         10018                 158706        0.063123    1.0  \n",
       "1                          7938                 158706        0.050017    2.0  \n",
       "2                          4419                 158706        0.027844    5.0  \n",
       "3                          3816                 158706        0.024044    7.0  \n",
       "4                          3652                 158706        0.023011    9.0  \n",
       "...                         ...                    ...             ...    ...  \n",
       "37452                         1                  65749        0.000015  431.0  \n",
       "37453                         1                  65749        0.000015  431.0  \n",
       "37454                         1                  65749        0.000015  431.0  \n",
       "37455                         1                  65749        0.000015  431.0  \n",
       "37456                         1                  65749        0.000015  431.0  \n",
       "\n",
       "[37457 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df = book_words['word_appearances_in_book'].rank(method='dense', ascending=False)\n",
    "book_words_df = pd.concat([rank_df.rename('rank'), book_words], axis=1).reset_index(drop=True)\n",
    "book_words_df[['Word 1', 'book', 'word_appearances_in_book','book_total_word_count', 'term_frequency', 'rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N = book_words_df['book'].nunique()\n",
    "n = book_words_df['n'] = book_words_df.groupby('Word 1')['book'].transform('nunique')\n",
    "book_words_df['idf'] = np.log(N / n)\n",
    "book_words_df = book_words_df.rename(columns={'n_x': 'total_no_of_books', 'n_y': 'no_of_word_freq'}) # Give more meaningful names\n",
    "\n",
    "tf = book_words['term_frequency']\n",
    "idf = book_words_df['idf']\n",
    "book_words_df['tf-idf'] =  tf * idf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>n</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>10018</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>of</td>\n",
       "      <td>7938</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.050017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>and</td>\n",
       "      <td>4419</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.027844</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>in</td>\n",
       "      <td>3816</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.024044</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>to</td>\n",
       "      <td>3652</td>\n",
       "      <td>158706</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37452</th>\n",
       "      <td>431.0</td>\n",
       "      <td>capo</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37453</th>\n",
       "      <td>431.0</td>\n",
       "      <td>modification</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37454</th>\n",
       "      <td>431.0</td>\n",
       "      <td>moles</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37455</th>\n",
       "      <td>431.0</td>\n",
       "      <td>candidly</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37456</th>\n",
       "      <td>431.0</td>\n",
       "      <td>modificationsnamely</td>\n",
       "      <td>1</td>\n",
       "      <td>65749</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37457 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank               Word 1  word_appearances_in_book  \\\n",
       "0        1.0                  the                     10018   \n",
       "1        2.0                   of                      7938   \n",
       "2        5.0                  and                      4419   \n",
       "3        7.0                   in                      3816   \n",
       "4        9.0                   to                      3652   \n",
       "...      ...                  ...                       ...   \n",
       "37452  431.0                 capo                         1   \n",
       "37453  431.0         modification                         1   \n",
       "37454  431.0                moles                         1   \n",
       "37455  431.0             candidly                         1   \n",
       "37456  431.0  modificationsnamely                         1   \n",
       "\n",
       "       book_total_word_count  term_frequency  n       idf    tf-idf  \n",
       "0                     158706        0.063123  4  0.000000  0.000000  \n",
       "1                     158706        0.050017  4  0.000000  0.000000  \n",
       "2                     158706        0.027844  4  0.000000  0.000000  \n",
       "3                     158706        0.024044  4  0.000000  0.000000  \n",
       "4                     158706        0.023011  4  0.000000  0.000000  \n",
       "...                      ...             ... ..       ...       ...  \n",
       "37452                  65749        0.000015  1  1.386294  0.000021  \n",
       "37453                  65749        0.000015  4  0.000000  0.000000  \n",
       "37454                  65749        0.000015  2  0.693147  0.000011  \n",
       "37455                  65749        0.000015  1  1.386294  0.000021  \n",
       "37456                  65749        0.000015  1  1.386294  0.000021  \n",
       "\n",
       "[37457 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "book_words_df.drop('book', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "      <th>bigram</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>n</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>side</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>the side</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grief</td>\n",
       "      <td>for</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>grief for</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>observation</td>\n",
       "      <td>and</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>observation and</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entire</td>\n",
       "      <td>University</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>entire University</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proportion</td>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>proportion of</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149823</th>\n",
       "      <td>the</td>\n",
       "      <td>yet</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>the yet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149824</th>\n",
       "      <td>shoot</td>\n",
       "      <td>of</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>shoot of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149825</th>\n",
       "      <td>my</td>\n",
       "      <td>heart</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>my heart</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149826</th>\n",
       "      <td>these</td>\n",
       "      <td>empty</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>these empty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149827</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>The Project</td>\n",
       "      <td>10018.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149828 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word 1      Word 2                                book  \\\n",
       "0               the        side            On the Origin of Species   \n",
       "1             grief         for  The Confessions of Saint Augustine   \n",
       "2       observation         and   The Adventures of Sherlock Holmes   \n",
       "3            entire  University                Beyond Good and Evil   \n",
       "4        proportion          of            On the Origin of Species   \n",
       "...             ...         ...                                 ...   \n",
       "149823          the         yet  The Confessions of Saint Augustine   \n",
       "149824        shoot          of  The Confessions of Saint Augustine   \n",
       "149825           my       heart  The Confessions of Saint Augustine   \n",
       "149826        these       empty  The Confessions of Saint Augustine   \n",
       "149827          The     Project  The Confessions of Saint Augustine   \n",
       "\n",
       "                   bigram  word_appearances_in_book  book_total_word_count  \\\n",
       "0                the side                     875.0               114926.0   \n",
       "1               grief for                     875.0               114926.0   \n",
       "2         observation and                     875.0               114926.0   \n",
       "3       entire University                     875.0               114926.0   \n",
       "4           proportion of                    1005.0               114926.0   \n",
       "...                   ...                       ...                    ...   \n",
       "149823            the yet                       1.0               158706.0   \n",
       "149824           shoot of                       1.0               158706.0   \n",
       "149825           my heart                       1.0               158706.0   \n",
       "149826        these empty                       1.0               158706.0   \n",
       "149827        The Project                   10018.0               158706.0   \n",
       "\n",
       "        term_frequency  n       idf    tf-idf  \n",
       "0             0.007614  1  1.386294  0.010555  \n",
       "1             0.007614  1  1.386294  0.010555  \n",
       "2             0.007614  1  1.386294  0.010555  \n",
       "3             0.007614  1  1.386294  0.010555  \n",
       "4             0.008745  2  0.693147  0.006061  \n",
       "...                ... ..       ...       ...  \n",
       "149823        0.000006  4  0.000000  0.000000  \n",
       "149824        0.000006  4  0.000000  0.000000  \n",
       "149825        0.000006  4  0.000000  0.000000  \n",
       "149826        0.000006  4  0.000000  0.000000  \n",
       "149827        0.063123  4  0.000000  0.000000  \n",
       "\n",
       "[149828 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "four_books_df = pd.concat([four_author_books_df, book_words],axis = 1)\n",
    "four_books_df = four_books_df.dropna(axis=0)\n",
    "four_books_df['n'] = book_words_df['n']\n",
    "four_books_df['idf'] = book_words_df['idf']\n",
    "four_books_df['tf-idf']= book_words_df['tf-idf']\n",
    "four_books_df\n",
    "\n",
    "sorted_df = four_books_df.sort_values(by= 'tf-idf', ascending = False)\n",
    "sorted_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "sorted_df = sorted_df.loc[:,~sorted_df.columns.duplicated()]\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         entire\n",
       "1             of\n",
       "2          actor\n",
       "3     University\n",
       "4          ebook\n",
       "         ...    \n",
       "27           for\n",
       "28          This\n",
       "29            my\n",
       "30           The\n",
       "31        bodily\n",
       "Name: Word 1, Length: 32, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('3')\n",
    "\n",
    "occurences = sorted_df.groupby('book').apply(lambda x : x.nlargest(8, 'tf-idf')['Word 1']).reset_index(drop=True)\n",
    "occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        entire University\n",
       "1             of laborious\n",
       "2              actor lurks\n",
       "3     University personnel\n",
       "4                 ebook is\n",
       "              ...         \n",
       "15               grief for\n",
       "16                  But is\n",
       "17            firmament to\n",
       "18                   for a\n",
       "19              This ebook\n",
       "Name: bigram, Length: 20, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('4')\n",
    "\n",
    "occurrences_bigrams = sorted_df.groupby('book').apply(lambda x: x.nlargest(5, 'tf-idf')['bigram']).reset_index(drop=True)\n",
    "occurrences_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>book</th>\n",
       "      <th>bigram</th>\n",
       "      <th>word_appearances_in_book</th>\n",
       "      <th>book_total_word_count</th>\n",
       "      <th>term_frequency</th>\n",
       "      <th>n</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>side</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>the side</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grief</td>\n",
       "      <td>for</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>grief for</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>observation</td>\n",
       "      <td>and</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>observation and</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entire</td>\n",
       "      <td>University</td>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>entire University</td>\n",
       "      <td>875.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proportion</td>\n",
       "      <td>of</td>\n",
       "      <td>On the Origin of Species</td>\n",
       "      <td>proportion of</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>114926.0</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149823</th>\n",
       "      <td>the</td>\n",
       "      <td>yet</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>the yet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149824</th>\n",
       "      <td>shoot</td>\n",
       "      <td>of</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>shoot of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149825</th>\n",
       "      <td>my</td>\n",
       "      <td>heart</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>my heart</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149826</th>\n",
       "      <td>these</td>\n",
       "      <td>empty</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>these empty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149827</th>\n",
       "      <td>The</td>\n",
       "      <td>Project</td>\n",
       "      <td>The Confessions of Saint Augustine</td>\n",
       "      <td>The Project</td>\n",
       "      <td>10018.0</td>\n",
       "      <td>158706.0</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149828 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word 1      Word 2                                book  \\\n",
       "0               the        side            On the Origin of Species   \n",
       "1             grief         for  The Confessions of Saint Augustine   \n",
       "2       observation         and   The Adventures of Sherlock Holmes   \n",
       "3            entire  University                Beyond Good and Evil   \n",
       "4        proportion          of            On the Origin of Species   \n",
       "...             ...         ...                                 ...   \n",
       "149823          the         yet  The Confessions of Saint Augustine   \n",
       "149824        shoot          of  The Confessions of Saint Augustine   \n",
       "149825           my       heart  The Confessions of Saint Augustine   \n",
       "149826        these       empty  The Confessions of Saint Augustine   \n",
       "149827          The     Project  The Confessions of Saint Augustine   \n",
       "\n",
       "                   bigram  word_appearances_in_book  book_total_word_count  \\\n",
       "0                the side                     875.0               114926.0   \n",
       "1               grief for                     875.0               114926.0   \n",
       "2         observation and                     875.0               114926.0   \n",
       "3       entire University                     875.0               114926.0   \n",
       "4           proportion of                    1005.0               114926.0   \n",
       "...                   ...                       ...                    ...   \n",
       "149823            the yet                       1.0               158706.0   \n",
       "149824           shoot of                       1.0               158706.0   \n",
       "149825           my heart                       1.0               158706.0   \n",
       "149826        these empty                       1.0               158706.0   \n",
       "149827        The Project                   10018.0               158706.0   \n",
       "\n",
       "        term_frequency  n       idf    tf-idf  \n",
       "0             0.007614  1  1.386294  0.010555  \n",
       "1             0.007614  1  1.386294  0.010555  \n",
       "2             0.007614  1  1.386294  0.010555  \n",
       "3             0.007614  1  1.386294  0.010555  \n",
       "4             0.008745  2  0.693147  0.006061  \n",
       "...                ... ..       ...       ...  \n",
       "149823        0.000006  4  0.000000  0.000000  \n",
       "149824        0.000006  4  0.000000  0.000000  \n",
       "149825        0.000006  4  0.000000  0.000000  \n",
       "149826        0.000006  4  0.000000  0.000000  \n",
       "149827        0.063123  4  0.000000  0.000000  \n",
       "\n",
       "[149828 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = sorted_df\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most frequent street names with the book they are coming from:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potential_street_names</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baker Street</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SaxeCoburg Square</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Leadenhall Street</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Popes Court</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Serpentine Avenue</td>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   potential_street_names                               book\n",
       "0            Baker Street  The Adventures of Sherlock Holmes\n",
       "13      SaxeCoburg Square  The Adventures of Sherlock Holmes\n",
       "19      Leadenhall Street  The Adventures of Sherlock Holmes\n",
       "23            Popes Court  The Adventures of Sherlock Holmes\n",
       "26      Serpentine Avenue  The Adventures of Sherlock Holmes"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "exploded_df = new_df.explode('bigram')\n",
    "\n",
    "street_name_pattern = r'\\b(?:\\d+\\s)?[A-Z][a-zA-Z]*\\s(?:Street|Avenue|Road|Lane|Boulevard|Drive|Court|Place|Square|Terrace|Way|Parkway|Circle|Highway|Alley|Crescent|Plaza|Trail|Row|Path)\\b'\n",
    "\n",
    "exploded_df['potential_street_names'] = exploded_df['bigram'].apply(lambda x: re.findall(street_name_pattern, x))\n",
    "\n",
    "exploded_df = exploded_df.explode('potential_street_names').dropna(subset=['potential_street_names'])\n",
    "\n",
    "street_name_counts = exploded_df.groupby('potential_street_names').size().reset_index(name='count')\n",
    "\n",
    "top_street_names = street_name_counts.nlargest(5, 'count')\n",
    "\n",
    "top_street_names_with_books = pd.merge(top_street_names, exploded_df, on='potential_street_names')\n",
    "\n",
    "result = top_street_names_with_books[['potential_street_names', 'book']].drop_duplicates()\n",
    "\n",
    "print(\"Top 5 most frequent street names with the book they are coming from:\")\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 bigrams in 'The Adventures of Sherlock Holmes' with 'observation' as the first word:\n",
      "  (observation and): 2\n",
      "  (observation of): 2\n",
      "  (observation in): 1\n",
      "  (observation not): 1\n",
      "\n",
      "Top 5 bigrams in 'The Confessions of Saint Augustine' with 'observation' as the first word:\n",
      "  (observation amid): 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fixed word1\n",
    "fixed_word1 = \"observation\"\n",
    "\n",
    "# Filter bigrams where 'Word 1' is the fixed word\n",
    "filtered_df = new_df[new_df['Word 1'] == fixed_word1]\n",
    "\n",
    "# Group by book and bigram, then count the occurrences\n",
    "grouped = filtered_df.groupby(['book', 'bigram']).size().reset_index(name='count')\n",
    "\n",
    "# Get the top 5 most common bigrams for each book\n",
    "top_bigrams = grouped.groupby('book').apply(lambda x: x.nlargest(5, 'count')).reset_index(drop=True)\n",
    "\n",
    "# Print the results\n",
    "for book in top_bigrams['book'].unique():\n",
    "    print(f\"Top 5 bigrams in '{book}' with '{fixed_word1}' as the first word:\")\n",
    "    book_bigrams = top_bigrams[top_bigrams['book'] == book]\n",
    "    for _, row in book_bigrams.iterrows():\n",
    "        print(f\"  ({row['bigram']}): {row['count']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
